<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Luc | PythonMood</title>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Luc | PythonMood Let‚Äôs code with Lulu</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Luc" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Luc Bertin‚Äôs blog of Python theoretical and hands-on tutorials. Here we cover Python from scratch and some use cases for Data Science related subjects" />
<meta property="og:description" content="Luc Bertin‚Äôs blog of Python theoretical and hands-on tutorials. Here we cover Python from scratch and some use cases for Data Science related subjects" />
<link rel="canonical" href="http://localhost:4000/author-luc.html" />
<meta property="og:url" content="http://localhost:4000/author-luc.html" />
<meta property="og:site_name" content="PythonMood Let‚Äôs code with Lulu" />
<script type="application/ld+json">
{"description":"Luc Bertin‚Äôs blog of Python theoretical and hands-on tutorials. Here we cover Python from scratch and some use cases for Data Science related subjects","@type":"WebPage","url":"http://localhost:4000/author-luc.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"}},"headline":"Luc","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

    <!-- Bootstrap Modified -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!-- Theme Stylesheet -->
    <link rel="stylesheet" href="/assets/css/theme.css">

    <!-- Custom styles and dark mode -->
    <link rel="stylesheet" href="/assets/css/custom.css">

    <link rel="stylesheet" href="/assets/css/dark.css">

    <!-- Jquery on header to make sure everything works, the rest  of the scripts in footer for fast loading -->
    <script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>

    <!-- Mathjax Support -->
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    
    <!-- This goes before </head> closing tag, Google Analytics can be placed here --> 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-176409228-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-176409228-1');
</script>


</head>

<body class="">

    <!-- Navbar -->
    <nav id="MagicMenu" class="topnav navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <div class="container">
        <a class="navbar-brand" href="/index.html"><strong>PythonMood</strong></a>
        <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarColor02" style="">
            <ul class="navbar-nav mr-auto d-flex align-items-center">
               <!--  Replace menu links here -->

<li class="nav-item">
<a class="nav-link" href="/index.html">Home</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/authors-list.html">Authors</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/contact.html">Contact</a>
</li>
            </ul>
            <ul class="navbar-nav ml-auto d-flex align-items-center">
                <script src="/assets/js/lunr.js"></script>

<script>
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 1000 );
        $( "body" ).removeClass( "modal-open" );
    });
});
    

var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404/",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "http://localhost:4000/author-luc.html",
    "title": "Luc",
    "body": "                        Luc Follow on Github:         https://lucbertin. com         Hi, my name is Luc. To me, code is art and i love coding in Python, hence the website !                                   Posts by Luc:                   		Supervised Machine Learning	: 		   Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed (if,if,if,else,if). ‚Äî Arthur Samuel, 1959	 			In 				TDs, 				StatsEnVrac, 								Sep 25, 2020						            		Some functional programming exercices	: 		  Some exercices following tutorial Introduction to functional programming to make you more comfortable with the concepts. 	 			In 				TDs, 				Exercices, 				Python, 								Sep 14, 2020						            		Some Pandas exercices	: 		  Some exercices following tutorial Discover Pandas to make you more comfortable with the concepts. 	 			In 				TDs, 				Exercices, 				Pandas, 				Python, 								Sep 14, 2020						            		Discover Pandas	: 		  Why Pandas ?	 			In 				TDs, 				Python, 								Sep 10, 2020						            		Webscrapping using Selenium	: 		  Selenium is an open-source automated testing suite for web apps. It was at first used to automate tests for web applications as it can emulate user interactions with browsers, althoug. . . 	 			In 				TDs, 				Lecture, 				Selenium, 				Python, 								Sep 07, 2020						            		Hands-on Numpy !	: 		  It is often better to visualize data of apparent heterogeneity (sounds, images, text) as arrays of numbers, so to process these data or apply machine learning on them. A well-known pa. . . 	 			In 				Lecture, 				Python, 				Numpy, 								Sep 01, 2020						            		Some Python exercices	: 		  Some exercices following tutorial Beginning in Python to make you more comfortable with some object-oriented concepts in Python ;)	 			In 				TDs, 				Exercices, 				Python, 								Sep 01, 2020						            		Setting up a simple Flask app	: 		  Flask is a micro web framework written in Python, first released in 2010. It is lightweight (hence the ‚Äúmicro‚Äù), has more stars on GitHub that is ‚Äúconcurrent‚Äù Django¬†‚Äî first released . . . 	 			In 				TDs, 				Flask, 				Python, 								Aug 29, 2020						            		A note on execution model	: 		  	 			In 				TDs, 				Lecture, 				Python, 								Aug 28, 2020						            		Beginning in Python	: 		  1st course will mainly focus on how to approach Python for the first time. For that we will use Jupyter module. 	 			In 				TDs, 								Aug 22, 2020						            		Install Python !	: 		  This tutorial helps newcomers to install Python properly and manage different Python versions, especially for Mac users having a system 2. 7 Python installed already. 	 			In 				TDs, 				Python, 								Aug 14, 2020						            		Coding a perceptron with Numpy	: 		  Voici un test pour un nouveau post	 			In 				TDs, 				Deep Learning, 								Aug 04, 2020						            		Introduction to functional programming	: 		  	 			In 				TDs, 				Lecture, 				Python, 								Aug 03, 2020						            		Go to all course practice sessions !	: 		  Github is a web-hosting platform and software development management service using Git versionning system. This site is developed using Ruby on Rails and contains as of today 50 milli. . . 	 			In 				TDs, 								Aug 03, 2020						        "
    }, {
    "id": 2,
    "url": "http://localhost:4000/authors-list.html",
    "title": "Authors",
    "body": "  {{page. title}}:       {% for author in site. authors %}                                                                 {{ author[1]. name }} :               (View Posts)              {{ author[1]. bio }}                                                       &nbsp;                 &nbsp;                                                                          {% endfor %}  "
    }, {
    "id": 3,
    "url": "http://localhost:4000/buy-me-a-coffee.html",
    "title": "Buy me a coffee",
    "body": "Hi! I am LucThank you so much! Buy me a coffee "
    }, {
    "id": 4,
    "url": "http://localhost:4000/categories.html",
    "title": "Categories",
    "body": "          Categories          {% for category in site. categories %}     {{ category[0] }}:           {% assign pages_list = category[1] %}    {% for post in pages_list %}    {% if post. title != null %}     {% if group == null or group == post. group %}           {% include main-loop-card. html %}     {% endif %}    {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}    {% endfor %}                  {% include sidebar-featured. html %}          "
    }, {
    "id": 5,
    "url": "http://localhost:4000/contact.html",
    "title": "Contact",
    "body": "  Please send your message to {{site. name}}. We will reply as soon as possible!   "
    }, {
    "id": 6,
    "url": "http://localhost:4000/",
    "title": "",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image_index contains  ://  %}{{ latest_post. image_index }}{% else %} {{site. baseurl}}/{{ latest_post. image_index}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image_index %}                         &lt;img class= w-100  src= {% if second_post. image_index contains  ://  %}{{ second_post. image_index }}{% else %}{{ second_post. image_index | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image_index %}                         &lt;img class= w-100  src= {% if third_post. image_index contains  ://  %}{{ third_post. image_index }}{% else %}{{site. baseurl}}/{{ third_post. image_index }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image_index %}                        &lt;img class= w-100  src= {% if fourth_post. image_index contains  ://  %}{{ fourth_post. image_index }}{% else %}{{site. baseurl}}/{{ fourth_post. image_index }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 7,
    "url": "http://localhost:4000/privacy-policy.html",
    "title": "Privacy Policy",
    "body": "‚Äù{{site. name}}‚Äù takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used. Collection of Routine Information: This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes. Cookies: Where necessary, this website uses cookies to store information about a visitor‚Äôs preferences and history in order to better serve the visitor and/or present the visitor with customized content. Advertisement and Other Third Parties: Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to opt out of Google‚Äôs cookie usage. Links to Third Party Websites: We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own. Security: The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security. Changes To This Privacy Policy: This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page. We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website. Contact Information: For any questions or concerns regarding the privacy policy, please contact us here. "
    }, {
    "id": 8,
    "url": "http://localhost:4000/tags.html",
    "title": "Tags",
    "body": "          Tags          {% for tag in site. tags %}     {{ tag[0] }}:           {% assign pages_list = tag[1] %}    {% for post in pages_list %}    {% if post. title != null %}     {% if group == null or group == post. group %}           {% include main-loop-card. html %}     {% endif %}    {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}    {% endfor %}                  {% include sidebar-featured. html %}          "
    }, {
    "id": 9,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ ‚Äúsitemap. xml‚Äù   absolute_url }}   "
    }, {
    "id": 10,
    "url": "http://localhost:4000/page2/",
    "title": "",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image_index contains  ://  %}{{ latest_post. image_index }}{% else %} {{site. baseurl}}/{{ latest_post. image_index}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image_index %}                         &lt;img class= w-100  src= {% if second_post. image_index contains  ://  %}{{ second_post. image_index }}{% else %}{{ second_post. image_index | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image_index %}                         &lt;img class= w-100  src= {% if third_post. image_index contains  ://  %}{{ third_post. image_index }}{% else %}{{site. baseurl}}/{{ third_post. image_index }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image_index %}                        &lt;img class= w-100  src= {% if fourth_post. image_index contains  ://  %}{{ fourth_post. image_index }}{% else %}{{site. baseurl}}/{{ fourth_post. image_index }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 11,
    "url": "http://localhost:4000/Notions-Supervised-Machine-Learning/",
    "title": "Supervised Machine Learning",
    "body": "2020/09/25 -  Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed (if,if,if,else,if). ‚Äî Arthur Samuel, 1959 IntroductionWhy Machine Learning (ML) ?: The promise with ML is to have a general framework to create data-related models which we expect to be more robust, personalized and easier to maintain into detecting patterns than hard-coding a set of rules. Detecting new patterns over time, or from different sources, only require you to update the model or retrain it over the corresponding set of data. ML models can also be inspected to infer about relationships between variables, and give humans a better understanding on complex and massive data, this is also called data mining. But in my opinion there should be caution on such practice as to infer on the data generation¬†process which is something that better falls in the scope of statistics. Machine Learning vs Statistics: Statistics emphasizes inference, whereas Machine Learning emphasizes prediction. Actually the term inference in ML refers more as the predictions made on unseen data from a trained model while inference in statistics is the process to deduce properties of an underlying distribution of probability, the observed data is believed to have originated from a larger population. Hence statistics is employed towards better understanding some particular data generating process  A statistical model (SM) is a data model that incorporates probabilities for the data generating mechanism and has identified unknown parameters that are usually interpretable and of special interest. Satistics explicitly takes uncertainty into account by specifying a probabilistic model for the data.  It has a mathematical formulation that shows the relationships between random variables and parameters.  Residuals are the portion of the data unexplained by the model.  Most of the variation in the data should be explained by the latter though i. e. \(data = model + residuals\).  It makes assumptions about the random variables. ML is more empirical including allowance for high-order interactions that are not pre-specified. Neithertheless, ML emboddies representation (the transformation of inputs from one space to another more useful space which can be more easily interpreted), and ML models can be also exploited or interpreted to extract meaningful information or patterns from the underlying observed data (this is also encapsulated by what is called as Data Mining). Some terminologyEstimator vs estimate vs estimand: Directly from Wikipedia (this is self-exaplanatory):  In statistics, an estimator is a rule for calculating an estimate of a given quantity based on observed data: thus the rule (the estimator), the quantity of interest (the estimand) and its result (the estimate) are distinguished. Probability space: It is a mathematical construct to give a theoretical frame to random process / ‚Äúexperiment‚Äù. Again using Wikipedia definition; it is constituted of 3 composants: \((\Omega, F, P)\)  a sample space (all the possible outcomes of the experiment) an event space (all the events, an event being a set of outcomes in the sample space) a probability function: which assigns to each event in the event space a probability. E. g. tossing a coin once sample space = {(head, head), (head, tail), (tail, tail)} (if we don‚Äôt care about the order : unordered) event space includes event1 ‚ÄúE=having eads twice‚Äù or event2 ‚ÄúE=having head and tail once‚Äù.  probability function: fair coin: 1/2 of 1 head and 1/2 of one tail. Random Variable: A random variable is a function defined on a probability space which assigns to a element in the sample space (an outcome of an experiment) a real value. \(X=(x_1, x_2, \dots, x_M)\) is one row of your dataset, then \(X\) can be associated with the ‚Äúrealization‚Äù of \(M\) random variables: \(X_1, X_2, \dots, X_M\) Hypothesis:  From Wikipedia: A statistical hypothesis is a hypothesis that is testable on the basis of observed data modeled as the realised values taken by a collection of random variables. A set of data (or several sets of data, taken together) are modelled as being realised values of a collection of random variables having a joint probability distribution in some set of possible joint distributions. The hypothesis being tested is exactly that set of possible probability distributions. Prediction vs Estimation: An estimator is a function (of a random variable corresponding to the observed data \(X\)), and is denoted \(\hat{\theta}\)The composition \(\hat{\theta}(X)\) is an estimate produced by applying the estimator function on some realizations of \(X\) (the observed data or a subset of it). The estimator thus maps the realizations of \(X\) to a (set of) sample estimates, depending on \(X\), making the composition a random variable, with a fixed value for a given input. For example, the OLS estimate for a simple linear regression is \((\hat{\alpha}, \hat{\beta})\). In OLS again, you can think of the formulas to define the \(\beta\)s and the \(intercept\) as estimators, and the corresponding estimates produced from applying the estimators on a given sample or set of data. A predictor concerns the independent observation/value of another random variable \(Z\) whose distribution is related to the unknown parameters we try to estimate using estimators. Hence, \(Z\) being a random variable, it also brings an additional uncertainty as the outcomes from \(Z\) are random, not only from the randomness of the data, but the randomness of \(Z\) itself. The predictor applied on a single vector of data-points, and \(Z\) itself, are not part of the dataset. Here we talk about realizations of a random variable that depends on the independent variables in the data \(Z\)=\(Y(x)\).  in addition, there is uncertainty in just what value of \(Y(x)\) will occur. This additional uncertainty - because \(Y(x)\) is random - characterizes predictions. [‚Ä¶] The source of potential confusion is that the prediction usually builds on the estimated parameters and might even have the same formula as an estimator. The Data: Units of observation: These are items that you actually observe, the level at which you collect the data. Unit of analysis (case): On another hand, this is the level at which you pitch the conclusions. For example, you may draw conclusions on group differences based on results you‚Äôve collected on a student level. Caracteristics: attributes and features: We may look at different caracteristics/dimensions for each given item we are observing. The name of each of the dimension that encapsulates the respective individual measurements is called a data attribute (e. g. weight of a patient, e. g. level of glucose). Similarly a feature embeds both the data attribute and its corresponding value for a given unit of observation. Often though, features and attributes are interchangeably used terminology. Finally feature variable is even more closely related to data attribute, a slight difference is that the variable is the ‚Äúoperationalized representation‚Äù of the latter. In other tutorials of this blog, we will use data attribute and feature variable interchangeably. Data points: Data points are the different measures carried out for a unit of observation. It is a collection of features / caracteristics. For example, one patient could have a data point defined as the collection {weight, height, level of glucose, BMI}. The point could be ‚Äúplot‚Äù in such n-dimensional figure. Features here are each of these dimensions. Data structure: For most ML algorithsm, data collected are often stored in a 2-dimensional dataframe or similarly shaped array. The features variables / data attributes correspond to the columns of the dataset, while the rows match the units of observation. Cross-sectionnal vs longitudinal vs time-series study: Units of observation could be equally spaced time records for one individual/entity/study unit. Say for example Apple stock price variations over time: we would then talk about a time-series study. When multiple individuals do have each different time point observations, we are talking about longitudinal study. Lastly, cross-sectional studies are constituted of entities‚Äô observations at one speficic point in time (e. g. Boston houses price dataset). Quantitative vs qualitative research: A quantitative research is an empirical method that relies on collected numerical data to apply elements of the scientific method on: such as the drawing hypotheses, generation of mathematical models and the ultimate acquiring of knowledge. A qualitative research is rather used to explore trends or gather insights using non-numerical data (video, text, etc. ) by conducting surveys or interviews for example. Quantitative vs Categorical variables (or ‚Äúnominal‚Äù): Statistical computations and analyses assume that the variables have specific levels of measurement. Categorical variables are variable holding 2 or more categories but without any ordering between the categories (can you order someone with blue eyes from someone else with red ones ?). Ordinal variables, on the other hand, have categories that can be ordered (e. g. Height could be Low, Medium or High), but the spacing between the values may not be the same across the levels of the variables ! Were it be, the variables would be numerical / quantitative. Numerical variables can be subclassed in continuous or discrete variables. Continuous variables is more of a conceptual construct: values discretion appears inevitably as instruments of measurement does not have infinite countable range values. The difference between numerical and ordinal variable is that the former necessarily implies an interval scale where the difference between two values is meaningful. The ML part: Algorithm vs model: An algorithm is the set of instructions i. e. the approach to build a model. The model is the final construct - computational tool obtained from running the algorithm on the data (training data more exactly). Model parameters change over the data the model has been trained on.  from windows docs: You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn‚Äôt seen before, and make predictions about those data. Model parameters vs hyperparameters: Model parameters change over the data the model has been trained on. Model hyperparameters have values that should be fixed prior to running the algorithm on the data to construct the model. The model structure can change depending on the values set for the hyperparameters. Hyperparams then eventually control the process of defining your model. These are ‚Äúparameters‚Äù to ultimately fine-tune, often controlling overfitting tendency of the model. A regression model built using OLS method and not using any penalization does not have any hyperparameters. A regression model made from using Gradient Descent algorithm does indeed use an hyperparameter: the learning rate. Outcome variable: What you‚Äôre trying to predict, in a supervised machine learning problem. The \(y\) is the true/observed value from the data.  \(y\) could be a single numerical value (this leads to a regression problem) or a categorical one (this leads to a classification problem).  \(y\) could be one element (univariate problem, e. g. the salaries of employees in the company), or a vector \(Y\) of elements (multivariate statistics). Actually many of the common techniques in multivariate analysis (ordination and clustering, for instance) use unsupervised learning algorithms (e. g. PCA). The term dependent variable is also used to refer to the outcome variable, under the hypothesis often drawn in statistics that this variables does not depend on the value of other variables by a mathematical function. Independent variables: It is used to refer to the variables that should not depend on other variables in the scope of the experiment, and that are used as predictor variables, as it is assumed a relationship does exist between the outcome variable and those. A performance measure: How well does perform your model ?How does it compare to another model ?To draw such comparisons you need to specify a performance measure. A fitness function is a function that returns an integer value for how good your model is. For traditional ML algorithms, we will use what we call a loss function. Similarly, the loss function measures how bad your model is on predicting one data point. It could be a quadractic loss function (squared difference between the real and predicted value):\(L(Y, f(X)) = (y - \hat{f}(X))^2\) (nice as it is differentiable), indicative loss function (0/1), absolute difference loss function, or other. Actually, more generally, a loss function can show how close an estimate is from its corresponding estimand (quantity of interest we try to estimate). Then, it could be how close an estimate $\hat{\beta}$ of the parameter $\beta$ is close to $\beta$ itself. Or it could be how close a model prediction $ \hat{f}(X) $ is close to the true observation y (e. g. MSE for an predictor, MSE for an estimator) given an single input vector (of features \(X\)), which assign the prediction \(\hat{y}\). The risk function, in a frequentist statistical theory, is the expected loss i. e. the averaging over all of the loss functions. It then describes how bad your model is on the set of data. Hence the closer the predictions match the real expected / true value, the lower the prediction errors are, and then the lower the cost functions gets, so is the risk function. We then seek to minimize the risk function. It is often nice to differentiate, if possible, such risk function over the model parameters, so to see how changing one parameter or the other could possibly minimize the risk function. Note: Sometimes cost function is used as synonym of loss function, sometimes as the risk one. Hence you should always read the underlying equation in a paper to ascertain of the definition one use. training vs test sets: If we were to preprocess data and later train a model ‚Äî that could be hyperparametrized ‚Äî on these data, and finally compute a risk function applied on the model predictions for these same data versus the observed values, we could then be tempted to lower the value returned by the risk function by changing our model hyperparameters or changing the way we processed data (this could include changing the data representation of some input features, handling of outliers, handling of missing data, feature selection and feature engineering). That would be such a bad idea though: how can one ensure the model will perform any better on a another sample from the population, so to say: generalize well to other inputs and probably unseed data from the generation process ? In order to mitigate this, you split the main dataset in train and test datasets.  The data processing decisions and training of the model will be performed on the training dataset.  An unbiased evaluation of the trained model (trained on the training dataset) will be raised by applying the risk function on a test set i. e. predicted outcome values on new, possibly unseen data from the test set will be compared to the observed outcome values from this same test set. This enables us to check how well does the model actually perform on new data in a supervised learning framework. Supervised vs Unsupervised Learning: A supervised machine learning alorigthm makes used of the presence of the outcome variable to guide the learning process (Element of Statistical Analysis Book). An unsupervised machine learning algorithm finds patterns in the data with no pre-existing **labels or outcome variable used for guidance in the learning process. Taking one approach or the other depends on your use case (making prediction vs trying to get new insights of your data using ML). Although splitting data into training and testing sets is mainly granted for supervised problems, unsupervised problems and algorithms can also benefit from this approach A base scenario in a Supervised Learning problem: This example should be fully understandable after reading the preceding questions. I directly quote this example framework from Elements of statistical Learning:  In a typical scenario, we have an outcome measurement, usually quantitative (such as a stock price) or categorical (such as yes heart attack/no heart attack), that we wish to predict based on a set of features (such as diet and clinical measurements). We have a training set of data, in which we observe the outcome and feature measurements for a set of observations (such as people). Using this data we build a prediction model, or learner, which will enable us to predict the outcome for new unseen objects. A good learner is one that accurately predicts such an outcome. Modelling: Linear-Regression: "
    }, {
    "id": 12,
    "url": "http://localhost:4000/some-functional-programing-exercices/",
    "title": "Some functional programming exercices",
    "body": "2020/09/14 - Some exercices following tutorial Introduction to functional programming to make you more comfortable with the concepts. Exo1: Let‚Äôs create a Data Science pipeline of generators üòâ: Let‚Äôs say we have 1000 data points generated using range(1000) to process through a set of functions. We would want to pass those data inputs to multiple functions so that the output of the one becomes the input of the other. This is also named a pipeline.  Example:range(1000) --&gt; FUNCTION1 ---&gt; intermediate_output1 ---&gt; FUNCTION2 --&gt; intermediate_output2 --&gt; FUNCTION3 in terms of code this would look like this: function3(function2(function1(range(1000)))) As the number of processing functions grows, it becomes less ‚Äúclean‚Äù and readible. we would prefer to build a function set_pipeline which would result in the following signature: set_pipeline(inputs, function1, function2, . . . ) What‚Äôs your strategy ? Hint: think about functools. reduce Define 3 generators functions: 1.  one that just multiply by 2 one that power by 2 one that divide by 52.  use those generators in the set_pipeline function you defined earlierExo2: Create a range with decimal increment: Create a generator function which gives you the behavior of range(start, stop, step) with step that could be a float try:  range(0,5,0. 2)except Exception as e:  print(e)'float' object cannot be interpreted as an integerExo3 : Counting letter occurences in a large file: Generate a 10Mb file using this command:base64 /dev/urandom | head -c 10000000 &gt; file. txt    Create the function:read_large_file(big_file, block_size=10000)which reads a large file by chunks. A chunk of size 1 equals one line of the file.     Create a generator function that stored cumulated occurences of each letter over the passing chunks.  "
    }, {
    "id": 13,
    "url": "http://localhost:4000/pandas-exercices/",
    "title": "Some Pandas exercices",
    "body": "2020/09/14 - Some exercices following tutorial Discover Pandas to make you more comfortable with the concepts. SendTo: contact &lt; at &gt;  lucbertin  &lt; dot &gt; com Subject: PANDAS - EXERCICES1 - &lt;SCHOOL&gt; - &lt;FIRSTNAMES LASTNAMES&gt; CC: your teammates‚Äô email if anyContent: A Jupyter Notebook converted in HTML file Base de donn√©es accidents corporels de la circulationdata. gouv est une plateforme de diffusion de donn√©es publiques de l‚Äô√âtat fran√ßais lanc√©e en 2011.  data. gouv. fr est d√©velopp√© par Etalab, une mission plac√©e sous l‚Äôautorit√© du Premier ministre. Pour cet exercice nous allons utiliser quelques donn√©es tabulaires (format CSV) sur les accidents corporels li√©s de la circulation. Voici les 3 url vers les CSV correspondants que nous allons exploiter. url_usagers2017 =  https://static. data. gouv. fr/resources/base-de-donnees-accidents-corporels-de-la-circulation/20180927-111153/usagers-2017. csv url_lieux2017 =  https://static. data. gouv. fr/resources/base-de-donnees-accidents-corporels-de-la-circulation/20180927-111131/lieux-2017. csv url_caracteristiques2017 =  https://static. data. gouv. fr/resources/base-de-donnees-accidents-corporels-de-la-circulation/20180927-111012/caracteristiques-2017. csv 1. ‚Ä¢‚Ä¢‚Ä¢ Open the CSVs whose urls are given above, store the DataFrames in variables usagers2017, lieux2017, caracteristiques2017. : 2. ‚Ä¢‚Ä¢‚Ä¢ Show the 10 first lines of usagers2017: 3. ‚Ä¢‚Ä¢‚Ä¢ Show the 10 last lines of caracteristiques2017: 4. ‚Ä¢‚Ä¢‚Ä¢ How many lines does caracteristiques2017 contain ?: 5. ‚Ä¢‚Ä¢‚Ä¢ How many column does caracteristiques2017 contain ?: 6. ‚Ä¢‚Ä¢‚Ä¢ Show the dtype of each column of usagers2017. Same for caracteristiques2017. : 7. ‚Ä¢‚Ä¢‚Ä¢ Does Num_Acc in usager2017 contain duplicated values ? What about Num_Acc in caracteristiques2017 ? Hint: duplicated()‚Ä¶: 8. ‚Ä¢‚Ä¢‚Ä¢ Conclude on the type of relationship if we were to join catacteristiques2017 and usagers2017 on Num_Acc ( one-to-one? one-to-many? many-to-many?): 9. ‚Ä¢‚Ä¢‚Ä¢ Replace all values ‚Äú1‚Äù and ‚Äú2‚Äù in column sexe by Homme and Femme: 10. ‚Ä¢‚Ä¢‚Ä¢ Show women who had experienced accidents. : 11. ‚Ä¢‚Ä¢‚Ä¢ Replace each integers in grav (gravit√© de l‚Äôaccident) column by their corresponding mapping. : 		1 - Indemne		2 - Tu√©		3 - Bless√© hospitalis√© 		4 - Bless√© l√©ger12. ‚Ä¢‚Ä¢‚Ä¢ Same for catu (cat√©gorie d‚Äôusagers) column: 		1 - Conducteur		2 - Passager		3 - Pi√©ton		4 - Pi√©ton en roller ou en trottinette		99 - Autre v√©hicule13. ‚Ä¢‚Ä¢‚Ä¢ Show the counts for each distinct values in grav. : 14. ‚Ä¢‚Ä¢‚Ä¢ Plot it. : 15. ‚Ä¢‚Ä¢‚Ä¢ Show the counts for each distinct values in catu. : 16. ‚Ä¢‚Ä¢‚Ä¢ Find women who had mild accidents (‚ÄúIndemne‚Äù or ‚ÄúBless√© l√©ger‚Äù, but not more severe!). : Hint: you can use masking and save in an intermediate variable for clean code. 17. ‚Ä¢‚Ä¢‚Ä¢ Show the number of accidents by sexe AND gravity. : 18. ‚Ä¢‚Ä¢‚Ä¢ Using GroupBy19. Using a Pivot Table20. ‚Ä¢‚Ä¢‚Ä¢ Display it in the form of a stacked bar-chart. : 21. ‚Ä¢‚Ä¢‚Ä¢ Do a merge between usagers2017 and caracteristiques2017 on Num_Acc. : 22. Is there any new value in Num_Acc in the final merged table compared to either of table that has been used for merging ? (e. g. does Num_acc has a value that does not exist in usagers2017 but does exist in caracteristiques2017, or the other way around): Hint: DataFrame. equals(other)  This function allows two Series or DataFrames to be compared against each other to see if they have the same shape and elements 23. ‚Ä¢‚Ä¢‚Ä¢ Count missing values in each column of caracteristiques2017. Hint: . isnull(): 24. Filter the results only by taking the columns having more than 0 missing values + sorted by decreasing number of them. : 25. Show the same number of missing values as a pourcentage of the total number of values (lines). : 26. ‚Ä¢‚Ä¢‚Ä¢ Select the accidents who took place in Paris county (d√©partement &lt;=&gt; ‚Äú750‚Äù in the table): 27. ‚Ä¢‚Ä¢‚Ä¢ Plot the map/the maps of accidents by gravity in Paris county. : 28. Plot a graph that ‚Äúshows graphically‚Äù the importance of missing values in each column of the dataset. : Let‚Äôs play with the dates: 29. Rename the columns::  ‚Äòjour‚Äô as ‚Äòday‚Äô ‚Äòmois‚Äô as ‚Äòmonth‚Äô ‚Äòan‚Äô  as ‚Äòyear‚Äô30. Add ‚Äò20‚Äô to each element in the lately renamed year column, (e. g. : 2017) so to be an understandable year format for pd. to_datetime. : 31. Create a date column taking into account the year, month, and day from question29 and using pd. to_datetime in question30. : 32. Plot the daily death trends during the entire year. : "
    }, {
    "id": 14,
    "url": "http://localhost:4000/discover-pandas/",
    "title": "Discover Pandas",
    "body": "2020/09/10 - Why Pandas ?To create a machine learning model, we need to apply the underlying algorithm on some training data (more on this in Lecture 5). For this to work, we need to have a specific data structure to pass as input. Most traditional ML models require a 2D data-structure, just like a matrix. A numpy. array can be used for that purpose. Each row define an observation (more on this in Lecture 5), types of observations might depend on our designed problem. Each column display a caracteristic for each of these observations. Now, imagine such 2D data structure, maybe you would want to first name your columns and rows, analogously to a spreadsheet or SQL table, then inspect your data, handle missing values, do some processing on it (e. g. retrieve number of streets out of the street name), combine with other related, 2D, data from different sources, quickly perform descriptive statistics, do some computations on columns, on rows, or even within groups of observations sharing some common arbitrary caracteristic, quickly display trends from your computations. Also, dealing with initially less structured, clean and complete data, consists in most of the time spent by the data scientist. Sometimes the data you‚Äôre being given doesn‚Äôt have such 2D representation and you would want to have some helpers functions to perform the conversion. In either cases, Pandas package and its DataFrame object comes in handy. Three important Pandas‚Äô data-structuresFrom the pandas docs, which give a nice overview of the package:  pandas. DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet. It got rows and columns‚Äô labels (pandas. Index objects). Each column is a pandas. Series. Pandas is built on top of Numpy, hence sharing some optimizations from the latter, as well as closely related API. In the rest of this tutorial we will mainly work on the DataFrame class, although we first need to introduce the 2 other core data structures mentioned sooner: the Series and the Index, as they are each constitutive of DataFrame and the former share also similarly named methods and behaviors with the DataFrame class. Series: Definition: one-dimensional array of indexed data. pd. Series([3,2,1])0  31  22  1dtype: int64with explicit index definition ! Example: serie_1 = pd. Series([3,2,1], index=[93,129, 219394])serie_193    3129    2219394  1dtype: int64serie_1. indexInt64Index([93, 129, 219394], dtype='int64')Series as a dictionnary-like object: A dictionnary-like, object with possible keys index repetition. serie = pd. Series([3,2,1], index=[ ren√© ,  ren√© ,  jean ])We display a series. serieren√©  3ren√©  2jean  1dtype: int64We can show the values, a numpy typed array. serie. valuesarray([3, 2, 1])and show the keys index ! serie. indexIndex(['ren√©', 'ren√©', 'jean'], dtype='object')Here the 4 basic dict operations work seamlessly the same for a Series.  Access by key index:serie['ren√©']ren√©  3ren√©  2dtype: int64 Set a new key index:value pairserie['joseph'] = 5 Change a value for a given key index. serie['ren√©'] = 4Notice the broadcoasting of the integer here in case of multiple same index for the given value. serieren√©   4ren√©   4jean   1joseph  5dtype: int64You can also pass a sequence of elements with a matching length with the index multiplicity number. serie['ren√©'] = [4,3]serieren√©   4ren√©   3jean   1joseph  5dtype: int64 delete a key index:value pairdel serie[ ren√© ]seriejean   1joseph  5dtype: int64You can also do lookups on indexes, using the same syntax as for dict keys. print('ren√©' in serie) #in the indexes, same syntax as for dict keysprint( jean  in serie)FalseTrue When index is unique, pandas use a hashtable just like dicts : O(1).  When index is non-unique and sorted, pandas use binary search O(logN) When index is non-unique and not-sorted, pandas need to check all the keys just like a list look-up: O(N). You can also do some other things you would not be able using dict primitive, like slicing. serie[0:4:2] # indexing: not possible in a simple dict jean  1dtype: int64The similarity with dict is although so close you can use a dict in the pd. Series constructor. This automatically create the indexes from the keys in the dict and the values from the corresponding values in the dict. Note: the index:value order in the newly created pd. Series can be slightly different for different concomittent versions of Python and Pandas. Pandas &gt;= 0. 23 conserve the insertion order from the underlying dict argument, although you still Python versions above 3. 6 to maintain dict keys‚Äôinsertion order (use OrderedDict for versions before). test = pd. Series(dict(zip([ ea , fzf , aeif ], [2,3,2])))# with zip or using a dicttest2 = pd. Series({ ea :2,  fzf :3,  aeif :2}, index=[ ea ])testaeif  2ea   2fzf   3dtype: int64test2ea  2dtype: int64If multiple different types reside in a Series, all of the data will get upcasted to a dtype that accommodates all of the data involved. test2 = pd. Series({ ea :2,  fzf :3,  aeif : zf }, index=[ ea ])test2ea  2dtype: objecttest2 = pd. Series({ ea :2,  fzf :3,  aeif :2. 4}, index=[ ea ])test2ea  2. 0dtype: float64dtype=object means that the best common type infered representation for the contents of the pd. Series is ‚Äúa Python object‚Äù. (Everything is object in Python see Lecture 2!). This also means a performance drop, any operations on the data will be done at the Python level. Python for-loops will be performed, checking the actual type of each ‚Äòobject‚Äô for the operation one want to perform on the input vector (1) Selection in Series: Masking: A Series mask is a Series as a collection of indexes:boolean-values, which can be later used to filter-out elements from another Series, based on the falsy evaluated values for each index in the former. Performing a comparison on a Series creates a mask of same shape, with indexes from the original array along with true or false results originating from the element-wise comparisons from your original comparison expression. (test&gt;2)aeif  Falseea   Falsefzf   Truedtype: bool(test&lt;4)aeif  Trueea   Truefzf   Truedtype: boolSince numpy arrays support vectorized calculations (more on that later) and does not contain arbitrary unlike typed elements as for lists, you can use the &amp; bitwise operator, a element-wise version of the logical and. # not  and  but  &amp;  : &amp; operator is a bitwise  and (test&gt;2) &amp; (test &lt; 4) aeif  Falseea   Falsefzf   Truedtype: boolYou can see the result is still a Series, but this time of boolean values (check the dtype !) type((test&gt;2) &amp; (test &lt; 4) )pandas. core. series. SeriesWe can later keep it in as a ‚Äòmask‚Äô variable, it is particularly useful when a lot comparisons should be given a meaningful name (e. g. mask variable here could be lower4greater2 for example). # mask ( the last expression whose result is an pd. Serie stored in the variable mask)mask = (test&gt;2) &amp; (test &lt; 4)test[mask]fzf  3dtype: int64Indexing: We can also select a value for a given index, as highlighted in the introductory section on Series. Although we should take extra care when doing so: the previous notation, e. g. serie['ren√©'], makes use of the names of the indexes we explicitly defined earlier. Fancy indexing: This is just a fancy word for selecting multiple indexes, provisioning a list of indexes. # fancy indexing (&lt;=&gt; selecting multiple indexes using a list of indexes)test[[ ea ,  fzf ]]ea   2fzf  3dtype: int64Slicing and the confusion of explicit vs implicit indexes: This is another word for selecting a subset of an original array (or even list), based on an interval constructed using a start, stop and [step] elements. For Series, we can slice a Series by 2 ways:  using the names we explicitly defined (or defaulted as integer-based indexes creation) for the index at Series creation time, for start and stop values.    using implicit start and stop values for the index. By implicit we mean integers which define the order of appearance of the index itself, taking caution that the first element is of index 0 in Python.   Explicit index slicing:# (using the labels of the indexes)test[ aeif :  fzf ]aeif  2ea   2fzf   3dtype: int64 Implicit index slicing (using integers i. e. order of appearance):test[0: 2]aeif  2ea   2dtype: int64   using explicit indexes while slicing include the final index     using implicit index in slicing exclude the final index  What about i defined at creation time a Series with integer index values and i want to slice them ? üôÑ serie2 = pd. Series({1:4, 2:8, 3:51})serie21   42   83  51dtype: int64Here you see that for indexing, the explicit index is used, i. e. ‚Äúelement of index defined as 3‚Äù, but for slicing it is takes elements from the 2nd indexed element to the 3rd, excluded, indexed element, no matter what value of index the elements are. serie2[3] # indexing: defaults to select explicit index / with label 3serie2[2:3] # slicing: defaults to select implicit indexes513  51dtype: int64Loc and Iloc accessors: These accessors give a great alternative from default, albeit confusing, slicing behaviors with respect to the indexes‚Äôvalues. Using loc property:This forces indexing and slicing using the explicitly defined index values: serie2. loc[1] # indexing: on explicit indexserie2. loc[2:3] # slicing: on explicit index42   83  51dtype: int64Using iloc property:This forces indexing and slicing using implicit indexes i. e. order of appearance of the elements from 0 (1st element) to n-1 (last one). This also means you will never use something else in iloc accessors than integers. serie2. iloc[1] # indexing: on implicit indexserie2. iloc[2:3] # slicing: on implicit index83  51dtype: int64serie2. loc[1:5] # slicing: explicit index serie2. iloc[1:5] # slicing: implicit index 1   42   83  51dtype: int642   83  51dtype: int64serie2. loc[[1,2]] # fancy indexingserie2. iloc[[1,2]] # fancy indexing 1  42  8dtype: int642   83  51dtype: int64dtypes: A serie being an-indexed array, it then maintain a well-known implementation feature from numpythat infers about the overall representation of the data within the array: the dtype. Recall that infering the data representation which accomodates all elements in the array is what enables, in case, for example, of numerical data (integers, float), to not only stored the values as C integers (avoiding the overhead introduced by Python primitive types) but also to perform efficient operations on the C for-loop level, as it is not required to dynamically type-check every single elements of the array and find which function to dispatch accordingly. %timeit np. arange(1E6, dtype= int ). sum()1. 14 ms ¬± 142 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1000 loops each)%timeit np. arange(1E6, dtype= float ). sum()1. 25 ms ¬± 17. 7 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1000 loops each)s = pd. Series(['The', 3, 'brown', 'fox'])s*20    TheThe1       62  brownbrown3    foxfoxdtype: objects. valuesarray(['The', 3, 'brown', 'fox'], dtype=object) Link. Creating an array with dtype=object is different. The memory taken by the array now is filled with pointers to Python objects which are being stored elsewhere in memory (much like a Python list is really just a list of pointers to objects, not the objects themselves). %timeit np. arange(1E6, dtype= object ). sum()77. 8 ms ¬± 4. 15 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)Index object: can be sliced or indexed: ‚Ä¶just like an array, because it is indeed an one-dimensional array. serie2. index[0]1serie2. index[:2]Int64Index([1, 2], dtype='int64')have sets‚Äô operations: By this we mean it does have common bitwise operatoin serie2. index &amp; {1, 5}Int64Index([1], dtype='int64')serie2. index ^ {1,5}Int64Index([2, 3, 5], dtype='int64')are immutables: serie2. index[0]=18Traceback (most recent call last): File  &lt;ipython-input-1096-707f9cda8675&gt; , line 1, in &lt;module&gt;  serie2. index[0]=18 File  /Users/lucbertin/. pyenv/versions/3. 5. 7/lib/python3. 5/site-packages/pandas/core/indexes/base. py , line 4260, in __setitem__  raise TypeError( Index does not support mutable operations )TypeError: Index does not support mutable operationsDataFrame: The ‚Äúmain thing‚Äù of this lecture that we are going to use intensively in the rest of this lecture:    sequence of ‚Äúaligned‚Äù Series objects (sharing the same indexes / like an Excel file).     each Series object is a column.     Hence pd. DataFrame can be seen as dictionnary of Series objects.     Flexible rows and columns‚Äô labels (Index objects for both).  Construction: serie1 = pd. Series({ Luc : 25,  Corentin :29,  Ren√© : 40})serie2 = pd. Series({ Ren√© :  100% ,  Corentin :  25% ,  Luc :  20% })# dictionnary of pd. Seriesdf = pd. DataFrame({ note : serie1,           charge_de_travail : serie2})df         charge_de_travail   note         Corentin   25%   29       Luc   20%   25       Ren√©   100%   40   # index objects on both columns and rowsdf. indexdf. columnsIndex(['Corentin', 'Luc', 'Ren√©'], dtype='object')Index(['charge_de_travail', 'note'], dtype='object') If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index. df2 = pd. DataFrame({ note : serie1,            charge_de_travail : serie2},          index=[ Corentin ,  Luc ,  Julie ],          columns=[ note ,  autre ])df2 # filled with NaN ( Not A Number ) # when no value exist for the given (row_index, column_index)         note   autre         Corentin   29. 0   NaN       Luc   25. 0   NaN       Julie   NaN   NaN   The DataFrame can be constructed using a list of dictionary.  each dict element is a row.  each key of each dict refers to a column. df2 = pd. DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])df2         a   b   c         0   1. 0   2   NaN       1   NaN   3   4. 0   pd. DataFrame([(1, 1, 3), (1, 2,4), (1,1,1)],       columns=[ a ,  b ,  c ],      index=[ Jean ,  Jacques ,  Ren√© ])         a   b   c         Jean   1   1   3       Jacques   1   2   4       Ren√©   1   1   1   You can also create a DataFrame by using pandas methods for reading supported file format, e. g. using pd. read_csv method. Shape property: df. shape(3, 2)shape: tuple of the number of elements with respect to each dimension    For a 1D array, the shape would be (n,) where n is the number of elements in your array.     For a 2D array, the shape would be (n,m) where n is the number of rows and m is the number of columns in your array  accessing a column/Serie by key : Accessing columns: As DataFrame is seen like a dictionary of Series / columns, you can access one of them using the corresponding key column‚Äôindex ! df['note']Corentin  29Luc     25Ren√©    40Name: note, dtype: int64Using the attribute notation is not advised especially for assignements as some methods or attributes of the same name already exist in the DataFrame class‚Äô own namespace. df. noteCorentin  29Luc     25Ren√©    40Name: note, dtype: int64Indexing or Slicing: Indexing works the same way as for Series, but you have to account this time for the second dimension df. loc_or_iloc[ dim1 = rows, dim2 = columns] df. iloc[:3, :1] # implicit indexing         charge_de_travail         Corentin   25%       Luc   20%       Ren√©   100%   columns slicing/indexing is optional here, without specifying it, you select only rows df. iloc[:3]         charge_de_travail   note         Corentin   25%   29       Luc   20%   25       Ren√©   100%   40   df. loc[ Corentin : Luc , charge_de_travail : note ] # explicit indexing         charge_de_travail   note         Corentin   25%   29       Luc   20%   25   same thing here, only rows selected df. loc[: Corentin ]         charge_de_travail   note         Corentin   25%   29   df. loc[[ Corentin ,  Luc ], :] # mixing slicing and fancy indexing         charge_de_travail   note         Corentin   25%   29       Luc   20%   25   Something to mention here: by default, without using accessors like loc and iloc, indexing or fancy indexing directly df, performs the indexing on its columns. df[[ charge_de_travail ]] # indexing directly df defaults to columns         charge_de_travail         Corentin   25%       Luc   20%       Ren√©   100%   Finally, of course you can set a new value for an element on some (row_index, column_index) using either of those accessors: df. iloc[0,2] = np. nanMasking: You can also use masking here and draw comparisons on a Dataframe level (e. g. df &gt; 3), or on Series/column level, e. g. df[ sexe ] ==  Homme , df[ age ] &gt; 18. In the first case, the resulting object will be a DataFrame filled with boolean values. In the second one, as before, a Series with boolean values. A difference here using Series as a mask is that filtering a DataFrame using only true evaluated values from a Series (a 1D indexed-array then), keeps the entire rows as you may have multiple aligned Series/ columns for one given Index (with a true value). Slicing using slice notation (::), or masking is performed on rows by default. mask = df[ charge_de_travail ]== 25%  maskCorentin   TrueLuc     FalseRen√©    FalseName: charge_de_travail, dtype: boolNote that the Series-like mask, having the explictly defined indexes from the original one, you can still use df. loc upon filtering. df[mask] # masking directly df is operated on rows# same as df. loc[mask]         charge_de_travail   note         Corentin   25%   29   df[:3] # slicing directly df is operated on rows         charge_de_travail   note         Corentin   25%   29       Luc   20%   25       Ren√©   100%   40   Operations between DataFrames: What about multiplying all elements from a DataFrame by 2?What about adding 2 DataFrame ? We first need to distinct 2 types of operations into binary and unary operations:  3 - 2 &lt;=&gt; substract(3,2) &lt;=&gt; binary operation (2 inputs) -2 &lt;=&gt; neg(2) &lt;=&gt; unary operation (one input) sin(2) &lt;=&gt; unary operation (one input)in Pandas :  unary operations on dfs elements preserve the indexes.  binary operations on elements from 2 dfs align the operations on the indexes.  These behaviors come from numpy ufuncs (universal functions i. e. vectorized functions i. e. that take the whole vector as input, applying the function element-wise) which can be used for DataFramess too. import numpy as np rng = np. random. RandomState(42) # for reproducibilitydata = rng. randint(0,10, (3,4)) # creating an array of random integer valuesdf = pd. DataFrame(data)df         0   1   2   3         0   6   3   7   4       1   6   9   2   6       2   7   4   3   7   df2 = pd. DataFrame(rng. randint(0,10, (4,4)))df2         0   1   2   3         0   7   2   5   4       1   1   7   5   1       2   4   0   9   5       3   8   0   9   2   We will use for the later example of summation between 2 DataFrames, reindex just to rearranged indexes of df2 (this does not change the association indexed-value !) df2 = df2. reindex([1,0,2,3]) #just to show rearranged indexes (does not change the association with the indexed data)df2         0   1   2   3         1   1   7   5   1       0   7   2   5   4       2   4   0   9   5       3   8   0   9   2   df + df2         0   1   2   3         0   13. 0   5. 0   12. 0   8. 0       1   7. 0   16. 0   7. 0   7. 0       2   11. 0   4. 0   12. 0   12. 0       3   NaN   NaN   NaN   NaN   on line of index 0, 7+6 = 13 which shows indexes had been aligned during the binary operation also notice the union of the indices during the binary operation. If one may not exist in either of the dataframes and the result can‚Äôt be evalutated, NaN fill the concerned entries df. __add__(df2, fill_value=25) # used in the binary operation 25+8 = 33)         0   1   2   3         0   13. 0   5. 0   12. 0   8. 0       1   7. 0   16. 0   7. 0   7. 0       2   11. 0   4. 0   12. 0   12. 0       3   33. 0   25. 0   34. 0   27. 0   Operations between Series and Dataframe: Performing an operation between a Serie and a DataFrame implies performing an operation between data structures of different shapes, hence implying numpy broadcasting. From the Numpy docs:  Broadcasting is how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is ‚Äúbroadcast‚Äù across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python The only requirement for broadcasting is a way aligning array dimensions such that either :  aligned dimensions are equal (so that operations are done on an element-by-element basis from 2 arrays of same shape) one of the aligned dimensions is 1 (in other words, dimensions with size 1 are stretched or ‚Äúcopied‚Äù to match the dimension of the other array)Operations between pandas. Series and pandas. DataFram then respect the numpy broadcasting rules:  If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side. ‚Äô (2) df. shape, df. iloc[1]. shape, df. iloc[1][np. newaxis, :]. shape((3, 4), (4,), (1, 4))dfdf. iloc[1]         0   1   2   3         0   6   3   7   4       1   6   9   2   6       2   7   4   3   7   0  61  92  23  6Name: 1, dtype: int64df - df. iloc[1] #row-wise (1,4) copied other 3 times =&gt; (3,4)         0   1   2   3         0   0   -6   5   -2       1   0   0   0   0       2   1   -5   1   1   df - df. iloc[1]. sample(4) # again: kept the index alignements during computation         0   1   2   3         0   0   -6   5   -2       1   0   0   0   0       2   1   -5   1   1   if you want to do it columnwise and not row wise df. __sub__(df. iloc[1], axis=0) # caution, the indexes operations will be based on the column indexes         0   1   2   3         0   0. 0   -3. 0   1. 0   -2. 0       1   -3. 0   0. 0   -7. 0   -3. 0       2   5. 0   2. 0   1. 0   5. 0       3   NaN   NaN   NaN   NaN   df. columns = [ a , b ,0, d ]df         a   b   0   d         0   6   3   7   4       1   6   9   2   6       2   7   4   3   7   df. iloc[1]a  6b  90  2d  6Name: 1, dtype: int64df. __sub__(df. iloc[1], axis=0) # based on the column indexes# only 0 match with one of the column index label         a   b   0   d         0   4. 0   1. 0   5. 0   2. 0       1   NaN   NaN   NaN   NaN       2   NaN   NaN   NaN   NaN       a   NaN   NaN   NaN   NaN       b   NaN   NaN   NaN   NaN       d   NaN   NaN   NaN   NaN   Close API with Series and numpy: The DataFrame object, constituted of Series object and being also an ‚Äòenhanced version‚Äô of a numpy array, no wonder why a major part of the API for one can be reused for the other. Here are just example of reused methods or properties (you‚Äôve seen other ones in the course like loc and iloc for instance): df[0]. shape, df. shape((3,), (3, 4))df2 = df - pd. DataFrame([(1,2), (4,5), (9,19)], columns=[ a , b ])df2         0   a   b   d         0   NaN   5   1   NaN       1   NaN   2   4   NaN       2   NaN   -2   -15   NaN   print(df. dtypes)print(df2. dtypes) # NaN is a floating-point value, # hence the Series embedding it gets its dtype upcasted to float (if it were an int)# this pd. Series supports fast operations contrarily to a Series of dtype=object# because Python needs to type check dynamically every timea     int64b     int640     int64d     int64notes  objectdtype: objectName     objectid_account  objectid_client   objectdtype: objectManaging missing values: This is a real asset of pandas Dataframe in comparison to numpy(which would find other strategies for handling missing values during computations, using classes like ‚Äúmasked arrays‚Äù). Managing missing values, either by dropping or imputing them based on some type of criteria, is an crucial step you should always document during your data scientist experiments. It is always a hot spot in areas such as Statistics or Machine Learning. A mishandling of NA values can definitely have an impact on your results or greatly lower your model performance trained on the data. pd. Series([2, np. nan]). isnull()0  False1   Truedtype: booldf2. iloc[0,2] = np. nandf2df2. isnull()         0   a   b   d         0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN            0   a   b   d         0   True   False   True   True       1   True   False   False   True       2   True   False   False   True   pd. Series([2, np. nan]). dropna()0  2. 0dtype: float64df2df2. dropna(axis=1) # drop a column when contains one NA valuedf2. dropna(axis=0) # drop a row when contains one NA valuedf2. dropna(axis=1, how= all ) # drop a column when contains all NA valuedf2. dropna(axis=1, thresh=3) # drop a column if below 3 non-NA value         0   a   b   d         0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN            a         0   5       1   2       2   -2            0   a   b   d              a   b         0   5   NaN       1   2   4. 0       2   -2   -15. 0            a         0   5       1   2       2   -2   df2df2. fillna(value=2) #fill NA with specified value# fill NA backwards # i. e. using the following non-null element# to fill preceding NA ones# defaults on rows basisdf2. fillna(method= bfill ) df2. fillna(method= bfill , axis=1) # on column basis         0   a   b   d         0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN            0   a   b   d         0   2. 0   5   2. 0   2. 0       1   2. 0   2   4. 0   2. 0       2   2. 0   -2   -15. 0   2. 0            0   a   b   d         0   NaN   5   4. 0   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN            0   a   b   d         0   5. 0   5. 0   NaN   NaN       1   2. 0   2. 0   4. 0   NaN       2   -2. 0   -2. 0   -15. 0   NaN   MultiIndex: data = {('group1', 'Luc'): 18,    ('group2', 'Jean'): 23,    ('group1', 'Seb'): 17,    ('group1', 'Ren√©'): 4,    ('group2', 'Alex'): 4,    ('group3', 'Sophie'): 25,    ('group2', 'Camille'): 2 }serie = pd. Series(data)seriegroup1 Luc    18    Ren√©    4    Seb    17group2 Alex    4    Camille   2    Jean    23group3 Sophie   25dtype: int64serie[:, Luc ]group1  18dtype: int64serie[ group1 ]Luc   18Ren√©   4Seb   17dtype: int64serie[serie&gt;=18]group1 Luc    18group2 Jean   23group3 Sophie  25dtype: int64# creating the multi-index using cartesian productindex = pd. MultiIndex. from_arrays([['group1', 'a', 'b', 'b'], [ Luc , 2, 1, 2]])serie. reindex(index) # works for multi-index too !# Conform Series to new index with optional filling logic, placing# NA/NaN in locations having no value in the previous indexgroup1 Luc  18. 0a    2    NaNb    1    NaN    2    NaNdtype: float64# hierarchical indices and columnsindex = pd. MultiIndex. from_product([[2013, 2014], [1, 2]],                  names=['year', 'visit'])columns = pd. MultiIndex. from_product(  [['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],names=['subject', 'type'])# mock some datadata = np. round(np. random. randn(4, 6), 1)data[:, ::2] *= 10data += 37# create the DataFramehealth_data = pd. DataFrame(data, index=index, columns=columns) health_data         subject   Bob   Guido   Sue          type   HR   Temp   HR   Temp   HR   Temp       year   visit                           2013   1   52. 0   36. 4   38. 0   36. 6   32. 0   38. 1       2   28. 0   37. 7   47. 0   35. 4   50. 0   36. 4       2014   1   30. 0   37. 0   16. 0   36. 6   49. 0   37. 7       2   52. 0   36. 8   31. 0   35. 5   36. 0   37. 6   health_data. loc[:2013 , ( Bob )]         type   HR   Temp       year   visit               2013   1   52. 0   36. 4       2   28. 0   37. 7   #health_data. loc[(:,1),[ Bob ]] # can't use the tuple to define indexidx = pd. IndexSlicehealth_data. loc[idx[:, 1], idx[:, 'HR']]         subject   Bob   Guido   Sue          type   HR   HR   HR       year   visit                  2013   1   52. 0   38. 0   32. 0       2014   1   30. 0   16. 0   49. 0   Unstacking and Stacking: a matter of dimensionality: Creating a multiIndex rather than a simple Index is like creating an extra-dimension in our dataset. We can take for each year, a 2D sub-dataframe composed of Bob‚Äôs HR visits. This DataFrame hence can be seen as having 4 dimensions. we can go back and forth from a multi-index series to a dataframe using unstack, so that one of the index level occupies the extra dimension given by the transition to a DataFrame seriegroup1 Luc    18    Ren√©    4    Seb    17group2 Alex    4    Camille   2    Jean    23group3 Sophie   25dtype: int64serie. unstack() #level -1 by default = most inner one         Alex   Camille   Jean   Luc   Ren√©   Seb   Sophie         group1   NaN   NaN   NaN   18. 0   4. 0   17. 0   NaN       group2   4. 0   2. 0   23. 0   NaN   NaN   NaN   NaN       group3   NaN   NaN   NaN   NaN   NaN   NaN   25. 0   df3 = serie. unstack(level=0)df3         group1   group2   group3         Alex   NaN   4. 0   NaN       Camille   NaN   2. 0   NaN       Jean   NaN   23. 0   NaN       Luc   18. 0   NaN   NaN       Ren√©   4. 0   NaN   NaN       Seb   17. 0   NaN   NaN       Sophie   NaN   NaN   25. 0   # to reset the index and create it as a simple new column you can use reset_index()df3. reset_index()         index   group1   group2   group3         0   Alex   NaN   4. 0   NaN       1   Camille   NaN   2. 0   NaN       2   Jean   NaN   23. 0   NaN       3   Luc   18. 0   NaN   NaN       4   Ren√©   4. 0   NaN   NaN       5   Seb   17. 0   NaN   NaN       6   Sophie   NaN   NaN   25. 0   You can do some aggregation by index level (we are going to see this extensively on GroupBy section health_data. mean(level='year')health_data. mean(level='visit')health_data. mean(axis=1, level='type')      subject   Bob   Guido   Sue       type   HR   Temp   HR   Temp   HR   Temp       year                           2013   40. 0   37. 05   42. 5   36. 00   41. 0   37. 25       2014   41. 0   36. 90   23. 5   36. 05   42. 5   37. 65         subject   Bob   Guido   Sue       type   HR   Temp   HR   Temp   HR   Temp       visit                           1   41. 0   36. 70   27. 0   36. 60   40. 5   37. 9       2   40. 0   37. 25   39. 0   35. 45   43. 0   37. 0            type   HR   Temp       year   visit               2013   1   40. 666667   37. 033333       2   41. 666667   36. 500000       2014   1   31. 666667   37. 100000       2   39. 666667   36. 633333   Concatenating DataFrames: pd. concat is here for the rescue ! df1df2         0   a   b   d         0   2. 0   False   2. 0   2. 0       1   2. 0   False   0. 0   2. 0       2   2. 0   False   0. 0   2. 0            0   a   b   d         0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN   pd. concat([df1, df2], axis=0) # concatenate rows (default)pd. concat([df1, df2], axis=1) # concatenate columns (default)         0   a   b   d         0   2. 0   0   2. 0   2. 0       1   2. 0   0   0. 0   2. 0       2   2. 0   0   0. 0   2. 0       0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN            0   a   b   d   0   a   b   d         0   2. 0   False   2. 0   2. 0   NaN   5   NaN   NaN       1   2. 0   False   0. 0   2. 0   NaN   2   4. 0   NaN       2   2. 0   False   0. 0   2. 0   NaN   -2   -15. 0   NaN   the indices are preserved, even duplicated verify_integrity=True can check if index from each df are differents ignore_index=True just override the indexes after concatenation by a new integer one keys = [ source1 ,  source2 ] leave the indexes as is but create a new outer level from the 2 different sources/df of the data concatenated pd. concat([df1, df2], axis=0, keys=[ source1 ,  source2 ])            0   a   b   d         source1   0   2. 0   0   2. 0   2. 0       1   2. 0   0   0. 0   2. 0       2   2. 0   0   0. 0   2. 0       source2   0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN   join='inner' keeps only the columns in common from the concatenation df2[ note ] = 2df2         0   a   b   d   note         0   NaN   5   NaN   NaN   2       1   NaN   2   4. 0   NaN   2       2   NaN   -2   -15. 0   NaN   2   pd. concat([df1, df2], axis=0, join='inner')         0   a   b   d         0   2. 0   0   2. 0   2. 0       1   2. 0   0   0. 0   2. 0       2   2. 0   0   0. 0   2. 0       0   NaN   5   NaN   NaN       1   NaN   2   4. 0   NaN       2   NaN   -2   -15. 0   NaN   serie1serie2serie1. append(serie2)Corentin  29Luc     25Ren√©    40dtype: int64Corentin   25%Luc     20%Ren√©    100%dtype: objectCorentin   29Luc      25Ren√©     40Corentin   25%Luc     20%Ren√©    100%dtype: objectdf1. append(df2)/Users/lucbertin/. pyenv/versions/3. 5. 7/lib/python3. 5/site-packages/pandas/core/frame. py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future versionof pandas will change to not sort by default. To accept the future behavior, pass 'sort=False'. To retain the current behavior and silence the warning, pass 'sort=True'.  sort=sort,         0   a   b   d   note         0   2. 0   0   2. 0   2. 0   NaN       1   2. 0   0   0. 0   2. 0   NaN       2   2. 0   0   0. 0   2. 0   NaN       0   NaN   5   NaN   NaN   2. 0       1   NaN   2   4. 0   NaN   2. 0       2   NaN   -2   -15. 0   NaN   2. 0   Merging DataFrames: df_account = pd. DataFrame({'accountNumber': [ AC1 ,  AC2 ,  AC3 ,  AC4 ],          'Amount': [10000, 109300, 2984, 1999],          'Name': [ LIVRET A ,  Compte √âpargne Retraite ,  Quadretto ,  Compte Courant ]})df_client = pd. DataFrame({'id_account': [ AC1 ,  AC2 ,  AC3 ,  AC4 ,  AC5 ],          'Name': [ Luc ,  Ren√© ,  Jean ,  Jean ,  Joseph ],          'id_client': [ ID1099 ,  ID1091 ,  ID1018 ,  ID1018 ,  ID1021 ]})df_accountdf_client         Amount   Name   accountNumber         0   10000   LIVRET A   AC1       1   109300   Compte √âpargne Retraite   AC2       2   2984   Quadretto   AC3       3   1999   Compte Courant   AC4            Name   id_account   id_client         0   Luc   AC1   ID1099       1   Ren√©   AC2   ID1091       2   Jean   AC3   ID1018       3   Jean   AC4   ID1018       4   Joseph   AC5   ID1021   pd. merge(left=df_account, right=df_client,     left_on= accountNumber ,     right_on= id_account ,     how='inner')         Amount   Name_x   accountNumber   Name_y   id_account   id_client         0   10000   LIVRET A   AC1   Luc   AC1   ID1099       1   109300   Compte √âpargne Retraite   AC2   Ren√©   AC2   ID1091       2   2984   Quadretto   AC3   Jean   AC3   ID1018       3   1999   Compte Courant   AC4   Jean   AC4   ID1018   df_merged = pd. merge(left=df_account, right=df_client,     left_on= accountNumber ,     right_on= id_account ,     how='right',     suffixes=[ _account ,  _client ])df_merged         Amount   Name_account   accountNumber   Name_client   id_account   id_client         0   10000. 0   LIVRET A   AC1   Luc   AC1   ID1099       1   109300. 0   Compte √âpargne Retraite   AC2   Ren√©   AC2   ID1091       2   2984. 0   Quadretto   AC3   Jean   AC3   ID1018       3   1999. 0   Compte Courant   AC4   Jean   AC4   ID1018       4   NaN   NaN   NaN   Joseph   AC5   ID1021   # to drop the (same) column we have been merging ondf_merged. drop('id_account', axis=1)         Amount   Name_account   accountNumber   Name_client   id_client         0   10000. 0   LIVRET A   AC1   Luc   ID1099       1   109300. 0   Compte √âpargne Retraite   AC2   Ren√©   ID1091       2   2984. 0   Quadretto   AC3   Jean   ID1018       3   1999. 0   Compte Courant   AC4   Jean   ID1018       4   NaN   NaN   NaN   Joseph   ID1021   #df_notes[ eleve ] = (df_notes# . eleve# . astype( category )# . cat. rename_categories(#   new_categories=#    [ eleve{} . format(i) for i in range(df_notes. eleve. nunique())]# )#)Apply: For the following sections, we are going to use real world data of students‚Äôgrades from an exam I gave üòú The data has been anonymised to fit GDPR regulation. It has been retrieved by scrapping automatically the online web app that stores the results from each passed quizz. You will see along the way we will need to make multiple modifications to our original data. # !curl --help # option : -o, --output &lt;file&gt; # Write to file instead of stdout!curl https://raw. githubusercontent. com/Luc-Bertin/TDs_ESILV/master/td3_discover_pandas/notes_eleves. csv -o  notes. csv  % Total  % Received % Xferd Average Speed  Time  Time   Time Current                 Dload Upload  Total  Spent  Left Speed100 21979 100 21979  0   0 66805   0 --:--:-- --:--:-- --:--:-- 66805df_notes = pd. read_csv( notes. csv , index_col=0)# showing just the first n rowsdf_notes. head(5)# or the last n rowsdf_notes. tail(5)         eleve   note   groupe   quizz         0   eleve0   71,43 %   Unknown   td1       1   eleve1   100 %   Unknown   td1       2   eleve4   71,43 %   Unknown   td1       3   eleve6   42,86 %   Unknown   td1       4   eleve8   57,14 %   Unknown   td1            eleve   note   groupe   quizz         741   eleve174   100 %   ibo5   td3       742   eleve166   66,67 %   ibo5   td3       743   eleve176   83,33 %   ibo5   td3       744   eleve186   100 %   ibo5   td3       745   eleve196   66,67 %   ibo5   td3   On a Series object: Let‚Äôs define a function to be applied for each element of a column. def function(val):     A fonction to be applied on each element of a pandas DataFrame column / Series      # we need to return a value for each element computation  return val. upper()df_notes. eleve. apply(function) # the function applies on each value in the column0    ELEVE01    ELEVE12    ELEVE43    ELEVE64    ELEVE8     . . .  741  ELEVE174742  ELEVE166743  ELEVE176744  ELEVE186745  ELEVE196Name: eleve, Length: 746, dtype: objectbehind, apply is looping on each element of the column eleve and returning a value for each of them on a DataFrame object: We can also use the apply method on a DataFrame object, but we need to provide an axis. applied function won‚Äôt be fed a single column element this time but a Series. a Series whose index depends on the axis we choose ! df_notes         eleve   note   groupe   quizz         0   eleve0   71,43 %   Unknown   td1       1   eleve1   100 %   Unknown   td1       2   eleve4   71,43 %   Unknown   td1       3   eleve6   42,86 %   Unknown   td1       4   eleve8   57,14 %   Unknown   td1       . . .    . . .    . . .    . . .    . . .        741   eleve174   100 %   ibo5   td3       742   eleve166   66,67 %   ibo5   td3       743   eleve176   83,33 %   ibo5   td3       744   eleve186   100 %   ibo5   td3       745   eleve196   66,67 %   ibo5   td3   746 rows √ó 4 columns def function(row):     A fonction to be applied on each row of the DataFrame  i. e. each row is indeed a pandas. Series object   passed-in the applied function at each loop iteration.   We will need later on to use axis=1 for Series to be the rows       # having a full row we can do many things to create  if int( row[ eleve ][-1] ) % 2 == 0:    return  pair   return  impair df_notes. apply(function, axis=1)0    pair1   impair2    pair3    pair4    pair    . . .  741   pair742   pair743   pair744   pair745   pairLength: 746, dtype: objectdef function(row):     Another function on rows but returning a pandas. Series each time  i. e. then the final result will be a stack of pandas. Series along an axis or the other  i. e. &lt;=&gt; a DataFrame     if int( row[ eleve ][-1] ) % 2 == 0:    odd_or_even =  pair   odd_or_even =  impair     cut_note = row[ note ]. split(',')[0] # what precedes the comma  return pd. Series([ odd_or_even, cut_note], index=['odd_or_even', 'cut_note'])df_notes. apply(function, axis=1) # a pandas. Series for each row         odd_or_even   cut_note         0   impair   71       1   impair   100 %       2   impair   71       3   impair   42       4   impair   57       . . .    . . .    . . .        741   impair   100 %       742   impair   66       743   impair   83       744   impair   100 %       745   impair   66   746 rows √ó 2 columns To avoid having to define a loop we should use vectorized functions (we will talk about it later on). On integers (not the case here) use of vectorized functions can greatly improve computational speed. (C-loop) def function(col):     Another function on cols this time     try:    return sum([int(x[:1]) for x in col])  except:    return  can't sum on this col   #return pd. Series([ odd_or_even, cut_note], index=['odd_or_even', 'cut_note'])df_notes. apply(function, axis=0) # a pandas. Series for each coleleve   can't sum on this colnote            3053groupe  can't sum on this colquizz   can't sum on this coldtype: objectdf_notes. note. str[:1]. astype(float). sum()3053. 0Manipulating columns with strings: Back to the definition of a vectorized function: it is a function that applies on the whole sequence rather than each element as input. This is the case for numpy functions like np. mean, np. sum, np. std which apply on a numerically valued input array as a whole, so the loop is moved from the Python-level to the C one  Numeric types include: int, float, datetime, bool, category. They exclude object dtype and can be held in contiguous memory blocks. See here too, concerning C contiguous array stored in memory when creating a numpy array.  Why are numpy operations more efficient than simple crude Python ? as we‚Äôve seen earlier Everything in Python is an object. This includes, unlike C, numbers. Python types therefore have an overhead which does not exist with native C types. NumPy methods are usually C-based. check here  np. vectorize is fake vectorisation. According to documentation: The vectorize function is provided primarily for convenience, not for performance. The implementation is essentially a for loop. It means there is no reazon in vectorize of function wich could be applied directly as it is in your example. Actually this could lead to degraded performance. Main goal of the ‚Äúvectorize‚Äù is to hide a for loop from you code. But it will not avoid it neither change expected results. This link provides a good an example of simple vectorization. Numpy does not provide vectorization functions for arrays of strings. Pandas provide vectorized str operations. Pros are that you don‚Äôt have to write any loop and can take the column/Series as a whole. Cons are that they are not actually faster than using a simply apply. String operations are inherently difficult to vectorize. Pandas treats strings as objects, and all operations on objects fall back to a slow, loopy implementation. Already provided Pandas vectorized string methods available in . str. df_notes[ eleve ] = df_notes. eleve. str. capitalize()df_notes         eleve   note   groupe   quizz         0   Eleve0   71,43 %   Unknown   td1       1   Eleve1   100 %   Unknown   td1       2   Eleve4   71,43 %   Unknown   td1       3   Eleve6   42,86 %   Unknown   td1       4   Eleve8   57,14 %   Unknown   td1       . . .    . . .    . . .    . . .    . . .        741   Eleve174   100 %   ibo5   td3       742   Eleve166   66,67 %   ibo5   td3       743   Eleve176   83,33 %   ibo5   td3       744   Eleve186   100 %   ibo5   td3       745   Eleve196   66,67 %   ibo5   td3   746 rows √ó 4 columns mask = df_notes. groupe. str. startswith( U )mask0    True1    True2    True3    True4    True    . . .  741  False742  False743  False744  False745  FalseName: groupe, Length: 746, dtype: booldf_notes[mask]         eleve   note   groupe   quizz         0   Eleve0   71,43 %   Unknown   td1       1   Eleve1   100 %   Unknown   td1       2   Eleve4   71,43 %   Unknown   td1       3   Eleve6   42,86 %   Unknown   td1       4   Eleve8   57,14 %   Unknown   td1       . . .    . . .    . . .    . . .    . . .        87   Eleve202   57,14 %   Unknown   td1       88   Eleve203   57,14 %   Unknown   td1       89   Eleve204   71,43 %   Unknown   td1       90   Eleve205   42,86 %   Unknown   td1       91   Eleve207   42,86 %   Unknown   td1   92 rows √ó 4 columns df_notes. note. str. split(',')0   [71, 43 %]1     [100 %]2   [71, 43 %]3   [42, 86 %]4   [57, 14 %]     . . .   741    [100 %]742  [66, 67 %]743  [83, 33 %]744    [100 %]745  [66, 67 %]Name: note, Length: 746, dtype: object(df_notes. note . str. replace( % ,  ) # replace all occurences of  %  as    . str. replace( , ,  .  ) # replace all occurences of  ,  as  .   . astype(float))0    71. 431   100. 002    71. 433    42. 864    57. 14    . . .  741  100. 00742   66. 67743   83. 33744  100. 00745   66. 67Name: note, Length: 746, dtype: float64(df_notes. note . str. findall( (\d+),?(\d+)? ) #regex to find all matching groups in each element of the Series . str[0] # vectorized element access in the column, works for all iterable, hence even a list in a pd. Series, . str. join( .  ) # join the lists with  .   rather than ',' . str. rstrip('. ') # take off the last dot if exists . astype(float) # convert to float type) 0    71. 431   100. 002    71. 433    42. 864    57. 14    . . .  741  100. 00742   66. 67743   83. 33744  100. 00745   66. 67Name: note, Length: 746, dtype: float64serie_notes =\( df_notes. note . str. extract( (\d+),?(\d+)? ) # expand to multiple cols . fillna(0) # fill NaN as 0 when no matched group . astype(float) # convert to float)serie_notes[0] += serie_notes[1]/100serie_notes. drop(1, axis=1,inplace=True)df_notes. note = serie_notesdf_notes         eleve   note   groupe   quizz         0   Eleve0   71. 43   Unknown   td1       1   Eleve1   100. 00   Unknown   td1       2   Eleve4   71. 43   Unknown   td1       3   Eleve6   42. 86   Unknown   td1       4   Eleve8   57. 14   Unknown   td1       . . .    . . .    . . .    . . .    . . .        741   Eleve174   100. 00   ibo5   td3       742   Eleve166   66. 67   ibo5   td3       743   Eleve176   83. 33   ibo5   td3       744   Eleve186   100. 00   ibo5   td3       745   Eleve196   66. 67   ibo5   td3   746 rows √ó 4 columns Other interesting functions to mention: To compute the counts of unique values use : pd. Series. value_counts() df_notes. groupe. value_counts(ascending=False)ibo1    117ibo5    115ibo7    114Unknown   92ibo6    85ibo3    85ibo4    81ibo2    57Name: groupe, dtype: int64To do a binning : i. e. group a number of more or less continuous values into a smaller number of ‚Äúbins‚Äù. Use `pd. cut pd. cut(df_notes. note, bins=5) # 5 equal sized bins0    (60. 0, 80. 0]1   (80. 0, 100. 0]2    (60. 0, 80. 0]3    (40. 0, 60. 0]4    (40. 0, 60. 0]      . . .    741  (80. 0, 100. 0]742   (60. 0, 80. 0]743  (80. 0, 100. 0]744  (80. 0, 100. 0]745   (60. 0, 80. 0]Name: note, Length: 746, dtype: categoryCategories (5, interval[float64]): [(-0. 1, 20. 0] &lt; (20. 0, 40. 0] &lt; (40. 0, 60. 0] &lt; (60. 0, 80. 0] &lt; (80. 0, 100. 0]]pd. cut(df_notes. note, bins=[0, 50, 75, 100])0    (50, 75]1   (75, 100]2    (50, 75]3    (0, 50]4    (50, 75]     . . .   741  (75, 100]742   (50, 75]743  (75, 100]744  (75, 100]745   (50, 75]Name: note, Length: 746, dtype: categoryCategories (3, interval[int64]): [(0, 50] &lt; (50, 75] &lt; (75, 100]]try:   pd. cut(df_notes. note, bins=[0, 50, 75, 100], labels=[ Bad ])except Exception as e:  print(e)Bin labels must be one fewer than the number of bin edgesdf_notes['appreciation'] = pd. cut(df_notes. note, bins=[0, 25, 50, 75, 100], labels=[ Very Bad ,  Bad ,  Ok ,  Good ])df_notes. appreciation0    Ok1   Good2    Ok3    Bad4    Ok    . . . 741  Good742   Ok743  Good744  Good745   OkName: note, Length: 746, dtype: categoryCategories (4, object): [Very Bad &lt; Bad &lt; Ok &lt; Good]GroupBy !: df_notes. head(3)         eleve   note   groupe   quizz         0   Eleve0   71. 43   Unknown   td1       1   Eleve1   100. 00   Unknown   td1       2   Eleve4   71. 43   Unknown   td1   Groupby applies the ‚Äúsplit, apply, combine‚Äù method.  We first have to use a key to groupby, i. e. a column of different labels that will serve to split the main df into different subsets (one for each label in the concerned column), just as we would do a GROUP BY in SQL syntax. df_notes. groupby('groupe') &lt;pandas. core. groupby. generic. DataFrameGroupBy object at 0x1187d9a90&gt;No computation is done yet This result in a DataFrameGroupBy object we can iterate on. for name_group, group in df_notes. groupby('groupe'):  # the label used , the df subset (one for each label)  print(  label used {}, dataframe shape {} . format(name_group,group. shape)) label used Unknown, dataframe shape (92, 4)label used ibo1, dataframe shape (117, 4)label used ibo2, dataframe shape (57, 4)label used ibo3, dataframe shape (85, 4)label used ibo4, dataframe shape (81, 4)label used ibo5, dataframe shape (115, 4)label used ibo6, dataframe shape (85, 4)label used ibo7, dataframe shape (114, 4) Notice that we are not limited by grouping over one column keys. for name_group, group in df_notes. groupby(['groupe',  quizz ]):  # the label used , the df subset (one for each label)  print(  label used {}, dataframe shape {} . format(name_group,group. shape)) label used ('Unknown', 'td1'), dataframe shape (92, 4)label used ('ibo1', 'td1'), dataframe shape (30, 4)label used ('ibo1', 'td2'), dataframe shape (30, 4)label used ('ibo1', 'td3'), dataframe shape (27, 4)label used ('ibo1', 'td4'), dataframe shape (30, 4)label used ('ibo2', 'td2'), dataframe shape (30, 4)label used ('ibo2', 'td3'), dataframe shape (27, 4)label used ('ibo3', 'td2'), dataframe shape (30, 4)label used ('ibo3', 'td3'), dataframe shape (27, 4)label used ('ibo3', 'td4'), dataframe shape (28, 4)label used ('ibo4', 'td2'), dataframe shape (27, 4)label used ('ibo4', 'td3'), dataframe shape (28, 4)label used ('ibo4', 'td4'), dataframe shape (26, 4)label used ('ibo5', 'td1'), dataframe shape (27, 4)label used ('ibo5', 'td2'), dataframe shape (30, 4)label used ('ibo5', 'td3'), dataframe shape (28, 4)label used ('ibo5', 'td4'), dataframe shape (30, 4)label used ('ibo6', 'td2'), dataframe shape (29, 4)label used ('ibo6', 'td3'), dataframe shape (28, 4)label used ('ibo6', 'td4'), dataframe shape (28, 4)label used ('ibo7', 'td1'), dataframe shape (29, 4)label used ('ibo7', 'td2'), dataframe shape (28, 4)label used ('ibo7', 'td3'), dataframe shape (28, 4)label used ('ibo7', 'td4'), dataframe shape (29, 4)This results in a mutli-index with:  level0 = the group level1 = the quizz numberWe can also index the GroupByDataFrame object by retrieving one Series (again no computation is done yet) df_notes. groupby(['groupe',  quizz ])[ note ]&lt;pandas. core. groupby. generic. SeriesGroupBy object at 0x1188bdeb8&gt;for name_group, group in df_notes. groupby(['groupe',  quizz ])[ note ]:  print(  label used {}, \n{} shape {} . format(name_group, type(group), group. shape)) label used ('Unknown', 'td1'), &lt;class 'pandas. core. series. Series'&gt; shape (92,)label used ('ibo1', 'td1'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo1', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo1', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (27,)label used ('ibo1', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo2', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo2', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (27,)label used ('ibo3', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo3', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (27,)label used ('ibo3', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo4', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (27,)label used ('ibo4', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo4', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (26,)label used ('ibo5', 'td1'), &lt;class 'pandas. core. series. Series'&gt; shape (27,)label used ('ibo5', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo5', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo5', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (30,)label used ('ibo6', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (29,)label used ('ibo6', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo6', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo7', 'td1'), &lt;class 'pandas. core. series. Series'&gt; shape (29,)label used ('ibo7', 'td2'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo7', 'td3'), &lt;class 'pandas. core. series. Series'&gt; shape (28,)label used ('ibo7', 'td4'), &lt;class 'pandas. core. series. Series'&gt; shape (29,)Aggregation functions: We can now think about the ‚Äúapply, combine‚Äù part df_notes. dtypes eleve   objectnote   float64groupe   objectquizz   objectdtype: objectPandas provides us some functions to be applied on a dataframe or Series (. mean(), . sum(), . std(), . describe(), . min(), etc‚Ä¶), we can seemlessly append one of them to the GroupBy Object to operate on each of the subsets DataFrames/Series created on the split step (this is the apply step). After applying the function to each split, a combined result is returned, in the form of a Series object or DataFrame. Note that for those aggregating functions reduce the shape of the data e. g. summing or meaning on a Series result in a scalar (the sum or the mean), this will be operated over each Series groups from the split step. df_notes. groupby(['groupe'])[ note ]. mean()groupeUnknown  63. 664022ibo1    87. 337607ibo2    97. 251053ibo3    86. 418824ibo4    87. 953580ibo5    80. 288957ibo6    83. 484000ibo7    86. 402456Name: note, dtype: float64df_notes. groupby(['groupe', 'quizz'])[ note ]. mean()groupe  quizzUnknown td1   63. 664022ibo1   td1   67. 618000     td2   94. 666667     td3   90. 739630     td4   96. 666333ibo2   td2   98. 666667     td3   95. 678148ibo3   td2   88. 666667     td3   88. 887037     td4   81. 630357ibo4   td2   87. 407407     td3   87. 500000     td4   89. 009231ibo5   td1   53. 967407     td2   90. 000000     td3   90. 475714     td4   84. 759667ibo6   td2   90. 344828     td3   83. 332857     td4   76. 529286ibo7   td1   74. 875517     td2   85. 714286     td3   94. 642500     td4   90. 637931Name: note, dtype: float64as we get a hierarchical index we can unstack to make use of the dimensionality brought by column indexesm _. unstack()      quizz   td1   td2   td3   td4       groupe                     Unknown   63. 664022   NaN   NaN   NaN       ibo1   67. 618000   94. 666667   90. 739630   96. 666333       ibo2   NaN   98. 666667   95. 678148   NaN       ibo3   NaN   88. 666667   88. 887037   81. 630357       ibo4   NaN   87. 407407   87. 500000   89. 009231       ibo5   53. 967407   90. 000000   90. 475714   84. 759667       ibo6   NaN   90. 344828   83. 332857   76. 529286       ibo7   74. 875517   85. 714286   94. 642500   90. 637931   Something is unusual? why is there NaN? some class groups should have grades for each quizz. df_notes. isnull(). sum()eleve   0note   0groupe  0quizz   0dtype: int64though all the data seems complete‚Ä¶ df_notes. isnull(). apply(sum, axis=0)eleve   0note   0groupe  0quizz   0dtype: int64Notice the Unknown group, we should look more into this‚Ä¶ df_notes[df_notes. groupe ==  Unknown ]         eleve   note   groupe   quizz   appreciation         0   Eleve0   71. 43   Unknown   td1   Ok       1   Eleve1   100. 00   Unknown   td1   Good       2   Eleve4   71. 43   Unknown   td1   Ok       3   Eleve6   42. 86   Unknown   td1   Bad       4   Eleve8   57. 14   Unknown   td1   Ok       . . .    . . .    . . .    . . .    . . .    . . .        87   Eleve202   57. 14   Unknown   td1   Ok       88   Eleve203   57. 14   Unknown   td1   Ok       89   Eleve204   71. 43   Unknown   td1   Ok       90   Eleve205   42. 86   Unknown   td1   Bad       91   Eleve207   42. 86   Unknown   td1   Bad   92 rows √ó 5 columns _. shape[0]92To apply multiple aggregate functions at once using a list of the functions you want to apply in aggregate df_notes. groupby('quizz'). agg({'note': ['max', min]})         note          max   min       quizz               td1   100. 0   0. 00       td2   100. 0   40. 00       td3   100. 0   50. 00       td4   100. 0   42. 86   this results in a multi column index _. columnsMultiIndex([('note', 'max'),      ('note', 'min')],      )Grouping by students, we may have more insight. df_notes. groupby('eleve'). agg(list)# applied on all columns (where the function can be used on) for each subset         note   groupe   quizz       eleve                  Eleve0   [71. 43, 80. 0, 100. 0]   [Unknown, ibo2, ibo2]   [td1, td2, td3]       Eleve1   [100. 0, 100. 0, 100. 0]   [Unknown, ibo2, ibo2]   [td1, td2, td3]       Eleve10   [100. 0, 100. 0, 85. 71, 71. 43]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]       Eleve100   [100. 0, 100. 0, 100. 0, 85. 71]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]       Eleve101   [100. 0, 100. 0, 85. 71, 100. 0]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]       . . .    . . .    . . .    . . .        Eleve95   [85. 71, 100. 0, 100. 0]   [Unknown, ibo2, ibo2]   [td1, td2, td3]       Eleve96   [100. 0, 100. 0, 100. 0, 42. 86]   [ibo1, ibo1, ibo1, ibo1]   [td4, td3, td2, td1]       Eleve97   [28. 57, 85. 71, 83. 33, 60. 0]   [Unknown, ibo4, ibo4, ibo4]   [td1, td4, td3, td2]       Eleve98   [42. 86, 85. 71, 100. 0, 100. 0]   [Unknown, ibo4, ibo4, ibo4]   [td1, td4, td3, td2]       Eleve99   [71. 43, 100. 0, 100. 0]   [Unknown, ibo2, ibo2]   [td1, td2, td3]   208 rows √ó 3 columns Some students are known, but are not always written as such. transform: sometimes we want the ‚Äúapply-combine‚Äù steps to avoid reducing the data size but compute for each data record something based on some intra-group/splits caracteristics Here we would want for example to group by students and replace Unknown fields by the correct information from the other students record. df_notes         eleve   note   groupe   quizz         0   Eleve0   71. 43   ibo2   td1       1   Eleve1   100. 00   ibo2   td1       2   Eleve4   71. 43   ibo2   td1       3   Eleve6   42. 86   ibo6   td1       4   Eleve8   57. 14   ibo4   td1       . . .    . . .    . . .    . . .    . . .        741   Eleve174   100. 00   ibo5   td3       742   Eleve166   66. 67   ibo5   td3       743   Eleve176   83. 33   ibo5   td3       744   Eleve186   100. 00   ibo5   td3       745   Eleve196   66. 67   ibo5   td3   746 rows √ó 4 columns df_notes. replace({ Unknown :np. nan}, inplace=True)df_notes[ groupe ] = df_notes. groupby('eleve')['groupe']. transform(lambda x: x. bfill(). ffill())df_notes. groupby('eleve'). agg(list)         note   groupe   quizz   appreciation       eleve                     Eleve0   [71. 43, 80. 0, 100. 0]   [ibo2, ibo2, ibo2]   [td1, td2, td3]   [Ok, Good, Good]       Eleve1   [100. 0, 100. 0, 100. 0]   [ibo2, ibo2, ibo2]   [td1, td2, td3]   [Good, Good, Good]       Eleve10   [100. 0, 100. 0, 85. 71, 71. 43]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]   [Good, Good, Good, Ok]       Eleve100   [100. 0, 100. 0, 100. 0, 85. 71]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]   [Good, Good, Good, Good]       Eleve101   [100. 0, 100. 0, 85. 71, 100. 0]   [ibo7, ibo7, ibo7, ibo7]   [td3, td2, td4, td1]   [Good, Good, Good, Good]       . . .    . . .    . . .    . . .    . . .        Eleve95   [85. 71, 100. 0, 100. 0]   [ibo2, ibo2, ibo2]   [td1, td2, td3]   [Good, Good, Good]       Eleve96   [100. 0, 100. 0, 100. 0, 42. 86]   [ibo1, ibo1, ibo1, ibo1]   [td4, td3, td2, td1]   [Good, Good, Good, Bad]       Eleve97   [28. 57, 85. 71, 83. 33, 60. 0]   [ibo4, ibo4, ibo4, ibo4]   [td1, td4, td3, td2]   [Bad, Good, Good, Ok]       Eleve98   [42. 86, 85. 71, 100. 0, 100. 0]   [ibo4, ibo4, ibo4, ibo4]   [td1, td4, td3, td2]   [Bad, Good, Good, Good]       Eleve99   [71. 43, 100. 0, 100. 0]   [ibo2, ibo2, ibo2]   [td1, td2, td3]   [Ok, Good, Good]   208 rows √ó 4 columns Let‚Äôs check if we still have some NAs? df_notes. groupby(['groupe', 'quizz'])[ note ]. mean(). unstack()      quizz   td1   td2   td3   td4       groupe                     ibo1   67. 618000   94. 666667   90. 739630   96. 666333       ibo2   76. 846207   98. 666667   95. 678148   NaN       ibo3   40. 002000   88. 666667   88. 887037   81. 630357       ibo4   56. 632500   87. 407407   87. 500000   89. 009231       ibo5   53. 967407   90. 000000   90. 475714   84. 759667       ibo6   61. 427667   90. 344828   83. 332857   76. 529286       ibo7   74. 875517   85. 714286   94. 642500   90. 637931   Seems better ! df_notes[(df_notes. groupe == 'ibo2') &amp; (df_notes. quizz == 'td4')]         eleve   note   groupe   quizz     seems we don‚Äôt have data for the exam number 4 fro this group (which had been cancelled due too large manifestations in Paris which lead to postpone the session too late. ) df_notes = df_notes[~(df_notes. quizz=='td4')]Pivot Table: df_notes. groupby(['groupe', 'quizz'])[ note ]. mean(). unstack()      quizz   td1   td2   td3       groupe                  ibo1   67. 618000   94. 666667   90. 739630       ibo2   76. 846207   98. 666667   95. 678148       ibo3   40. 002000   88. 666667   88. 887037       ibo4   56. 632500   87. 407407   87. 500000       ibo5   53. 967407   90. 000000   90. 475714       ibo6   61. 427667   90. 344828   83. 332857       ibo7   74. 875517   85. 714286   94. 642500   df_notes. pivot_table('note', index='groupe', columns='quizz', margins=True)      quizz   td1   td2   td3   All       groupe                     ibo1   67. 618000   94. 666667   90. 739630   84. 120805       ibo2   76. 846207   98. 666667   95. 678148   90. 370349       ibo3   40. 002000   88. 666667   88. 887037   84. 838065       ibo4   56. 632500   87. 407407   87. 500000   77. 056747       ibo5   53. 967407   90. 000000   90. 475714   78. 711059       ibo6   61. 427667   90. 344828   83. 332857   78. 116667       ibo7   74. 875517   85. 714286   94. 642500   84. 957412       All   64. 686180   90. 882353   90. 154715   82. 528696   results = df_notes. pivot_table(index='groupe', columns='quizz',           aggfunc={ note :['max', min]})results         note          max   min       quizz   td1   td2   td3   td1   td2   td3       groupe                           ibo1   100. 00   100. 0   100. 0   28. 57   80. 0   50. 00       ibo2   100. 00   100. 0   100. 0   42. 86   80. 0   83. 33       ibo3   57. 14   100. 0   100. 0   14. 29   40. 0   66. 67       ibo4   100. 00   100. 0   100. 0   0. 00   40. 0   66. 67       ibo5   85. 71   100. 0   100. 0   0. 00   60. 0   50. 00       ibo6   100. 00   100. 0   100. 0   28. 57   40. 0   50. 00       ibo7   100. 00   100. 0   100. 0   28. 57   40. 0   66. 67   %matplotlib inlineimport matplotlib. pyplot as pltplt. rcParams['figure. figsize'] = (20, 10)results['note']. plot(kind='bar')&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11d11eba8&gt; df_notes. groupby('groupe'). appreciation. value_counts(dropna=False). sort_values(). plot(kind= bar )&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11ddc1cc0&gt; (df_notes.   . groupby(['quizz','groupe'])   ['appreciation']   . value_counts(). sort_index()   . plot(kind= bar ))&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11d1b4908&gt; (df_notes   . groupby(['quizz','groupe'])   ['appreciation']   . value_counts()   . unstack(). plot(kind='bar', stacked=True))&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11ef2ff98&gt; (df_notes   . pivot_table(index='quizz',          columns='groupe',          aggfunc={'appreciation':'value_counts'})   . plot(kind= bar ))&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11ee1d7f0&gt; df_notes. appreciation. value_counts(dropna=False). plot(kind= bar )&lt;matplotlib. axes. _subplots. AxesSubplot at 0x11d5a9128&gt; df_notes[pd. isna(df_notes. appreciation)]         eleve   note   groupe   quizz   appreciation         75   Eleve183   0. 0   ibo4   td1   NaN       525   Eleve111   0. 0   ibo5   td1   NaN   missing grades for students. Final question should be‚Ä¶What should we put in fillna for them üòâ ? Just an interesting link on representation of the data "
    }, {
    "id": 15,
    "url": "http://localhost:4000/webscrapping/",
    "title": "Webscrapping using Selenium",
    "body": "2020/09/07 - Selenium is an open-source automated testing suite for web apps. It was at first used to automate tests for web applications as it can emulate user interactions with browsers, although its scope is wider as it can be used for other purposes: such as webscrapping for example. ‚Äî Related practical session Jupyter Notebook ‚Äî How does Selenium Webdriver work ?How to programmatically create user interactions with Selenium ? through its WebDriver component  It allows users to simulate common activities performed by end-users; entering text into fields, selecting drop-down values and checking boxes, and clicking links in documents. It also provides many other controls such as mouse movement, arbitrary JavaScript execution, and much more. Every web browser are different in their ways of performing operations, Selenium WebDriver API aims at giving a common language neutral interface, whichever browser you may use, whichever language you code with.  Downstream, one * ‚Äú browser driver‚Äù* (many exist), i. e. ‚Äúone Selenium WebDriver implementation‚Äù , is a layer: responsible for delegating down to the browser, and handles communication to and from Selenium and the browser. To do so, it uses the automation APIs provided by the browser vendors.  Upstream, Webdriver API also refers to the language bindings to enable developpers to write test cases in different languages like Python, Java, C#, Ruby or NodeJS. Thus, referring to both the language bindings and the browsers controlling codes, the Webdriver API aims to abstract differences among all browsers by providing a common object-oriented interface.  How does your Python code get executed in the browser?By JSON Wire Protocol, tie to the Webdriver API. Each webdriver implementation (e. g. ChromeDriver) has a little server waiting for the Python commands (try to execute the chromedriver. exe file and you will see on which port it is listening too). You can communicate directly with the Webdriver implementation API (e. g. Chromedriver API), but also can use a selenium Python client library for issuing those requests one by one as HTTP client requests for the WebDriver server. When these commands come in the form of HTTP ones, the Webdriver implementation interprets those, ordering the underlying browser to perform them, and then returns the results back to the Webdriver API through the wire protocol. WebDriver became recently a W3C standard, it is an interface provided by Selenium. Thus, all classes (e. g. ChromeDriver) implementing this interface need to have a certain set of methods. It is then a structure/syntax that allows the computer to enforce certain properties on a class, certain behavior or requirements any object instanciated with that class must fulfill. A good example to read. Also Safari Dev docs highlights this schema Edit: WebDriver W3C Living Document has replaced JSON Wire Protocol.  Note from wikipedia: Where possible, WebDriver uses native operating system level functionality rather than browser-based JavaScript commands to drive the browser. This bypasses problems with subtle differences between native and JavaScript commands, including security restrictions. Interesting article to read too InstallationReading the installation process from the unofficial but thorough community docsis a good starting point to set the tools we need.  Create a virtual environement Install Python bindings client library:pip install selenium Takes a (web)driver matching with the browser you want to automate a session in. I. E. I have Chrome, i can download the ChromeDriver here for the matching version of Chrome I have.  You can put the downloaded driver (e. g. chromedriver. exe) in the current working directory and reference its path . /chromedriver. exe later in the webscrapping code for the instanciation of a ChromeDriver instance. Altough this may not seem ideal as the script will rely on the path where any person put the driver in. Hence it is better to export the executable driver path first and then not use anything in the code. As per the requirements of ChromeDriver:  The ChromeDriver consists of three separate pieces. There is the browser itself i. e. chrome, the language bindings provided by the Selenium project i. e. the driver and an executable downloaded from the Chromium project which acts as a bridge between chrome and the driver. This executable is called the chromedriver, we generally refer to it as the server to reduce confusion. Later on I will use the term browser driver for the controlling code provided by browser-vendors, to not confuse with language driver, the bindings provided by Selenium project as a client library for communciating with the Webdriver (or one of its implementation). InitialisationI use the Chrome Webdriver hence the line below does set up a Webdriver server and ultimately launch a new browser session using the browser driver. When we‚Äôre done, we can later use close()method to close the automated browser initialized session. We could also use the driver context manager using a with statement. from selenium import webdriver # driver = webdriver. Chrome() #### Your operations##driver. close() # to close the browser tab (window if there is only one tab. )OperationsNavigating:    Going to an url:    driver. get(url_name) # loaded when `onload` even has fired      Selecting an element:   # ! find element return the first element matching ! driver. find_element_by_class_name() driver. find_element_by_css_selectorn() driver. find_element_by_link_text() # the text attached to the link driver. find_element_by_partial_link_text() # part of the text attached to the link driver. find_element_by_name() #name attribute of the element driver. find_element_by_id() #id attribute of the element driver. find_element_by_xpath() #using XPath, see later driver. find_element_by_tag_name() #tag name driver. find_element() # private method, you can use By from selenium. webdriver. common. by import By, rather than using the shortcuts methods https://stackoverflow. com/questions/29065653/what-is-the-difference-between-findelementby-findelementby # Note that you can use directly on a webelement: # &lt;webelement&gt;. find_element_by. . . () will use the element as the scope in which to search for your selector. https://stackoverflow. com/questions/26882604/selenium-difference-between-webdriver-findelement-and-webelement-findelement # An example provided here https://github. com/Luc-Bertin/TDs_ESILV/blob/master/webscrapping_test2find_element. ipynb # # # When no element exist: NoSuchElementException is raised # ! find elementS return a list of Web elements ! driver. find_elements_by_class_name() driver. find_elements_by_css_selectorn() driver. find_elements_by_link_text() ## . . . # When no elements exist: just an empty list    Interacting with forms:     send keys to a form field / input:     element = driver. find_element_by_name( loginform ) element. send_keys( mot_de_passe ) ## To add use special keys in the keyboard: from selenium. webdriver. common. keys import Keys          clear the content of the form     element = driver. find_element_by_name( loginform ) element. clear()           Toggle the selection of checkboxes:   # example: https://www. w3schools. com/howto/howto_custom_select. asp from selenium. webdriver. support. ui import Select select = Select(driver. find_element_by_tag_name( select )) # Select by index (starts at 0) select. select_by_index(2) # Select by visible text #select. select_by_visible_text( text ) # Select by value select. select_by_value(value) # Deselecting all the selected options (for mutliselect elements only), a good example of multiselect # https://www. w3schools. com/tags/tryit. asp?filename=tryhtml_select_multiple select. deselect_all() # loop over options available for option in select. options: 	# print their text  print( option. text )    Managing Pop-Up dialogs (javascript alerts):   # A good example of alert here: http://demo. guru99. com/test/delete_customer. php # Wait for the alert to be displayed alert = wait. until(expected_conditions. alert_is_present()) # Switch to the alert pop-up alert = driver. switch_to. alert # Check the content of the alert alert. text # Click on the OK button / accept the alert the pop-up alert. accept() # or dismiss it: alert. dissmiss()    Moving between windows   driver. switch_to. window( windowName ) # to find out the name of the window you can check the link or js code that generated it # or loop other all windows handles by the driver for window in driver. windows:  driver. switch_to. window(window)    Moving between frames   # by name of the frame driver. switch_to_frame( name_of_frame ) # by index driver. switch_to. frame(0) # a subframe of a frame driver. switch_to. frame( name_of_frame1. 0. frame3 ) # going back to parent frame driver. switch_to. default_content()      Cookies   # 1. Go to the correct url / domain # 2. Set the cookie, it is valid for the entire domain # the cookie needs a 2 key:vals at least: # - 'name':&lt;name&gt; of the cookie # - 'value':&lt;thevalue&gt; of the cookie # You can set additional params such as if the cookie is HTTPOnly or not # E. g. driver. add_cookie({'name':'test', 'value':'thevalue'}) # 4. Get all cookies driver. get_cookies() # As an exercice you can apply this to check that you have a new EU cookie consent record after clicking the pop-up where you accept the use of cookies by the website [{'domain': '. w3schools. com',  'expiry': 1633354196,  'httpOnly': False,  'name': 'euconsent-v2',  'path': '/',  'sameSite': 'Lax',  'secure': True,  'value': 'CO5eHhQO5eHhQDlBzAENA2CsAP_AAH_AACiQGetf_X_fb2vj-_599_t0eY1f9_63v-wzjheNs-8NyZ_X_L4Xv2MyvB36pq4KuR4ku3bBAQdtHOncTQmRwIlVqTLsbk2Mr7NKJ7LEmlsbe2dYGH9vn8XT_ZKZ70_v___7_3______777-YGekEmGpfAQJCWMBJNmlUKIEIVxIVAOACihGFo0sNCRwU7K4CPUECABAagIwIgQYgoxZBAAAAAElEQAkBwIBEARAIAAQArQEIACJAEFgBIGAQACgGhYARRBKBIQZHBUcogQFSLRQTzRgSQAA'}, {'domain': '. w3schools. com',  'expiry': 1633354196,  'httpOnly': False,  'name': 'snconsent',  'path': '/',  'sameSite': 'Lax',  'secure': True,  'value': 'eyJwdWJsaXNoZXIiOjAsInZlbmRvciI6MywiY3ZDb25zZW50cyI6e319'}, {'domain': '. www. w3schools. com',  'expiry': 253402257600,  'httpOnly': False,  'name': 'G_ENABLED_IDPS',  'path': '/',  'secure': False,  'value': 'google'}, {'domain': '. w3schools. com',  'expiry': 1599744590,  'httpOnly': False,  'name': '_gid',  'path': '/',  'secure': False,  'value': 'GA1. 2. 1056235777. 1599658190'}, {'domain': 'www. w3schools. com',  'httpOnly': False,  'name': 'test',  'path': '/',  'secure': True,  'value': 'thevalue'}, {'domain': '. w3schools. com',  'expiry': 1606003200,  'httpOnly': False,  'name': '_gaexp',  'path': '/',  'secure': False,  'value': 'GAX1. 2. U2DF0lIpTsOVepnCdIak9A. 18588. 0'}, {'domain': '. w3schools. com',  'expiry': 1662730198,  'httpOnly': False,  'name': '__gads',  'path': '/',  'secure': False,  'value': 'ID=34d373f41409cec7-229cd97515a60048:T=1599658198:S=ALNI_MaHAR9T3-JOlXvVv0J_m6hrSCzcPQ'}, {'domain': '. w3schools. com',  'expiry': 1662730190,  'httpOnly': False,  'name': '_ga',  'path': '/',  'secure': False,  'value': 'GA1. 2. 669605950. 1599658190'}]   XPath: Although it is part of the navigation, I think it should be dedicated an entire section. In XPath you can select a lot type of objects (also designed as nodes). Among them: attribute, text, or element. A good read for XPath Here on dot notation in startswith in XPath Here on dot versus text() And on the current node vs everywhere//ol/descendant::code[contains(text(),  //* )][2] node-set passes to starts-with function as 1st argument (@*). The starts-with function converts a node-set to a string by returning the string value of the first node in the node-set, i. e. only 1st attribute Waits: A lot of browser are using AJAX (asynchronous javascript and XML), hence making calls from a client to the server asynchronously to modify components in a web page without needing to refresh the concerned page. Although this separates the presentation logic from the data exchange logic and greatly improve user experience, a ‚Äúloaded‚Äù page doesn‚Äôt mean other scripts won‚Äôt display other elements later on. implicit wait:: For the whole lifetime of the WebDriver object, each time an object is not available on request, repeat till n seconds elapsed. explicit wait:: Makes the webdriver wait for a certain condition to execute further instructions. from selenium. webdriver. support. ui import WebDriverWaitfrom selenium. webdriver. support import expected_conditions as ec# timeout after 10s without success# or returning the web element otherwisetry:	element = WebDriverWait(driver, timeout=10). until(		ec. presence_of_element_located((By. ID,  myDynamicElement )))except TimeoutException:	print( Looks like it didn't work out during the time requested )# caution: inside the expected condition class constructor, you must fill a locator in the form of a tuple (by, path)Directly from the docs here are some convenient expected conditions class‚Äôconstructors you can use:  title_is title_contains presence_of_element_located visibility_of_element_located visibility_of presence_of_all_elements_located text_to_be_present_in_element text_to_be_present_in_element_value frame_to_be_available_and_switch_to_it invisibility_of_element_located element_to_be_clickable staleness_of element_to_be_selected element_located_to_be_selected element_selection_state_to_be element_located_selection_state_to_be alert_is_presentCustom wait conditions are also interesting to check as it uses some concepts (__call__) we have covered elsewhere in this blog. Action chains: One of the most useful WebDriver tool:  ActionChains are a way to automate low level interactions such as mouse movements, mouse button actions, key press, and context menu interactions. This is useful for doing more complex actions like hover over and drag and drop. Usage: # 1. import the class ActionChainsfrom selenium. webdriver. common. actions_chains import ActionChains# 2. Keep for later the elements you are going to interact withmenu = driver. find_element_by_css_selector( . nav )hidden_submenu = driver. find_element_by_css_selector( . nav #submenu1 )# 3. ActionChains constructor expects the driverpile_of_actions = ActionChains(driver)# 3. stack of actions (not performed yet)actions. move_to_element(menu) # moving the mouse to the middle of the elementactions. click(hidden_submenu)# 4. perform the stored actions in the order it was defined (top to bottom) actions. perform()move_by_offset(xoffset, yoffset) is really useful to cause web animations/interactions which rely heavily on the user‚Äôs mouse moves. It moves to an offset (x or y coordinates) from current mouse position. See example below (this is for educational purposes only !) 	injecting js code in the browser: One use case could be to scroll in a news or social network feed. Here is an example of such: 	additional infos: DOM: Document Object Model Wikipedia best describes it: Another interesting link on the difference between RemoteWebDriver and Webdriver "
    }, {
    "id": 16,
    "url": "http://localhost:4000/hands-on-numpy/",
    "title": "Hands-on Numpy !",
    "body": "2020/09/01 - It is often better to visualize data of apparent heterogeneity (sounds, images, text) as arrays of numbers, so to process these data or apply machine learning on them. A well-known package for creating and handling such arrays is Numpy (Numerical Python). Numpythe Python overhead numpy is dealing: As we outlined in Beginning in Python, in Python, everything is anobject. Hence even the simple integer 3 is actually the value of an integer object with possible methods and attributes associated to it. Taking the reference implementation (CPython), it is actually a C structure under-the-hood, so are other Python primitives (list, tuple, set, dict, etc. ). This brings an overhead    check overhead for an integer (bytes)     labels C first link messages  outer product: https://fr. wikipedia. org/wiki/Produit_dyadique contiguous C and Fortran arrays and why reshape sometimes do a copy of the data:https://stackoverflow. com/questions/26998223/what-is-the-difference-between-contiguous-and-non-contiguous-arrays https://stackoverflow. com/questions/38127123/strange-typecasting-when-adding-int-to-uint8/39253434 "
    }, {
    "id": 17,
    "url": "http://localhost:4000/some-python-exercices/",
    "title": "Some Python exercices",
    "body": "2020/09/01 - Some exercices following tutorial Beginning in Python to make you more comfortable with some object-oriented concepts in Python ;) SendTo: contact &lt; at &gt;  lucbertin  &lt; dot &gt; com Subject: PYTHON - EXERCICES1 - &lt;SCHOOL&gt; - &lt;FIRSTNAMES LASTNAMES&gt; CC: your teammates‚Äô email if anyContent: A Jupyter Notebook converted in HTML file Ex. 1: from a list of lists to a dictionnary: Transform this: liste = [[1, 2], [3,4], [5,6], [7,8]] into this: OUTPUT: {1: 2, 3: 4, 5: 6, 7: 8} using dict comprehension using dict constructorEx. 2: Counting letter frequencies in a text. :  You should count letter frequencies using these strategies:     using a simple Python dictionary   using defaultdict (subclass of dict)   using Counter (subclass of dict)defaultdict and Counter can be found in collections (i. e. from collections import defaultdict, Counter)    Count word frequencies (store them in a Python dictionary). text =    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum sagittis neque turpis, in gravida erat tincidunt a. Maecenas lobortis rutrum arcu, in posuere dolor fermentum sed. Duis imperdiet laoreet nibh, a pretium lectus condimentum eget. Maecenas eu elit vitae nibh euismod lacinia et a tortor. Donec at egestas leo, eget molestie quam. Sed elementum scelerisque sapien, quis suscipit ex malesuada vel. Aenean non mollis erat, in tincidunt massa. Mauris semper, purus in dictum imperdiet, libero nunc bibendum ex, eget facilisis turpis lorem ac lorem. Sed bibendum scelerisque tortor vel dictum. Aliquam dignissim eget erat non mollis. Maecenas vehicula feugiat tortor, in vulputate ex molestie nec. Ut suscipit iaculis nulla, auctor elementum urna dapibus non. Fusce facilisis mollis tellus sit amet venenatis. Praesent metus enim, tincidunt posuere tellus et, placerat tincidunt justo. Nunc id gravida ipsum, id porttitor magna. Maecenas porttitor accumsan odio non mattis. Suspendisse ultrices eleifend tristique. Vivamus accumsan libero tortor, eu aliquam sapien iaculis sed. In congue quis mi sed condimentum. Ut est libero, condimentum sit amet sagittis eu, tincidunt sed risus. Suspendisse pharetra molestie rutrum. Cras bibendum, dui ac consectetur eleifend, leo leo laoreet nibh, eget tristique lorem enim a nisi. Duis a purus eu augue consectetur malesuada id nec ex. Pellentesque sed odio laoreet, imperdiet dui ut, sodales odio. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Donec interdum, tortor eu dapibus pharetra, libero nisi faucibus nisl, id malesuada felis diam id urna. Praesent est metus, gravida eu luctus vitae, egestas vel metus. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Cras suscipit malesuada dui, vitae faucibus libero mollis a. In posuere blandit augue, sed semper ante imperdiet sed. Cras egestas posuere augue at semper. Praesent fermentum nunc risus, vitae aliquet augue consectetur a. Fusce interdum orci nunc, non posuere ex venenatis id. Nam faucibus fringilla mollis. Nulla ac enim accumsan, accumsan risus sit amet, rutrum tellus. Praesent lacinia augue at pulvinar venenatis. Etiam nunc augue, suscipit a faucibus sed, sodales ut mauris. Quisque quis magna malesuada, ultricies leo eget, elementum est. Praesent enim purus, pretium a nisl quis, accumsan blandit sapien. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Mauris ultricies iaculis nunc, quis fringilla arcu bibendum ac. Integer eu sem eget dui tempor sagittis. Ut sit amet ipsum quis nisi porttitor pulvinar. Etiam suscipit, leo nec fringilla luctus, lacus est egestas augue, eget vestibulum augue diam non eros. Duis posuere ac magna eget ullamcorper.    Ex. 3: decoding mARN using dict and list comprehensions !: In a cell, ribosomes synthesises proteins by translating triplets of nucleotides from the mRNA into a chain of amino-acids. Here is a dictionary made from the inverse table of the DNA-codon-to-amino-acids conversions. amino_acids_from_triplets = {  Ala :  ( GCT ,  GCC ,  GCA ,  GCG ),  Arg :  ( CGT ,  CGC ,  CGA ,  CGG ,  AGA ,  AGG ),  Asn :  ( AAT ,  AAC ),  Asp :  ( GAT ,  GAC ),  Cys :  ( TGT ,  TGC ),  Gln :  ( CAA ,  CAG ),  Glu :  ( GAA ,  GAG ),  Gly :  ( GGT ,  GGC ,  GGA ,  GGG ),  His :  ( CAT ,  CAC ),  START : ( ATG ),  Ile :  ( ATT ,  ATC ,  ATA ),  Leu :  ( CTT ,  CTC ,  CTA ,  CTG ,  TTA ,  TTG ),  Lys :  ( AAA ,  AAG ),  Met :  ( ATG ),  Phe :  ( TTT ,  TTC ),  Pro :  ( CCT ,  CCC ,  CCA ,  CCG ),  Ser :  ( TCT ,  TCC ,  TCA ,  TCG ,  AGT ,  AGC ),  Thr :  ( ACT ,  ACC ,  ACA ,  ACG ),  Trp :  ( TGG ),  Tyr :  ( TAT ,  TAC ),  Val :  ( GTT ,  GTC ,  GTA ,  GTG ),  STOP :  ( TAA ,  TGA ,  TAG ) }   Using dict comprehension, convert this dictionary in another one having keys as tuples of nucleotides and resulting amino-acids as values (e. g. for ‚ÄúHis‚Äù amino_acid, {( CAT ,  CAC ): His }. We will call this dictionary all_triplets_to_amino_acids     Using dict comprehension, expand the tuples in dictionary all_triplets_to_amino_acids as simple keys for each element of the tuples. Hence you should have in the resulting dictionary multiple same amino acids values for some keys (e. g. ‚ÄúCAT‚Äù: ‚ÄúHis‚Äù, ‚ÄúCAC‚Äù: ‚ÄúHis‚Äù)We will call this dictionary triplets_to_amino_acids     This is an mARN extract that is about to get translated in protein synthesis:arn = ‚ÄòGCCGAGTAACTAGCCAGCTATGACACGATCCCGGCTAGGAAAGTGAACCCGCGGAAGTATATTGGTACCTCACGGTAGGAGACGGCGGGATAATTCTTGTCGCTGTGTGTGCCATCGTACACGAGACGGGTCCACTGAGTAAAGCGAGTATCACACAGACGAAGGTGACCTCCCCTTGTAGTCAGTAATCTTTCCTGAATCTAATTACTGTCATCGATTGCAAAACTTTGCAAAAAAACATTTGTAGACAACCGCTTACGTGGCGCTTCCTGCATTAAACGATTCCGGTGCACGGAACAA‚ÄôSplit this arn in sequence of triplets to further get the amino-acids conversion (you can use list comprehension + range).     Translate the sequence of triplets into a corresponding string of amino acid separated by a separator ‚Äú-‚Äú (Hint: use a list comprehension for the looping part, then convert the resulting list into a string with ‚Äú-‚Äú separators)/  Ex. 4: functions:  Create/define a simple function that prints ‚Äòhello‚Äô. The function should not return anything neither take any inputs. Call that function.  Create/define a simple function that takes one parameter ‚Äòname‚Äô and returns ‚Äòhello &lt;name&gt;‚Äô. Call that function.  Create/define a simple function that does the same as 2, but provides default value if the name argument is not passed-in the function call by the user. Call that function.  Create/define a simple function that takes 2 params: age and name. It first ‚Äúupperizes‚Äù the name, and convert age as a string so to have the returned form as ‚ÄòHello &lt;name&gt;, you are &lt;age&gt; years old‚Äô.  Call the function in 4 passing positional arguments in the right order. Call a the function a second time passing keywords arguments in either orders. Prove the order of keywords arguments does not matter here.  Call the function in 4 each time on each input (name and age) provided below, using for loop and tuple unpacking from the dict below:  inputs = {'Luc': 25, 'Corentin': 18, 'Thomas': 29, 'Julie': 22, 'Juliette': 21}      Using this input list of arguments below:  list_of_arguments = ['Luc', 25]    Call the function defined in 4 passing-in the list_of_arguments to be ‚Äúparsed‚Äù/unpacked into positional arguments in the function.   Using this dict of arguments below:  dict_of_arguments = {'age':25, 'name': 'Luc'}    Call the function defined in 4 passing-in the dict_of_arguments to be ‚Äúparsed‚Äù/unpacked into keyword arguments in the function. Does the position matter ? Prove it.   Recall what we did in 6? Reuse the same variable inputs below:  inputs = {'Luc': 25, 'Corentin': 18, 'Thomas': 29, 'Julie': 22, 'Juliette': 21}    to print a hello message using for loop from the dict below, but this time with the unpacking that happens within the function call !  A function with undefined number of arguments:    Create/define a more flexible function named multiply that returns a value made from multiplying any number of positional arguments passed in that function. Call multiply(8,2,3)Call multiply(19,2,10)Call multiply(1)To prove validity of the function.     Create/define the function multiply2that do the same as multiplytake an additional boolean keyword argument inverse defaulting to False, but when set as True on function call, will inverse the final result to be returned. Call multiply(8,2,3, inverse=True)Call multiply(19,2,10, inverse=True)Call multiply(1, inverse=True)To prove validity of the function. What happens if i do ? Explain it. Call multiply(8,2,3, True)     Create/define the same function multiply2, but this time that takes any number of keywords arguments (just like inverse, but would not be reduced to that). Add some behavior in the function definition for arbitrarily named keywords arguments (just as we did with inverse), and use them in different calls.  Ex. 4: Sort a dictionary‚Ä¶ by values !: Hint: use Ordereddict x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}Ex. 5: Let‚Äôs create a decorator using class definition: A decorator is a construct often written as a function, that takes a function as parameter and returns another one which extends the behavior of the passed-in function. It thus needs to return a new function who had been defined in its inner scope and wrapped the first one. We can also write a decorator using a class: the method __call__ (instance method) enables to an instance of a class to behave just like a function by being callable (the instance, not the class! ‚ÄúCalling‚Äù the class equals to calling its constructor e. g. People( boulanger )) 1 / Create a class NbFunctionCalls. 2/ Each instance need to have one instance attribute to which is assigned a function during the initialization process. 2/ The instance (not the class) also needs to have counter. 3/ Use the __call__ instance method so to be able to call the instance as if it was a function. 4/ To each call, the instance attribute function needs to be called and the counter incremented by 1. 5/ Define a function somme which compute the sum of an undefined number of params passed to it. 6/ Use the notation @NbFunctionCalls to add the functionality brought by the decorator. 7/ Which formula equals to the preceding notation ? 7b/ What does somme‚Äôs type become ? 7c/ Access to the counter. 8/ What functionality does NbFunctionCalls bring ? 9/ Keep the overall structure from NbFunctionCalls . But this time, move counter as class variable and not instance variable. 10/ Create a multiply function, that multiplies all passed-in args (a * b * c * ‚Ä¶ * z) 11/ Create a divide function that divides all passed-in args (a / b / c / d ‚Ä¶) 12/ Add @NbOfAllFunctionCalls to both of those functions. 13/ Call them separately and check their respective counters, what is happening ? 14/ Create a decorator in the same context to record the different results from those functions. The results must be saved in a dictionary:  keys  = params used values = results obtainedEx. 6: Create a custom list üòâ: Create a class List whose behavior upon doing liste1 + liste2 (with liste1 and liste2 being List instances), is to add each of their elements element-wise i. e. liste1[i] + liste2[i] for each i. If the lists have different length, the sum is considered longestliste[i] + 0. "
    }, {
    "id": 18,
    "url": "http://localhost:4000/setting-up-a-simple-flask-app/",
    "title": "Setting up a simple Flask app",
    "body": "2020/08/29 - Flask is a micro web framework written in Python, first released in 2010. It is lightweight (hence the ‚Äúmicro‚Äù), has more stars on GitHub that is ‚Äúconcurrent‚Äù Django¬†‚Äî first released in 2005 ‚Äî and is based on the philosophy that the main fundations and services are built into Flask and ready-to-use, while additional features can be seamlessly added to your app by installing extensions and initializing them to your app. 2 main dependencies:  Jinja2, a web templating engine Werkzeug, a WSGI library, provides a communication layer between your Python code and a WSGI-compatible server. Databases, forms validations, user authentification are provided by Flask extensions created by the community. Setting up the flask project: We need to create a Python virtual environement using venv, which comes in the standard Python library as of Python 3. 3.  Installation of flask module: pip install flaskFirst app: A client makes a request through an URL endpoint. An endpoint is specified as a relative or absolute url that usually results in a response from the server. Upon a request, the server (which can be the built-in WSGI flask dev-server, or a production-grade server such as Gunicorn), which are WSGI compatbile servers, passes this request to the application instance, an object of class/type Flask, which needs to handle it, what code should it run, code embedded within a function for that specific matched endpoint. This handling function is called a route. 	# creation of the application instance (there could be many)	from flask import Flask	app = Flask(__name__) # so flask knows where is the root path of the app# application instance is called `app`# those routes are handled by the application instance 'app' (`app` may be imported from a different file or this code could be simply written in the same file after the previous code block)# endpoint here is the root url '/'# the decorator turns root_url function to a  route function @app. route('/')def root_url():	# returned value = response	return  &lt;h1&gt;Hello !&lt;/h1&gt; # endpoint here is '/home/'# with dynamic url routing@app. route('/home/&lt;name&gt;/')def second_url_function_handler():	# name becomes an argument that you can use in the decorated function wrapped by flask decorator	response_string =  &lt;h1&gt;Hello to Home {}!&lt;/h1&gt; . format(name)	return response_stringYou can access the request object within route functions to get more insight of the incoming request (args, method, json). This ‚Äúcontext glocal‚Äù variable is accessible by pushing the request context so Flask knows in which environment/thread/client request he is operating on. The same way, session object is persistent between requests (can be used to store user informations) and depends on the request context too. Finally, g and current_app depend on the application context, g is reset between each request and used as storage during handling of requests. app. url_map shows all the mapped URL endpoint to routes. Responses::  returned value(s) from the route as a tuple.  better: make_response(data, HTTP_code, [dict_of_header]), you can set additional things using methods of the response object such as setting cookies redirect(url_to_redirect) (flask automatically set the default 302 HTTP response code used for redirection). Adding extension(s):: from flask_extension import TheClassthe_instance = TheClass(app) # app instance goes in the constructor of the extension flask-script: add command-line parser instead of modifying args in app. run() flask-bootstrap: open source CSS framework from Twitter (also include some js animations)To connect from another host in the network: FLASK_ENV=development python . /script. py runserver -h 192. 168. 0. 16presentation logic: what the user sees and interact with. business logic: processings invisible to the user. view functions handle both logics by design, but it is better to allocate presentation logic to the templating engine Jinja to improve readibility and maintainability of the app. The template is a file that contains the text of the response, with placeholder variables or dynamic parts (loops/conditions) changing from a request to the other. The rendering is the process of associating the computed value from the request to the template placeholders. Templates are located in ‚Äútemplates‚Äù subfolder by default (can be change in Flask constructor) Then in the view function:render_template(file. html, key1=val1, key2=val2) the value could be of any type (dict, list, user-defined objects, etc. )  filters modify variables in-place {{ variable | filter_name }} example1: capitalize to capitalize the variable : ‚Äúluc‚Äù -&gt; ‚ÄúLuc‚Äù   example2: safe to avoid escaping the content of the variable (hence you can put some html tags inside variable it will be rendered as is). Be careful though on security concerns (malicious code that can be inserted into your website).   conditional statements and loops:  include an html file as is ‚Äî for example a navigation bar that does not need to be changed ‚Äî from a template file to another  for portion of html code that need to be modified by a template you can use and in file_with_blocs. html: A good practice would be to create different categories of pages with a layout by creating base. html file(s) and derive them for all pages being part of some kind of subcategory. Subcategories can also further be extended: adding an error handler for a webpage returning some error code: @app. errorhandler(404)def page_not_found(e):	return render_template('404. html'), 404This handler function won‚Äôt be call unless an Exception is raised, here an HTTPException. Hence we need to import and raises it first: from werkzeug. exceptions import HTTPExceptionThen for any endpoint that does not match our previous urls in the url_map, an HTTPException is raised along with the path variable. @app. route('/&lt;path:nompath&gt;')def error_test(nompath):	# raises an HTTPException of status code 404	# nompath is the error message	# retrieved from e in page_not_found(e)	abort(404, nompath)Links should not be hard-coded into the templates folder either.  to respect the DRY principle (Don‚Äôt Repeat Yourself) also because it is too complex to write dynamic paths (based on the name provided by a person for example just as for routes handling)url_for is here for the rescue!, its parameters are the:  1st parameter: the name of the routed function any number of keyword arguments, each corresponding to a variable part of the URL rule.  _external(Boolean): if evaluated to True, returns the absolute URL, otherwise relative to the root ‚Äò/‚Äô.  unrecognized params are appended to the URL as query parameters e. g. test=25 /?test=25from flask import url_forOpening the interpreter we can check what url_for could build us: with app. app_context():	with current_app. test_request_context():		url_for('second_url_function_handler', name= luc )We obtain ‚Äò/home/luc‚Äô which makes sense with the route logic. Now we can use it in our template file, for example in the navigation. html Hence we just linked the route url with the navigation link But url_for can also be used in the routes handling: # just as an example@app. route('/admin/')def admin():  if not loggedin:  	# should login endpoint exist    return redirect(url_for('login'))And even querying static files (images, assets, CSS) using url_for(‚Äòstatic‚Äô) along with the filename param (e. g. filename='logos/favicon. ico'). Forms: You can access data from POST requests on forms using request. form. Why using an extension for forms then ?  For automatic rendering of HTML for the forms (based on a library call WTForms), mainly based on the data type required for each component of the form.  data validation (critical, before storing in a database for example) CSRF protection: to avoid malicious persons making hidden malicious requests from another website visited by a user who is logged-in to the first, and on behalf on him/her (cookies are sent automatically along with the request). CSRF protectionWe first need a key which create encrypted tokens passed along with the form to make sure of user authenticity. the server would generate a random string and add it as an hidden field to the form which is accessible only by the user app. config[ SECRET_KEY ] =  randomly generated string A Form Class: To create a form, define a Class ‚Äúdata model‚Äù. Each class attribute = a fieldEach field can have multiple validations hence validators with it. 1st argument is the label of the field, visible to the user. from wtforms import Form, StringField, SubmitField, IntegerFieldfrom wtforms. validators import DataRequired, Lengthclass MyForm(Form):  name = StringField( Name , validators=[DataRequired()])  age = IntegerField( Age , validators=[Length(min=13,max=19), Required()])  submit = SubmitField( Submit )Here is a list of built-in validators provided by the extension. You can also build your custom validators by creating callable classes After that, you can simply import functions for WTF forms rendering using Bootstrap and call wtf. quick_form() directly on the MyForm object instance. To pass the form object, we need to change a bit the index function, corresponding to the url endpoint hit by the client where the form will be visible. from Miguel Grinberg‚Äôs book:  Adding POST to the method list is necessary because form submissions are much more conveniently handled as POST requests. It is possible to submit a form as a GET request, but as GET requests have no body, the data is appended to the URL as a query string and becomes visible in the browser‚Äôs address bar. For this and several other reasons, form submissions are almost universally done as POST requests. instance_Form. validate_on_submit(): True if form submitted and data valid. When a browser is refresh, the last request is submitted again, which is a form submission, leading to a warning by the browser of a double submit. To counteract this we have to do redirect HTTP get request back to the form or in another endpoint/place. But then, after an HTTP redirect, we don‚Äôt have memory anymmore of the values submitted by the user, we then use the request-context global variable sessionfor memorizing informations among different requests.  From pythonise. com Sessions in Flask are a way to store information about a specific user from one request to the next. They work by storing a cryptographically signed cookie on the users browser and decoding it on every request. You can set the datetime. delta for when the session should be erased. They expire if the user close the browser, unless we specify: flask sessions expire once you close the browser, unless modify the permanent attribute and set a timeout for expiration. session. permanent = Trueapp. permanent_session_lifetime = timedelta(minutes=30) # lasts 30 minutesThose line can be encapsulated within a request hook i. e. : @app. before_first_requestdef permanent_session():	. . . 	# here	. . . You can also play with those items to set a short timedelta value within a before_request hook. Hence an short inactivity would lead to the user being kicked out of the website. Databases: We will use the ORM SQLAlchemy using the extension Flask-SQLAlchemy. ORM is short for Object-relational mapper. It is an higher level of abstraction that enables you to define the data model for your website using Python classes. One class for each table, each class attribute for a field, in an analogous way when we created forms using Flask WTForms. The main advantage of doing so is mainly because it makes it a very easy-to-use and highly portable solution, since you can sometimes use the same classes for different databases engine (SQLAlchemy will take care of converting those Python representations of the data model into a set of SQL instructions for the proper database engine to create the corresponding table(s)). pip install flask-sqlalchemyWe now have to create a new entry in the flask app. config object to incorporate the URI location for the database engine (i. e. ‚Äúwhere can i locate the database‚Äù). # we will use here the SQLite as it is stored in a disk in the computer rather that relying on another server hosting the database service (either on the same computer or outside). # absolute path of the directory containing this filebasedir = os. path. abspath(os. path. dirname(__file__))app. config[ SQLALCHEMY_DATABASE_URI ] = 'sqlite:///' + os. path. join(basedir, 'data. sqlite')Here are the defined models. 1 User can have multiple Posts1 Post have 1 User onlyHence Post is the thinnest degree of granularity if we where to join those 2 tables. It has a foreign key of user representing the user. id_ values. And a relationship is created on the User model with respect to Post to make SQLAlchemy understand the relationship, giving meanwhile a backref for how to refer to a user instance from a post level. ### models ####class Post(db. Model):  __tablename__ =  posts   id_ = db. Column(db. Integer, primary_key=True)  name = db. Column(db. String(64), unique=True)  # 1 User can have multiple Posts.   # Hence we need to put a foreignkey on the Posts,   # where the level of granularity is the thinnest   # (idpost1-user1, idpost2, user1, etc. )  user_id = db. Column(db. Integer, db. ForeignKey( users. id_ )) # the ids in this column match with the ids column in user.   # and a relationship in the  Parent  to link them.   def __repr__(self):    return  Post: {}: name {} . format(self. id_, self. name)class User(db. Model):  # renaming the table and not default user  __tablename__ =  users   id_ = db. Column(db. Integer, primary_key=True)  username = db. Column(db. String(64), unique=True, index=True)  # this is how SQLAlchemy understand there is a relationship with the model Post  posts = db. relationship( Post , backref= user )  # posts will show a list of related post to one user  # from post, you can access to the user as an object using the backref instead of the  user  foreign_key (which returns only the user id)    def __repr__(self):    return  User {}: with name: {} . format(self. id_, self. username)###############using uselist=False (in the db. relationship()) lead to a one-to-one relationship instead of one-to-many relationship. To create the tables from the models we can interactively open a python interpreter using: python script. py shelland instruct: from script import dbdb. create_all()A new data. sqlite file is created (using the URI defined in the app. config). As highlighted by Miguel Grinberg, db. create_all() does not update on models changes in the code. Hence a base solution (not the best, especially if your website run and you want to migrate smoothly without loosing your data) is to do a: db. drop_all()db. create_all()note the during the db. drop_all() process, only the tables are being deleted/dropped, not the database-file itself (same for db. create_all() if a database-file at the URI does already exist). Below is a cope snipped to play with the database, create new entries, set them, filter some python script. py shellfrom script import dbfrom script import User, Postdb. create_all()# You can query using the `ModelClass. query`# From simple queryUser. query. all() # all usersPost. query. all() # all posts# You can insert new elements / rows by first creating the higher-level Python instancesuser1 = User(username =  David )user2 = User(username =  Corentin )user3 = User(username =  Jos√©phine )post1 = Post(name =  Le savoir-faire , user = user1)post2 = Post(name =  L'√©trange No√´l , user = user1)post3 = Post(name =  coder en Python , user = user2)# Using a dict and unpacking it inside the function signaturepost4_dict = {  name :  coder en C ,  user : user2 }post4 = Post( **post4_dict ) # SQLAlchemy will take care of assigning a primary key id_ when writing into the database# print(user1. id_) output None so far# add the changes to be madedb. session. add(user1) db. session. add(user2)db. session. add(user3)db. session. add(post1)db. session. add_all( [ post2, post3, post4 ])# write the changes to the database# ‚ÄúAll-or-nothing‚Äù, if any error occurs, the previous state is unchanged. db. session. commit()# Querying againUser. query. all() # all usersPost. query. all() # all posts# To more advanced ones# We define a query objectone_query = Post. query. filter_by(name= Le savoir-faire )# We execute the query using `all()`one_query. all()# Some other examplesPost. query. filter_by(user=user1). all()# the equivalent using `filter`Post. query. filter(Post. user == user1). all()Post. query. filter(Post. user. has(username= David )). all()# we can also use other type of operatorsPost. query. group_by(Post. name). all()executed_query = Post. query. group_by(Post. name). all()one_post = executed_query[0]one_post. userexecuted_query = User. query. filter_by(username= David ). all()executed_query[0]. posts# when using `posts` from the db. relationship, a query is issued but it returns here a list, no longer queryable, we would want to query the objects it could contain. This can be circumvented using `lazy = 'dynamic‚Äô` in `db. relationship` so query is not issued too soonMigrations: Dropping and recreating all the tables in the database each time the data model change a little bit is really neither convenient nor easy to maintain, even more in the situation where your application is already deployed and registering user or user‚Äôs data that you don‚Äôt want to be lost. Alembic is a tool which checks changes in your data model and creates migrations scripts for SQLAlchemy database migrations. Each script contains 2 Python functions (upgrade and downgrade) which can be invoked directly by command-line using Flask-Migrate extensions, so to perform changes on the database level. upgrade() applies the new changes while downgrade() does the exact inverse, allowing you to go to any structures your tables had at a certain timepoint. Installation of Flask-Migrate: pip install flask-migrateImport ad connection to the app: from flask-migrate import Migrate, MigrateCommand # adding an handler for web pagemigrate = Migrate(app, db)# to run as command line options using Flask Scriptmanager. add_command('db', MigrateCommand)Creation of the migration folder: python script. py db initCreation of the first script (from nothing to actual table structure): python script. py db migrate -m  first migration You can known check the scripts in the migration folder which should look like that: def upgrade():  # ### commands auto generated by Alembic - please adjust! ###  op. create_table('users',  sa. Column('id_', sa. Integer(), nullable=False),  sa. Column('username', sa. String(length=64), nullable=True),  sa. PrimaryKeyConstraint('id_')  )  op. create_index(op. f('ix_users_username'), 'users', ['username'], unique=True)  op. create_table('posts',  sa. Column('id_', sa. Integer(), nullable=False),  sa. Column('name', sa. String(length=64), nullable=True),  sa. Column('user_id', sa. Integer(), nullable=True),  sa. ForeignKeyConstraint(['user_id'], ['users. id_'], ),  sa. PrimaryKeyConstraint('id_'),  sa. UniqueConstraint('name')  )  # ### end Alembic commands ###def downgrade():  # ### commands auto generated by Alembic - please adjust! ###  op. drop_table('posts')  op. drop_index(op. f('ix_users_username'), table_name='users')  op. drop_table('users')  # ### end Alembic commands ###This is the same as creating the tables the first time. After that, any new changes in the model and any new migrations scripts derived from them will be incremental changes from the current model. The script isn‚Äôt applied yet, it was here for review. To apply it (and in that case actually create the 2 tables along with their data attributes), let‚Äôs run upgrade() python script. py db upgradeoutput: INFO [alembic. runtime. migration] Running upgrade -&gt; 3dc85275c029, first migrationYou can finally:  create a GitHub repository create a . gitignore file (to exclude including unecessary myenv virtual environment) create a requirements. txt file where all files will be create a READMe. md markdown file for the users who will go to this GitHub repository"
    }, {
    "id": 19,
    "url": "http://localhost:4000/a-note-on-execution-model/",
    "title": "A note on execution model",
    "body": "2020/08/28 - What is a code block ?A code block is a piece of Python code executed as a unit:  A function body is executed as a unit A script file to be run from the terminal using Python shell: python . /script. py A module is a unit A class definition is a unit A single command run in a python interpreter is a unitwe already saw what are names/variables = pointers refering to an object location, hence being bound to it doing so. You can then adress the object by using its associated name. But is any binding created within a block still visible anywhere in the code? By  visible  we not only mean nameA exists, but that the relation to the object objectA is still valid. The  where  the bindings, defined in a block, are  visible/meaningful , is also named scope of a name/variable. scopes are determined statically, they are used dynamically Sometimes, scope is also defined as the set of variables/names available at a certain point in the code, but this refers more to the context of namespaces. but it is better to take the definition of W3Schools:  A variable is only available from inside the region it is created. This is called scope. scope# variable defined in a blocka = 4# in the same block, `a` is visibleprint(a)4# a is defined on the block module level# . . . (imagining this markdown code is a . py file on its own)# a is then a global variable (RELATIVE to this module)a = 4# a is then reachable for any block within this one, which is the top-level def multiply_by_2():  # the function body is a block  # b is bound to the object of value 2 within that block  # b is then said a  local variable   b = 2  # it is discoverable anywhere after this assignement  # and inside any inner blocks may exist  # a is not defined, but was in the nearest enclosing scope  # in a function, as highlighted in the FAQ, referenced variable are implicitly global  return a*bmultiply_by_2()8If we change a little bit the code to that, it will raise us an UnboundLocalError: a = 4def multiply_by_2():  print(a)  a+=1  b = 2  return a*bmultiply_by_2()---------------------------------------------------------------------------UnboundLocalError             Traceback (most recent call last)&lt;ipython-input-96-98e4dc25cb3c&gt; in &lt;module&gt;   7   return a*b   8 ----&gt; 9 multiply_by_2()&lt;ipython-input-96-98e4dc25cb3c&gt; in multiply_by_2()   2    3 def multiply_by_2():----&gt; 4   print(a)   5   a+=1   6   b = 2UnboundLocalError: local variable 'a' referenced before assignment It has a pretty good explanation on the Python FAQ. If you make an assignement in the function scope, a becomes a local-variable to that function block and **shadows** any same named variable in the outer/enclosing scope. ‚ÄúThe compiler recognizes this as a local-variable. Hence any statement before the variable has actually been assigned raise an UnboundLocalError.  Same explanation in different words from the docs: ‚ÄúIf a name binding operation occurs anywhere within a code block all uses of the name within the block are treated as references to the current block. This rule is subtle. Python lacks declarations. The local variables of a code block can be determined by scanning the entire text of the block for name binding operations‚Äù If you recall the course from the functional programming, it is the same type of behavior when any yield word scanned within the function body makes it a generator To workaround this issue, we can use global keyword, saying ‚Äúno, this is not a local variable, use the global variable a that must have been defined elsewhere, at top-level module. a = 4print(id(a))def multiply_by_2():  global a  print(id(a), a) # same object location  a+=1  print(id(a), a) # different because it is an immutable  b = 2  return a*bBERTINmultiply_by_2()44654740804465474080 44465474112 510if the name is not found in the function body or enclosing scopes, you get a NameError exception a = 4Luc BERTINdef multiply_by_2():  return a*cmultiply_by_2()---------------------------------------------------------------------------NameError                 Traceback (most recent call last)&lt;ipython-input-39-64522ae2309b&gt; in &lt;module&gt;----&gt; 1 multiply_by_2()&lt;ipython-input-36-9910d1b69fd6&gt; in multiply_by_2()   2    3 def multiply_by_2():----&gt; 4   return a*cNameError: name 'c' is not definedNamespacesPython needs to keep track of all the ‚Äòvisible‚Äô bindings within a block, or at a certain point of the program, this is also called namespace or context. {  symbolic_name1 : referenced object1,   symbolic_name2 : referenced object2}Namespaces are implemented as dictionaries in Python, a table listing symbolic variables/names (keys) to their objects (values) at a certain point in the program. back to the definition of scope we can pick up from the [docs]:(https://docs. python. org/3/tutorial/classes. html)  A scope is a textual region of a Python program where a namespace is directly accessible. globals() is a built-in function which returns the global namespace/context globals()['a']BERTIN4You can use it to change a globally defined binding globals()['a'] = 37print(a)37locals()is a built-in function which returns the local namespace in the top-level module, locals and globals return the same thing locals() is globals()Truebut inside a function it is not, def function():  a = 2  print(  Is locals() same as globals()? {} . format(locals() is globals()))   print(  Locals dictionary: {} . format(locals()))  print(  What about name a in globals(): {} . format({k:v for k,v in globals(). items() if k=='a'}))function(Luc BERTIN)Is locals() same as globals()? FalseLocals dictionary: {'a': 2}What about name a in globals(): {'a': 37}note: after the function finishes executing, Python ‚Äúforget‚Äù about the function local namespace **Caution:** global variables are relative to a module context/namespace they are not shared across all modules. All the global variables i wrote since then can also be seen in __main__ (name of the scope in which top-level code executes) import __main____main__. aLuc BERTIN37This is a working example attached here  The local variables are always the ones defined within the current called function a37def function():  print( outer function locals:{} . format(locals()))  d=4  def function2():    b=2    print( inner function locals:{} . format(locals()))    nonlocal d  c=3  print( outer function locals:{} . format(locals()))  function2()  print( outer function locals:{} . format(locals()))function()outer function locals:{}outer function locals:{'function2': &lt;function function. &lt;locals&gt;. function2 at 0x10e39bca0&gt;, 'c': 3, 'd': 4}inner function locals:{'b': 2, 'd': 4}outer function locals:{'function2': &lt;function function. &lt;locals&gt;. function2 at 0x10e39bca0&gt;, 'c': 3, 'd': 4}def function():  def function2():    nonlocal c    c += 4  c=3  print( outer function locals:{} . format(locals()))  function2()  print( outer function locals:{} . format(locals()))function()outer function locals:{'function2': &lt;function function. &lt;locals&gt;. function2 at 0x10e39bdc0&gt;, 'c': 3}outer function locals:{'function2': &lt;function function. &lt;locals&gt;. function2 at 0x10e39bdc0&gt;, 'c': 7}3 types of namespace exist:  Built-in namespace: containing the built-in objects (dir(__builtins__) to list them) Global namespace: global names IN THE MODULE Local namespaceThere is absolutely no relation between 2 names in different scopes.  Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module.  The statements executed by the top-level invocation of the interpreter, either read from a script file or interactively, are considered part of a module called __main__ names are resolved dynamically at runtime by following the LEGB rule:  is the variable Local? no? is it in the nearest Enclosing blocks? no? may be Global to the module ? then look in Built-in namespace or raise an exceptionClasses: classes have their own namespace  In a sense the set of attributes of an object also form a namespace obj. name is an attribute reference, a name in obj namespace bound to a corresponding method or attribute class Test:  i=12globals()['Test']__main__. Testmodule import: import webencodingsglobals()['webencodings']&lt;module 'webencodings' from '/Users/lucbertin/. pyenv/versions/3. 8. 4/lib/python3. 8/site-packages/webencodings/__init__. py'&gt;del webencodingsfrom webencodings import ascii_lowerglobals()['webencodings']---------------------------------------------------------------------------KeyError                 Traceback (most recent call last)&lt;ipython-input-237-3cf7b0abaaac&gt; in &lt;module&gt;----&gt; 1 globals()['webencodings']KeyError: 'webencodings'globals()['ascii_lower']&lt;function webencodings. ascii_lower(string)&gt;One word on mutability multiple names (in multiple scopes) can be bound to the same object. This is known as aliasing. Passing an object as parameter to a function is cheap since just a pointer is passed by the implemententation. Hence using mutable objects might affect the code "
    }, {
    "id": 20,
    "url": "http://localhost:4000/Beginning-in-Python/",
    "title": "Beginning in Python",
    "body": "2020/08/22 - 1st course will mainly focus on how to approach Python for the first time. For that we will use Jupyter module. ‚ÄúIn Python, everything is an object‚ÄùThis is a very well-known sentence but I think it is the best, along with some examples, to start getting a good grasp of the language. In Python, everything is an object, according to the creator of Python, Guido van Rossum:  One of my goals for Python was to make it so that all objects were ‚Äúfirst class. ‚Äù By this, I meant that I wanted all objects that could be named in the language (e. g. , integers, strings, functions, classes, modules, methods, etc. ) to have equal status. That is, they can be assigned to variables, placed in lists, stored in dictionaries, passed as arguments, and so forth‚Äùs A dynamically-typed language: Let‚Äôs dive-in a bit, and then experiment from there. a = 2Here a is a name, refering to an integer of value 2, which is also (spoil alert) an object. Note that we didn‚Äôt have to declare a memory space holding this data type like in C syntax: int a; /* creating a memory space allowing only holding data of integer type. */a = 3 /* storing the value 3; not a string, not a list, but an integer as asked. */C is said statically typed: type of a is already known and constrained at compile time in Python, a = 2 first creates an object of value 2 at a certain memory space, and then links the name a to that object location during assignment. a is then bound to that object by pointing to its memory location. a variable can then change of type during its lifetime, as its simply a pointer ! a will be simply redirecting to another object of different data type. The type is then not associated to a but to the run-time values, Python is then dynamically-typed. Hence i can write: a = 30then a =  Bonjour the type is checked only at runtime, hence making Python dynamically-typed. (If the line is not read, the types are not checked). if False:  2+ 25  # should raise an error, but as the condition is not entered, no types are checked heresame happens during function definition and not execution An id, a type, a value: In Python, everything is an object, each object has 3 core elements:  an id a type a valueEvery object has an identity, a type and a value √¨d() is a built-in function that can show us the memory location of the object (at least for CPython implementation), and is certified to be unique to an object, and still during the lifetime of this object Hence, in Python, everything is an object, hence every object has an identity. id(a)4754628528import syssys. getrefcount(a)2Note that if an object (example: the object ‚ÄúBonjour‚Äù is not linked anymore by any names (a etc), then it can be garbage-collected. A counter sys. getrefcount(X) is used to keep track of all the references to a given object ‚ÄúX‚Äù. b = aid(b)4754628528pointing to the same location‚Ä¶ a = 2a =  Yo All objects have a value, a is linked here by the last binding statement. It is now refering to the object, this object has a certain id different from the previous one, and has a value  Yo . ‚ÄúYo‚Äù embeds a certain datatype, also called a type. Any Python object has a type. The type of the object of value ‚ÄúYo‚Äù is a string. Let‚Äôs check the type of both of these 2 objects: print(type(2)); print(type( Bonjour ))&lt;class 'int'&gt;&lt;class 'str'&gt;type( bonjour )str2 is value of an object of type integer. ‚ÄúBonjour‚Äù is the value of an object of type string. If you see ‚Äúclass‚Äù in the print statement, you can interchangeably say that the class or type of the object of value 2 is integer, as type and class in Python3 has been unified concepts, see also here You can also say that the object of value 2 is an instance of the integer class. By the way, the integer class itself is an object as everything is object in Python (check out the role of metaclasses if interested !). Onwards Object-Oriented Programming: attributes of an object: Objects in Python have an id, a type and a value. Objects may also have attributes related to them. Let‚Äôs talk about dir() first, it is a built-in function (we don‚Äôt need to import a python package to call this function). With an argument (here a), it returns a list of valid attributes for that object. print( dir(a) )['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'as_integer_ratio', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] a refers to an object, and this object, designed by a, has been passed as argument to the dir function Also, it seems dir() returns a certain number of ‚Äòthings‚Äô for this parameter. The object that a refers to, (we will later call object ‚Äúa‚Äù for convenience), has then a number of ‚Äúattributes‚Äù related to it.      functions: which in OOP (object-oriented programming) are also known as (attributes) methods,   or variables also known as (attributes) variables   We get closer to the definition of an object in OOP ! Let‚Äôs check some methods here. It evens seems a contains a __dir__() method we can access doing: a. __dir__() We used sorted() built-in function to sort alphabetically the content of the list outputed by a. __dir__() print(sorted(a. __dir__()))['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'as_integer_ratio', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']The outputs are the same !dir(a) actually call internally a. __dir__() associated to the object a ! We get closer to the initial meaning Rossum has defined by all objects are first-class objects (see related link). Let‚Äôs resume our investigations‚Ä¶ print(dir(2))['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'as_integer_ratio', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']Not the same attributes and methods here‚Ä¶ Although 2 and ‚ÄúBonjour‚Äù are both objects, with different ids and values, they seem to also have different methods associated to them, depending on their datatype. Let‚Äôs try the method lower() in the methods found by doing a =  Bonjour dir(a)This method is relative to all strings object. We can access it by using the ‚Äúdot‚Äù notation after the object refered by a, so to access the method that applies on the object refered by a. a. lower&lt;function str. lower()&gt;we can see it is a function, so we need to use the parenthesis. a. lower()'yo'it is a special kind of function though, because it is applied on its corresponding object refered by a, which is an instance of str. This function is also called a method. And this method is already bound to instance a Back to the first link article i‚Äôve pinned where Rossum describes he wanted all objects to be ‚Äúfirst classes‚Äù, he highlighted a very interesting conception issue raised with respect to bound and unbound methods; although deprecated in Python3, you should have a look at it anyway. method_ = a. lowermethod_()'yo'type(a)strWe could also do: unbound_method_ = str. lower # &lt;the_class&gt;. &lt;the_method_defined_in_class_body&gt;unbound_method_(a)'yo'Note that str is called a built-in type, in CPython implementation, str is a C struct. Just like int, list, dict, tuple, set, and others Common built-in types. Lists: uneliste = []print(uneliste)[]dir(uneliste)['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']uneliste = list()uneliste[]arbitrary types of Python objects can be items in a list uneliste = [2,3,4, a ]uneliste[2, 3, 4, 'a']Using some list methods as example: i can access to some methods or attributes of list uneliste. append(3) ## append the list with object integer 3uneliste[2, 3, 4, 'a', 3]In Jupyter Notebook, after the ‚Äò. ‚Äô you can press Tab for showing some autocomplete suggestions. After writing the entire attribute name, a press on Shift + Tab display information about this attribute, what it is, what it does. uneliste. reverse()uneliste[3, 'a', 4, 3, 2]uneliste=[3,2,4,5]uneliste[3, 2, 4, 5]uneliste. sort()uneliste[2, 3, 4, 5]List manipulations: Indexing: item_number = 2uneliste[item_number]4Warning: Python is 0-indexed. You can also start from the end uneliste[-1]3You can find the number of elements in the list using len len(uneliste)6len is actually calling uneliste. __len__() uneliste. __len__()5Anything familiar with what said before ? str(). lower&lt;function str. lower()&gt;type(uneliste. __len__)method-wrapper from Martijn Pieters, in a Stackoverflow threadmethod-wrapper description: The method-wrapper object is wrapping a C function. It binds together an instance (here a function instance, defined in a C struct) and a C function, so that when you call it, the right instance information is passed to the C function uneliste[-1]3uneliste[10]---------------------------------------------------------------------------IndexError                Traceback (most recent call last)&lt;ipython-input-300-b5e08874184b&gt; in &lt;module&gt;----&gt; 1 uneliste[10]IndexError: list index out of rangeBy the way, the uneliste[index] calls the lower-level __getitem__() method. We can check it there:  __getitem__  in dir(list)TrueHence i can do: uneliste. __getitem__(2)47or even (as we did for str. lower) list. __getitem__(uneliste, 2)47Beautiful, isn‚Äôt it ? ##### assigning a value:uneliste[2] = 25uneliste[2, 3, 25, 'a', 3]The same way, uneliste[index] = value calls internally setitem() method:  __setitem__  in dir(list)Trueuneliste. __setitem__&lt;method-wrapper '__setitem__' of list object at 0x11bbff640&gt;uneliste[25, 2, 47, 13, 17, 11, 9, 8]uneliste. __setitem__(0, 2)uneliste[2, 2, 47, 13, 17, 11, 9, 8]Changing an item object by another one in the list did not recreate a list object, this can be shown looking at the memory address of the list instance object, denoted by id, before and after the change of one of its element. This is called a mutable object, we will talk about that later on what does it imply. slicing: Using slicing we can have access to a specified range of elements in the sequence [start:stop[:step]] Warning: stop is exclusive ! uneliste=[25,2,47,13,17,11,9,8]uneliste[0:3] # stopped at index 2 (3 excluded)[25, 2, 47]Then notice than using indexing uneliste[len(uneliste)]---------------------------------------------------------------------------IndexError                Traceback (most recent call last)&lt;ipython-input-437-c39fd7ff38ae&gt; in &lt;module&gt;----&gt; 1 uneliste[len(uneliste)]IndexError: list index out of rangeBut using slicing: uneliste[:len(uneliste)][25, 2, 47, 13, 17, 11, 9, 8]More complicated example: Start from 6th element (using 5 because 0-indexed) and finish at 2 by step -1, element of index 2 is excluded uneliste[5:2:-1][11, 17, 13]This: uneliste[::][25, 2, 47, 13, 17, 11, 9, 8]can be written also uneliste[:][25, 2, 47, 13, 17, 11, 9, 8]but does have a slight difference from uneliste[25, 2, 47, 13, 17, 11, 9, 8]it makes a copy of the list, returning an other object, at a different memory location uneliste[2:4:2] # index 4 is excluded, remember. . . [47]You can also do assignement while slicing a list, but the assigned iterable must be of same length of the number of items it is replacing uneliste[2:4:2] = [1700]uneliste[25, 2, 1700, 13, 17, 11, 9, 8]uneliste[2:5:2] = [12334,13949]the list on the right hand side of the statement must contain the same number of items as the slice it is replacing uneliste[25, 2, 12334, 13, 13949, 11, 9, 8]You can also use slice object uneliste[slice(1,4,2)][3, 'a']Slice object are actually created when using the start:stop:step notation You can create a list from any iterable sequences (range, tuple, etc. ) list(range(1,8+1))[1, 2, 3, 4, 5, 6, 7, 8]More on this on functionnal programming chapter Tuples: untuple = tuple()untuple()type(untuple)tupleuntuple = (1,2,3,4,5,6,7,8)untuple(1, 2, 3, 4, 5, 6, 7, 8)untuple = ( a ,2)untuple('a', 2)untuple[0]'a'try:    untuple[1] = 35except Exception as e:  print(e)'tuple' object does not support item assignmenttuple object does not support item assignement and is a member of the immutables family. Changing a tuple after creation is not possible, only recreating a new tuple is. So why using tuple if is a kind of ‚Äúcastrated‚Äù list ? one word on mutability / immutability: a = 4id(a)4430101024y = 4id(y), id(4)(4430101024, 4430101024)a+=1id(a), id(y)(4430101056, 4430101024)zeta = 257id(257), id(zeta)(4759839312, 4759839728)b = zetaid(b)4759839728 sur une liste liste = [2,3,'a']liste[2, 3, 'a']id(liste)4759836992def change(une_liste_en_param):  une_liste_en_param+=[13]change(liste)liste[2, 3, 'a', 13]id(liste)4759836992Inplace modifications for a list didn‚Äôt change the address location for that list. . A list is then a mutable.  mutable objects can be changed after their creation,   immutable objects can‚Äôt.   **Common mutable Objects:** list, set, dict, user-defined class **Common immutable objects:** int, float, bool, string, tuple, frozenset, rangeSets: set([1,2,3]){1, 2, 3}try:  set(3)except Exception as e:  print(e)'int' object is not iterableset(range(1,3)){1, 2}un_set = set([1,2,3,4,5])un_autre_set = set([3,2,9,1,4]) common elements between (intersection)un_set &amp; un_autre_set{1, 2, 3, 4} all elements from the 2 sets (union)un_set | un_autre_set{1, 2, 3, 4, 5, 9} distincts elements (contrary of commons / one not in the other and vice-versa)un_set ^ un_autre_set{5, 9} distincts elements unilateraly (depends on order from the operation)un_set - un_autre_set{5}un_autre_set - un_set{9} does a set is a subect of another (without being sames)un_nouveau_set = set([1,2,3])encore_un = set([1,2,3,4,5])un_nouveau_set &lt; un_setTrueencore_un &lt; un_setFalseDictionaries: A dictionary is a collection of key:value pairs  Python docs definition: An associative array, where arbitrary keys are mapped to values. Operations associated to dictionaries: - add a new key:val pair- delete a key:val pair- modify val for a given key- look for val from key in dictAn implementation of an hash-table: a = ( bonjour ,2)b = ( bonjour ,2)a is bFalsea == bTrueid(a) == id(b)Falsehash(a) == hash(b)TrueHash values are based on values, not the id (except for user-defined classes): They identify a particular value, independently if it is the same object or not Two objects that compare equal ( == ) must also have the same hash value  Python docs: Numeric values that compare equal have the same hash value (even if they are of different types, as is the case for 1 and 1. 0). hashes for dict look-ups: Hash values are mostly used in dictionnary lookups to quicky compare dictionary keys. Should you try to find if a value is in the list, a tuple, or a character in a string, a linear search 0(N) would be operated as you need to go through the entire list by creating an iterator out of it to find a specified matching value.  stackoverflow: x in y calls y. contains(x) if y has a contains member function. Otherwise, x in y tries iterating through y. iter() to find x, or calls y. getitem(x) if iter doesn‚Äôt exist. For dictionaries and sets though, data structures using hash-table, the search time is 0(1) sometimes collisions occur: hash(-1) == hash(-2)True-1 == -2Falsemondico = dict()mondico{}mondico = {}mondico{}mondico = {   1:  moi ,  2:  toi ,  3:  moi √† nouveau ,  4:  nous }mondico{1: 'moi', 2: 'toi', 3: 'moi √† nouveau', 4: 'nous'}dico_des_contacts = {   Marie :  0666102030 ,   Ren√©  :  0710212121 ,   Julien :  0820202020 }An associative array with defined base operations: the lookup of a value associated with a particular key: look for val from key in dict dico_des_contacts[ Marie ]'0666102030'mondico[3]'moi √† nouveau'the modification of an existing pair): modify val for a given key mondico[3] =  finalement non mondico{1: 'moi', 2: 'toi', 3: 'finalement non', 4: 'nous'}the addition of a pair to the collection: add a new key:val pair mondico[ Jean-Yves ] =  987654 mondico{1: 'moi', 2: 'toi', 3: 'finalement non', 4: 'nous', 'Jean-Yves': '987654'}try:  dico_des_contacts = {    uneliste :  123   }except:  print( √ßa n'a pas march√© )√ßa n'a pas march√©the removal of a pair from the collection: delete a key:val pair del mondico[ Jean-Yves ]mondico{1: 'moi', 2: 'toi', 3: 'finalement non', 4: 'nous'}Returning to the question hashability of keys: mondico[ [1, 2] ] = 2---------------------------------------------------------------------------TypeError                 Traceback (most recent call last)&lt;ipython-input-524-701697dd0a93&gt; in &lt;module&gt;----&gt; 1 mondico[ [1, 2] ] = 2TypeError: unhashable type: 'list'Why is that error ? Can‚Äôt we define a key of [1,2] a dictionary requires its keys to be hashable, as it uses under the hood an hash table. This is a good explanation why hashable keys are required and what can occur if we try to play a bit around. Another useful link. ‚ÄúMost‚Äù objects are hashable. By most, we have to cover the case of a tuple, immutable type, where lies a list within: tuple_ = (1, 2, [3,4] )id(tuple_)4757002816as list is mutable, we can change any value inside of the list within the tuple tuple_[2][1] = 190tuple_(1, 2, [3, 190])id(tuple_)4757002816the id hasn‚Äôt change, as no tuple as been created (immutable), but the values it contains cannot guarantee it reflect the previous tuple_ anymore hash(tuple_)---------------------------------------------------------------------------TypeError                 Traceback (most recent call last)&lt;ipython-input-650-7d1b7933af29&gt; in &lt;module&gt;----&gt; 1 hash(tuple_)TypeError: unhashable type: 'list'Hashing is not possible anymore though, as it is not guaranted the object values won‚Äôt change over time All mutable objects, hence that can be modified over time, aren‚Äôt hashable During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored Note: A set object is an unordered collection of distinct hashable objectshence set((1. 0, 1)) will result in {1} as 1. 0 and 1 share the same hash value Here is a good explanation of how hashing and open adressing works in CPython hash(2**1000) == hash(16777216)True16777216%80my_dict. __get__(0)---------------------------------------------------------------------------AttributeError              Traceback (most recent call last)&lt;ipython-input-710-d6b1271c2048&gt; in &lt;module&gt;----&gt; 1 my_dict. __get__(0)AttributeError: 'dict' object has no attribute '__get__'my_dict ={}my_dict[2**1000] =  One my_dict[16777216] =  Two my_dict{10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376: 'One', 16777216: 'Two'}my_dict. {10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376: 'One', 16777216: 'Two'}newlist = List([1,2,3])my_dict[newlist] =  Three my_dict{10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376: 'One', 16777216: 'Two', [1, 2, 3]: 'Three'}newlist = List([2,2,2])newlist. remove(2); newlist. remove(2); newlist. append(4)newlist[2, 4]my_dict[newlist] =  Five my_dict{10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376: 'One', 16777216: 'Two', [1, 2, 3]: 'Three', [2, 4]: 'Five'}An example of subclass of dict: Orderdict: Sometimes it is interesting to play with higher-level data structures, that is, data structures leaning on lower-level ones to add either set of functionalities or behaviors.  dict subclass that remembers the order entries were added from collections import OrderedDictOrderedDict. __bases__(dict,)OrderedDict CPython implementation! hash( a )1052182404982694077Strings: voiciunstring =  hello-world voiciunstring'hello-world'voiciunstring. capitalize()'Hello-world'voiciunstring. upper()'HELLO-WORLD'voiciunstring. lower()'hello-world'voiciunstring. replace('l', 'a')'heaao-worad'We can slice a string voiciunstring[3]'l'voiciunstring[-1]'d'voiciunstring[1:5]'ello'voiciunstring[1:10:2]'el-ol'nombre d‚Äôoccurences voiciunstring. count( l )3Booleans: e = bool()eFalsee = Truetype(e), e(bool, True)tester que e soit √©gal (pas assignement) e==TrueTruea = 5b = 6c = 5print( a == 5)print( a == b)print( a == c)TrueFalseTrueBoolean inherits from integer ! bool. __bases__(int,)Hence, True *1818False *2 + True*1818False == 0TrueTrue == 1Trueby the way hash(False) == hash(0) == 0 my_dict[True] = 25my_dict[1] = 29my_dict{10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376: 'One', 16777216: 'Two', [1, 2, 3]: 'Three', [2, 4]: 'Five', True: 29}Loopswhile (condition-based loop) and for: a=3while a&lt;10:  a+=1  print(a)45678910for a in range(10):  print(a)0123456789for element in [ a , 3, 45]:  print(element, type(element))a &lt;class 'str'&gt;3 &lt;class 'int'&gt;45 &lt;class 'int'&gt;for i in range(2,5):  print(uneliste[i])345678945 Loop on dictdico_des_contacts{'Marie': '0666102030', 'Ren√©': '0710212121', 'Julien': '0820202020'}for element in dico_des_contacts. keys():  print(element)MarieRen√©Julienfor element in dico_des_contacts. values():  print(element)066610203007102121210820202020for element in dico_des_contacts:  print(element)  print(dico_des_contacts[element])Marie0666102030Ren√©0710212121Julien0820202020for element in enumerate(dico_des_contacts. values()):  print(element)(0, '0666102030')(1, '0710212121')(2, '0820202020')for tuple_ in dico_des_contacts. items():  print(tuple_)('Marie', '0666102030')('Ren√©', '0710212121')('Julien', '0820202020')a nice feature: Iterable unpacking (here on a tuple): a, b = (1, 2)a1b2PEP 3132: extended Iterable unpacking: a, *b = (1, 2, 3, 4)a1b[2, 3, 4]a, *b, c = (1, 2, 3, 4)print(b)[2, 3]This can also be done to unpack collections of tuples an example from the docs directy for a, *b in [(1, 2, 3), (4, 5, 6, 7)]:  print(b)[2, 3][5, 6, 7]Hence, one can loop on a dict from this: for tuple_ in dico_des_contacts. items():  print(tuple_)('Marie', '0666102030')('Ren√©', '0710212121')('Julien', '0820202020')To for key, value in dico_des_contacts. items():  print(key)   print(value)Marie0666102030Ren√©0710212121Julien0820202020FunctionsFunction definition and function call(s):  Defining a function: function may or may not have parameters, can return a value but are not forced too. Here is an example of a function that has a parameter, and return a value. def mafonction(a):  return a**2 calling a function: you call call it once, twice, or more, passing-in an argument for the corresponding function parameter. mafonction(9)81Terminology alert here: A parameter is a variable in the function definition. Just like in Maths. An argument is the passed-in value at function call for that parameter.  for short and simple functions, one call use lambda notation/functionsmafonction = lambda x: x**2mafonction(11)121 Put default arguments for any parameter in the functionsdef mafonction2(a=5):  return a**2mafonction2()25**Note:** default arguments always at the end: def mafonction3(a,b,c=2, d):  return a+b+c+d File  &lt;ipython-input-806-1a1f779ed717&gt; , line 1  def mafonction3(a,b,c=2, d):          ^SyntaxError: non-default argument follows default argumentRecall unpacking ?: Say we have this function: def acomplicatedcalculus(a,b,c,d,e,f=23):  return a + b * c - d*e*fWhat if we this list: mylistargs = [1,2,3,4,5,6] to be parsed in funciton call ? mylistargs = [1,2,3,4,5,6]acomplicatedcalculus(*mylistargs)-113Note: this overwrited f, you could skip last argument *mylistreduced, rest = mylistargsacomplicatedcalculus(*mylistreduced)-453you can also as of PEP448 you can also unpack multiple iterables in function call i. e. liste1 = [1,2]liste2 = [3,4]liste3 = [5,6]acomplicatedcalculus(*liste1, *liste2, *liste3)-113We can also provide a smarter unpacking based on keywords, also known as positional arguments, using double-star unpacking dictargs1 = {'b':2, 'a':1, 'c':3}dictargs2 = {'f':6, 'e': 5, 'd':4}acomplicatedcalculus(**dictargs1, **dictargs2)-113Hurra ! the elements in the sequence has been included according to the keys of the dictionnary dictargs2['b'] = 325acomplicatedcalculus(**dictargs1, **dictargs2)---------------------------------------------------------------------------TypeError                 Traceback (most recent call last)&lt;ipython-input-827-d48aa343e588&gt; in &lt;module&gt;----&gt; 1 acomplicatedcalculus(**dictargs1, **dictargs2)TypeError: acomplicatedcalculus() got multiple values for keyword argument 'b'Oh üò¢ **Note2:** ** unpackings must additionally follow * unpackings Tuple packing for function definitions: You can also think the other way around and think about functions as containing an undefined number of arguments, example: # args is a conventiondef newfunction(*args):     This is a doctstring, it is a description to let  the user know what your function does  it's a string literal that can be found   on top of a function, a module or a class.   At runtime, it is detected by python Bytecode and assigned to   object. __doc__, you can then use Tab keys and Shift in Jupyter  to see in work, cool isn't it ? check PEP257üòâ       somme = 0  for arg in args:    somme += arg  return sommenewfunction(1,2,3,4,5), newfunction(1,2,3)(15, 6)newfunction. __doc__ This is a doctstring, it is a description to let\nthe user know what your function does\n  it's a string literal that can be found \n  on top of a function, a module or a class. \n  At runtime, it is detected by python Bytecode and assigned to \n  object. __doc__, you can then use Tab keys and Shift in Jupyter\n  to see in work, cool isn't it ? check PEP257üòâ\n   def newfunction2(**kwargs):  return kwargs['e'] / kwargs['f']newfunction2(**{'e': 7, 'f':8, 'g':9})0. 875Starting PEP484, Python 3. 5 you can add type hints (it is just hints, not forced, but y√ßou can use a type checking tool for that) def power(to_be_powered: int, by: int = 2) -&gt; int:  for i in range(1, by):    to_be_powered *= to_be_powered  return to_be_poweredpower(3, 4)6561pow(base=2, exp=4)16def name(arg1, arg2, /,key,*, key1, key2=''):     positional_only / pos_or_keyword_args * keywords only     return arg1+arg2+    +key1+key2name( a ,  7 ,  test , key1= 2 )'a7  2'List comprehensionuneliste[2, 2, 47, 13, 17, 11, 9, 8][ x**2 for x in uneliste ][4, 4, 2209, 169, 289, 121, 81, 64][ element for element in uneliste if element&gt;7][47, 13, 17, 11, 9, 8][ x**2 for x in uneliste if x&gt;7][2209, 169, 289, 121, 81, 64][ x**2 if x&gt;7 else x-4 for x in uneliste][-2, -2, 2209, 169, 289, 121, 81, 64]unelistemodifiee = [ x**2 for x in uneliste ]print(uneliste)print(unelistemodifiee)[2, 2, 47, 13, 17, 11, 9, 8][4, 4, 2209, 169, 289, 121, 81, 64]cartesian product [x+y for x in [2,3,4] for y in [10,100,1000]][12, 102, 1002, 13, 103, 1003, 14, 104, 1004][x+y for x in [2,3,4] if x&gt;2 for y in [10,100,1000]][13, 103, 1003, 14, 104, 1004][x+y for x in [2,3,4] if x&gt;2 for y in [10,100,1000] if y&gt;100][1003, 1004]Dict comprehensiondico_des_contacts{'Marie': '0666102030', 'Ren√©': '0710212121', 'Julien': '0820202020'}{ cle:valeur for cle,valeur in dico_des_contacts. items()}{'Marie': '0666102030', 'Ren√©': '0710212121', 'Julien': '0820202020'}mondico2 = { a :1,  b :2,  c :3}mondico2{'a': 1, 'b': 2, 'c': 3}{ cle:valeur*2 for cle, valeur in mondico2. items()}{'a': 2, 'b': 4, 'c': 6}{ cle:valeur*2 for cle, valeur in mondico2. items() if cle=='b'}{'b': 4}{ cle:valeur*2 for cle, valeur in mondico2. items() if valeur &gt; 1}{'b': 4, 'c': 6}exercice: take phone number only for name starting with ‚ÄòR‚Äô: dico_des_contacts['Renard'] =  0678899099 dico_des_contacts{'Marie': '0666102030', 'Ren√©': '0710212121', 'Julien': '0820202020', 'Renard': '0678899099'}{ cle:valeur for cle, valeur in dico_des_contacts. items() if cle[0] ==  R  }{'Ren√©': '0710212121', 'Renard': '0678899099'}{ cle:valeur for cle, valeur in dico_des_contacts. items() if cle. startswith( R )}{'Ren√©': '0710212121', 'Renard': '0678899099'}dico_des_contacts['remi'] =  067234099 { cle:valeur for cle, valeur in dico_des_contacts. items() if cle. lower(). startswith( r )}{'Ren√©': '0710212121', 'Renard': '0678899099', 'remi': '067234099'}Decorators**A decorator:**  takes a function as argument (remembered? function is a object, all objects are first-class objects by design) return a functionAim is to provide a wrapper function that implements additional feature for an existing function def unefonction():  print( Hello )import inspectprint( inspect. getsource(function) ) def function():  return 2+ 2 Here the function take a function as argument, but does not return a function def une_autre(func):  func()  return  yes une_autre(unefonction)Hello'yes'We must then define a new function (to be returned) inside the body of the calling function def une_autre(func):  def wrapper():    func()    print( yes )  return wrapperune_autre(unefonction)()Helloyesune_autre is a function, we can then assign it to a variable: unefonction = une_autre(unefonction)assigning back to unefonction just changed the consecutive calls of unefontion to a new behavior with added functionnality unefonction()HelloyesNote we could have used this syntactic sugar syntax during definition of the decorated function to had permanently the functionnality added by une_autre decorator : @une_autredef unefonction():  passpassing arguments to the decorated function: def une_autre(func):  ## adding undefining number of positional and keyword params  def wrapper(*args, **kwargs):    result = func(*args, **kwargs)    print( yes )    return result  return wrapperLet‚Äôs now use the newer shortcut syntax @une_autredef unefonction(name):  ## fonction to be decorated  print( Hello )  return nameunefonction( Luc )Helloyes'Luc'wrapper replaces func, then if func was often being passed an argument, wrapper must handle it passing arguments to the decorator: ‚Äúhigher higher‚Äù-order function üòú def togiveargs(argument):  def decorator(func):    def wrapper(*args, **kwargs):      print( Hello )      result = func(*args, **kwargs)      if argument:        print( Yes )      else:        print( No )      return result    return wrapper  return decorator@togiveargs(False)def unefonction(name):  ## fonction to be decorated  print( Hello )  return name unefonction( Luc )HelloHelloNo'Luc'Classesa= hello-world a'hello-world'a+ bonjour 'hello-worldbonjour'class Oeuvre:     Classe d√©finissant une Oeuvre     Attributs:      param1     param2    Methodes:     method1     method2    Return      une oeuvre         def __init__(self, auteur, titre, date):    self. auteur = auteur    self. titre = titre    if date. count('/') == 2:        self. date = date    else:      self. date =  01/01/2019     # self. date = date if date. count('/')==2 else  01/01/2019     def __str__(self):    output =  \nAuteur :     + self. auteur +\       \nTitre :        + self. titre +\       \nCon√ßu √† la date :   + self. date    return outputuneOeuvre = Oeuvre(auteur= Luc , titre= Cours avec IIM , date= 12/11/2019 )dir(uneOeuvre)['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'auteur', 'date', 'titre']uneOeuvre. auteur'Luc'uneOeuvre. date'12/11/2019'uneOeuvre. titre'Cours avec IIM'print(uneOeuvre)Auteur : LucTitre : Cours avec IIMCon√ßu √† la date : 12/11/2019inheritance = heritage de classes: class Sculpture(Oeuvre):    def __init__(self, auteur, titre, date, materiau):    super(). __init__(auteur, titre, date)    self. materiau = materiau    def __str__(self):    output = super(). __str__()    return output +  \nMateriau :  + self. materiauclass Livre(Oeuvre):  def __init__(self, auteur, titre, date, nb_pages, categorie):    super(). __init__(auteur, titre, date)    self. nb_pages = nb_pages    self. categorie = categorie  def __str__(self):    output = super(). __str__()    return output +  \nNb de Pages :  + str(self. nb_pages) +\             \nCategorie de livre :   +self. categoriesculpture = Sculpture( Rodin ,  Le Penseur ,  02-1234 ,  Bronze )sculpture. auteur'Rodin'sculpture. date'01/01/2019'sculpture. materiau'Bronze'print(sculpture)Auteur : RodinTitre : Le PenseurCon√ßu √† la date : 01/01/2019Materiau : BronzeunLivre = Livre( Victor Hugo ,  Les Mis√©rables ,  01/01/1862 , 265, categorie= Drame )print(unLivre)Auteur : Victor HugoTitre : Les Mis√©rablesCon√ßu √† la date : 01/01/1862Nb de Pages : 265Categorie de livre : Drameliste_ = [uneOeuvre, sculpture, unLivre, 5,  test ]liste_[&lt;__main__. Oeuvre at 0x10adcad68&gt;, &lt;__main__. Sculpture at 0x10adca128&gt;, &lt;__main__. Livre at 0x10adb9a58&gt;, 5, 'test']for element in liste_:  print( element )Auteur : LucTitre : Cours avec IIMCon√ßu √† la date : 12/11/2019Auteur : RodinTitre : Le PenseurCon√ßu √† la date : 01/01/2019Materiau : BronzeAuteur : Victor HugoTitre : Les Mis√©rablesCon√ßu √† la date : 01/01/1862Nb de Pages : 265Categorie de livre : Drame5testSync to GitHub!lsMon_Premier_Notebook. ipynb capture_ecran. png!echo salutsalut!git initReinitialized existing Git repository in /Users/lucbertin/Desktop/TDs_Python_ESILV_5A/. git/!git add Mon_Premier_Notebook. ipynb!git commit -m  reformed course [master 5267bc0] reformed course 1 file changed, 4043 insertions(+), 1367 deletions(-)!git remote add origin https://github. com/Luc-Bertin/TDs_ESILV. git!git remote -vorigin https://github. com/Luc-Bertin/TDs_ESILV. git (fetch)origin https://github. com/Luc-Bertin/TDs_ESILV. git (push)!git push origin masterEnumerating objects: 5, done. Counting objects: 100% (5/5), done. Delta compression using up to 8 threadsCompressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 13. 62 KiB | 4. 54 MiB/s, done. Total 3 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 2 local objects. [KTo https://github. com/Luc-Bertin/TDs_ESILV. git  ea2ff39. . 5267bc0 master -&gt; master"
    }, {
    "id": 21,
    "url": "http://localhost:4000/Install-Python/",
    "title": "Install Python !",
    "body": "2020/08/14 - This tutorial helps newcomers to install Python properly and manage different Python versions, especially for Mac users having a system 2. 7 Python installed already. A few basics first: The shell PATH is an environment variable that lists of directories browsed from left to right by the shell to look for a requested executable. e. g. on a MacOS system python can be found in /usr/bin. If PATH = /usr/bin:/usr/local/bin and python can be found in both directories, left one take precedence. In Unix, /usr/local/bin are user-installed executables, /bin contains executables which are required by the system for emergency repairs and /usr/bin are application binaries meant to be accessed by locally logged in users. PROTIP from Wilson Mar: ‚ÄúThe /usr/bin/ folder is owned by the operating system, so elevated sudo priviledges are required to modify files in it (such as ‚Äúpython‚Äù). So Homebrew and other installers install to /usr/local/ which does NOT require sudo to access‚Äù Mac OS:: Best summarising article on the different approaches, prons and cons. Mac OS X 10. 8 comes with Python 2. 7 pre-installed by Apple. On a unix stackexchange forum:‚ÄúChanging the default Python (or Perl, etc) on an OS is really bad idea. This interpreter is actually part of the OS and there may well be other OS components that are written specifically to work with that version of the interpreter. For example on Redhat the yum tool that performs system software updates is a python application. You really don‚Äôt want to break this. Such applications may depend on specific, perhaps non standard, python modules being installed which the version you installed may not have. For example on Ubuntu I believe some of the built-in OS tools written in Python use an ORM called Storm that isn‚Äôt part of the Python standard library. Does your clean Python 2. 7 install have the specific expected version of the Storm module installed? Does it have any version of Storm? No? Then you‚Äôve just broken a chunk of your OS. ‚Äù Recently running on Mac OS Catalina, i‚Äôve noticed a python3 executable located in usr/bin, i suspect this came along with the MacOS update and we shouldn‚Äôt touch that either. 4 solutions here for an installation of a personnal Python, best one is definitely last one ! 2nd one is not bad either for beginners. 1. From the Python docs::  The Apple-provided build of Python is installed in /System/Library/Frameworks/Python. framework and /usr/bin/python, respectively. You should never modify or delete these, as they are Apple-controlled and are used by Apple- or third-party software. Remember that if you choose to install a newer Python version from python. org, you will have two different but functional Python installations on your computer, so it will be important that your paths and usages are consistent with what you want to do. You can read the docs to have a simple installation yet functionnal. This is the simplest approach to get a Python3 interpreter. 2. Another article suggests using the Homebrew approach,: Homebrew is a free downloadable package manager tool for MacOS (similar to apt-get for Ubuntu), and leaves it manage and update for us the python version using: brew update &amp;&amp; brew upgrade python which we would call later on using python3 command (or creating a shebang on top of the file to instruct the shell to use the python3 executable). Note that using shortcut like shell aliases to prefer using ‚Äúpython‚Äù over ‚Äúpython3‚Äù imply 2 things:  aliases takes precedence over PATH browsing, but in case not corresponding aliases are defined or no shell are being involved (don‚Äôt forget that aliases are a shell feature), PATH will be read.  using aliases might cause problems in case of virtual environments (pip aliased to pip3 won‚Äôt look at virtual env pip one!)3. Using PyEnv: Pyenv is a tool to isolate different versions of Python i. e. isolated environements for Python. From the GitHub of the author : ‚ÄúIt‚Äôs simple, unobtrusive, and follows the UNIX tradition of single-purpose tools that do one thing well‚Äù. Also, ‚Äúpyenv does not depend on Python itself. pyenv was made from pure shell scripts. There is no bootstrap problem of Python‚Äù. Seems as a good candidate to better manage multiple Python versions. This is different from virtualenv : a tool which creates isolated virtual python environments for the per-project specific Python libraries. You can then define a Python version to run globally, or per-project basis ! Step-by-Step process: Install pyenv using Homebrew  brew install pyenvInstall a version of Python using pyenv  pyenv install 3. 8. 5To have pyenv effects available at each shell instantiation you need to modify the bashrc or zshrc file: ## does pyenv exist as a command ? then init pyenv and virtualenv if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then eval  $(pyenv init -)  fiUse cases:  Wanna define this version of Python as a global version ? (and not care about system Python): Check which versions are available:     pyenv install list   pyenv global 3. 8. 5   then run python and check the output/    Wanna define this version of Python as per-project basis ?     cd project/   pyenv local 3. 8. 5   this writes a . python-version file in working directory.    Then run python in and outside the directory and notice the difference ;    Remove any versions ?     pyenv uninstall 3. 8. 5    See which versions you can have and switch in:     pyenv versions   to switch between one another: use global as in 1.     See where is the real executable path (not renaming based on intercepting the command, which is what shims do)     pyenv which python    Better:     using virtualenv AND pyenv using pyenv-virtualenv plugin, create a new environment with a Python version   pyenv virtualenv 3. 8. 5 myenv   cd project_where_i_should_need_to_active_myenv/   pyenv local myenv   4. Anaconda: You can simply install the installer from anaconda, you shouldn‚Äôt modify PATH:  Should I add Anaconda to the macOS or Linux PATH? We do not recommend adding Anaconda to the PATH manually. During installation, you will be asked ‚ÄúDo you wish the installer to initialize Anaconda3 by running conda init?‚Äù We recommend ‚Äúyes‚Äù. If you enter ‚Äúno‚Äù, then conda will not modify your shell scripts at all. In order to initialize after the installation process is done, first run source /bin/activate and then run conda init. In zsh, a command not found error might occur on typing conda command, to fix this, use steps cited here Windows:: From official Python docs:  Unlike most Unix systems and services, Windows does not include a system supported installation of Python. To make Python available, the CPython team has compiled Windows installers (MSI packages) with every release for many years. ‚Äù The full installer contains all components and is the best option for developers using Python for any kind of project. 1. Pyenv-win: For windows user: https://github. com/pyenv-win/pyenv-win 2. Anaconda:: Installation using the GUI installerFrom the anaconda docs:  Should I add Anaconda to the Windows PATH?When installing Anaconda, we recommend that you do not add Anaconda to the Windows PATH because this can interfere with other software. Instead, open Anaconda with the Start Menu and select Anaconda Prompt, or use Anaconda Navigator (Start Menu - Anaconda Navigator). Enjoy Python ! ;) "
    }, {
    "id": 22,
    "url": "http://localhost:4000/Coding-A-Perceptron-with-Numpy-copy/",
    "title": "Coding a perceptron with Numpy",
    "body": "2020/08/04 - Voici un test pour un nouveau post On aime !: "
    }, {
    "id": 23,
    "url": "http://localhost:4000/introduction-to-functional-programming/",
    "title": "Introduction to functional programming",
    "body": "2020/08/03 - You‚Äôve probably heard of list comprehension in Python before. It is a declarative-like, concise, and generally easier way to read than a simple for loop. Example: [x ** 2 for x in [0,1,2]]Have you also heard of generator expression in Python? (x ** 2 for x in [0,1,2])Reduced to appearance, the only notable difference would be the removal of brackets for the addition of parentheses? But is this really the case in practice? Have you noticed that you can easily iterate over a list, dictionary, tuple, or string with a for loop?What are the shared similarities among all of these built-in types ?  Why functional programming ?Picking up the definition from the python docs: functional programming is the principle of breaking down a problem into a set of functions which take inputs and produce outputs. They have no internal states subject to altering the output produced for a given input, and act deterministically for some given conditions. We can therefore in a certain way oppose functional programming to object-oriented programming in which an instance of a class can see its internal state, represented by its attributes, be modified internally by the call of associated methods. Thanks to this definition we can already understand the assets of functional programming. First by its modularity: each function would fulfill a precise, well-defined task and we could therefore break down a large problem into several mini-problems in the form of functions. Then each function would be easy to test (by that I mean develop an associated unit-test) due to its reduced action spectrum and its deterministic side. In a data scientist approach, this approach would allow us to build pipelines, in which some flow of data would pass through different processing functions, the output of one would be the input for another, and so on. Another big advantage is the parallelization: as each function is stateless and deterministic i. e. f(x)=y, if we wish to transform a sequence of elements, we can transform parallely each element x1, x2, x3,‚Ä¶ of this sequence into y1, y2, y3,‚Ä¶ by calling f in parallel for each input Here, of course, I show a fairly simplistic but totally viable diagram, for example transforming the column of a dataset into a log. 1. the iteratorsdefinition: Again, based on the official python documentation: an Iterator is an object representing a sequence of data. The object returns data one item at a time, much like a bookmark in a book announces the page of that book. It is an object that enables to traverse a container, such as list or dict. To know if we are dealing with an iterator we must look in the magic methods associated with this object: if the object contains the __next__() and __iter__() methods then it is an iterator. This is also called the iterator protocol. This method can also be called by the function: next(iterator) and simply allows you to return the next element of the sequence, as by moving the bookmark of the book. If the last element is reached and __next__() is called again, a StopIteration exception is raised. A list is a sequence of elements, is a list an iterator?: We can call dir(), a built-in function that returns a list of attributes and methods (magic or not) for a given object.  We can see that __next__ does not exist here. List is therefore not an iterator. On the other hand, we see that the __iter__() method exists: This method can also be invoked from the iter(list) function. What does iter() produce from this list? Iter seems to return an iterator from the list. We can verify it as follows: If we do the same thing on a dictionary, this is what we get.  Again an iterator. Now, we can return each of the elements sequentially by calling next().  Conversely, we can also call iterator. __next__()Note again that next(a_list) cannot be done, the error message is self-explanatory.  Thus we see that a dictionary or a list, although being a sequence of objects, are not iterators, but iterables, that is to say that we can create an iterator from those - here by calling the __iter__ method, the iterator being, I remind you, is an object, which returns its elements one by one thanks to the implementation of its __next__ method. In a similar fashion, we can therefore consider the book as an iterable, i. e. a sequence of elements from which we can create an object that returns each of its pages one by one. We also see that only the dictionary keys are returned here. (Reminder, if we want to return tuples of (key, value) we can use the items () method in python 3+).  Isn‚Äôt this behavior similar to what you would get by looping with for? This is what is implicitly done when looping through a dictionary or a list:As the python documentation shows, these 2 loops are equivalent. for i in iter(obj):  print(i)for i in obj:  print(i)So that‚Äôs what‚Äôs behind it when you loop through a sequence of tuple, list, or dictionary elements. Note that we can also express an iterator as a list or tuple from the constructor of these objects which can admit an iterator as a parameter. To get the original dictionary from the old example again we can also call the dict() constructor on the previously discussed item_iterator.  If we can extract an iterator from an iterable, and iterate over it, what‚Äôs the point of this extra step, why doesn‚Äôt list understand the __next__ method? Well because an iterator can only be iterated once, once ‚Äúconsumed‚Äù it is necessary to recreate a new iterator from the iterable. The idea is that a new iterator will start at the beginning, while a partially used iterator picks up where it left off.  Wikipedia defines it well: you must see an iterator as an object that enables a programmer to traverse a container and gives access to data elements from this container. This iterator could use data stored in memory (from a list by iterating on it), or read a file or generate each value ‚Äúon-the-fly‚Äù. Creating an iterator: Here is a Counter class which defines an iterator, here the values ‚Äã‚Äãare generated on-the-fly rather than stored previously in a list. You are probably starting to understand now the crucial functionality that some iterators bring, if you do not need to store all the values ‚Äã‚Äãin memory, where in the case of infinite sequence, you can successively generate the values ‚Äã‚Äãand do calculations on these at the time of iteration / ‚Äúlazy generation‚Äù which results in less memory usage. Some iterable are lazy too, it‚Äôs the case of map objects. 1234567891011class Counter:  def __init__(self, low, high):    self. current = low - 1    self. high = high   def __iter__(self):    return self   def __next__(self):     self. current += 1    if self. current &lt; self. high:      return self. current    raise StopIterationfor c in Counter(3, 9):  print(c)345678Note: iterators implement __iter__ method just as iterables, they just return themselves (return self), they can then be used in for-loops just the same way iterables did. A nice use-case: Opening a file using the built-in open() function generates a file object which turns out to be an iterator!Reading line by line using a for loop implicitly calls the readline method, so only certain lines can be re-requisitioned on demand, rather than reading the whole file in memory, particularly useful in the event of a large file! We can therefore only traverse the file once (unless we reopen and recreate another iterator), and can just load the lines on demand that we want! Something interesting to mention, calling __iter__ on a iterable such as a list returns a new iterator each time (reading the beginning of this article should help you understand why). However, doing the same thing on an iterator returns himself. Have a look at the below screenshot and then look back at the Counter class definition.  2. The generatorsGenerators vs Iterators: Don‚Äôt get me wrong, generators are not something different from an iterator, they are actually iterators. Conversely, iterators are not all generators. Why are generators objects‚Ä¶ iterators? because they implement __next__and __iter__ methods. How to create a generator object? from a generator function or a generator expression. What are the purpose of doing so? writing a generator function (or a generator) expression is generally being easier to write than iterators (where we created a class and implemented by hand the 2 magic methods). Here we will implement some sort of logic in a function or an expression. When called they will return a generator object which behave the same way as the iterator i‚Äôve mentionned. I will then break this section in 2 parts: generators expression and generators ‚Äòfunctions‚Äô, as they share similarities in their implementation. Generators expressions:: Back to the first paragraphe of this chapter, we talked about list comprehension and generator expression.  Here you can see the object returned behaves exactly as an iterator. It is indeed an iterator. But, once again, why not using simply list comprehension rather than generator expression? because of memory usage and lazyness evaluation of each item. When we use a list comprehension, every element of the list have been computed and the whole result is returned as a list with allocated memory space.  When we use a gen expression, elements of the sequence are evaluated only when requested (lazy evaluation). This lead to use less memory and sometimes, depending on what you do thereafter, an increase in performance. Note that range(start, stop[, step]) here is actually an iterable. It does not implement __next__ unless you call iter() on it. However, range implement lazyness implementation, just like previously showed iterators, it will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed). Also range has the nice property to be indexable, which is not the case of our simple generator expression.  I can then start doing fancy stuff such as piping generator expression: Here is a code to make an generator indexable, seems beautiful. Have to test it . Generators functions:: Have you ever seen the yield keyword in certain functions before ? That keyword tranforms the function definition into a special type of function ‚Äî when compiled into Bytecode ‚Äî, named generator functions, also abbrieved generators. Instead of destroying local variables defined in the scope of a normal function when this function returns a value or ends, you can here resume the function where it left-off, preserving those local variables. Test those lines of code from the documentation and see the behavior of the function. 123def generate_ints(N):  for i in range(N):    yield iThe generator function, when called, returns a generator object, which is an iterator, which implements next and iter and controls the execution of the generator function. Close behavior to a generator expression here. Hence the close names. yield operates just like a return statement then, but preserved the state of the local variables for later ‚Äònext‚Äô calls.  As you can also see, the above function is easier to write than Counter although achieving the same thing at last. sending values to a generator function: As highlighted by the Python docs, you can also send values to the generator by writing: val = (yield i). Actually, the value of the yield expression after resuming the function is None if __next__() has been used. Otherwise, if send() was used, then the result will be the value passed in to that method. Have a look at the counter definition from the docs: 123456789def counter(maximum):  i = 0  while i &lt; maximum:    val = (yield i)    # If value provided, change counter    if val is not None:      i = val    else:      i += 1and the output where you can send an arbitrary value inside of the &gt;&gt;&gt; it = counter(10) &gt;&gt;&gt; next(it) 0&gt;&gt;&gt; next(it) 1&gt;&gt;&gt; it. send(8) 8&gt;&gt;&gt; next(it) 9&gt;&gt;&gt; next(it) Traceback (most recent call last): File  t. py , line 15, in &lt;module&gt;  it. next()StopIterationhence, yield does not only preserve local variable but gives us an entrypoint to the generator function to send input. 3. Functions operating on iteratorsNow that you have a good grasp on how to design one-time objects that read through a sequence of elements, it is to browse some built-in Python functions that leverage use of iterators. any() and all(): Clearly the first ones that come up to my mind: those functions are evaluating trueness of elements of a sequence.  any return True if any element of a sequence is true (caution: 0 and None are falsy) all return True is all element of a sequence evaluates to true. But the most interesting about those 2 functions is that they are lazy, this means, they abort as soon as the outcome is clear. Combined to a generator expression, this could drastically improve performance rather than using a list-comprehension (hence resulting in returning a complete list first before evaluating trueness of the elements)Don‚Äôt do that: all([x for x in range(0,100000000)]) But that: all((x for x in range(0,100000000))) compare the difference in execution time, why do the second one stop so quickly ? (reminder: 0 is falsy) By the way, you can delete the parentheses when the generator expression is used directly in a function that can expect to take iterators as parameter. map(function, sequence(s)) (imap in Python 2+): In Python 2 (deprecated as of 2020), imap is the lazy version of map. In Python 3+, map replaced imap. Thus as of Python3+, just use only map. map returns a map object an iterator and evaluates an iterator as parameter lazily evaluated.  Interesting sidenote i didn‚Äôt know before reading the docs, you can use map with 2 or more iterators and encapsulate them in the lambda x1,x2,x3,‚Ä¶ function. filter(function, sequence): Also returns an iterator, whose content has been filtered from another sequence.  1st parameter: a function to evaluate trueness, if None : return only non-falsy elements from the sequence 2nd parameter: iterableevaluationNote that filter(function, iterable) is equivalent to the generator expression (item for item in iterable if function(item)) if function is not None and (item for item in iterable if item) if function is None. filter(None, range(0,10000000000000000000)) Very fast isn‚Äôt it? once again, the iterator returned is evaluated only on demand when calling __next__ The itertools module: The Python docs also mention the itertools module that add some other functions making use of (or returning) iterators, i will just then pick the one that i found quite important:  itertools. count(start, step) =&gt; returns an infinite stream of evenly spaced values.  itertools. cycle(iterable) =&gt; from an iterable, returns an infinite stream of copies of this iterable itertools. repeat(elem, [n]) =&gt; similar to iterable, but with an element only, repeated infinitely or n times itertools. chain(iterA, iterB, ‚Ä¶) =&gt; concatenates the iterables itertools. islice(iterable, [start], stop, [step]) =&gt; from an iterable, return a slice of it.  itertools. tee(iter, [n]) =&gt; copy n times the provided iterator (reminder: once consumed, an iterator cannot be used anymore) itertools. starmap(function, iterable) =&gt; the name is actually well chosen, think of it as a *map or maybe more like map(function, *sequence_of_tuples). For sequences being tuples: it will unpack each tuple and apply the function with multiple unpacked paramaters f(*tuple) itertools. takewhile(predicate, iter): returned an iterator sliced from the iterable till the first falsy value from the predicate is encountered.  itertools. dropwhile(predicate, iter): inverse of takewhileCombinations: For some use-cases (when creating unit-testing during an internship trying to cover all possible cases, some combinatoric functions where really useful):  itertools. combinations(iter, n): returns an iterator of all psosible combinations of n elements (order doesn‚Äôt matter) itertools. permutations(iterable, n): ordre matter (2 different order = 2 possible combinations)For statistics, can be useful to simulate the sample of balls with replacement.  itertools. combinations_with_replacement(iterable, n)functools module:  functools. partial(function, *args, **kwargs): create a partial object, (callable object, just like a function) which when called will behave like the function in parameter, with positional and keyword arguments passed in. VERY USEFUL: functools. reduce(function, sequence, [initial_value]): cumulately perform an operation on each element: function(function(function(x1, x2), x3), x4))For example for a prod: ((x1*x2)*x3)*x4you can provide an initial value (optional) for starting conditions just before x1. 4. What about multiprocessing ?With reduced memory usage in certain cases, and a evaluation of each item on-demand, iterators/generators are somehow appealing to create pipelines in Data Science for example. One might want to involve multiprocessing with iterators/generators, by splitting the latter in multiple processes. However, even functions defined within generators/iterators are stateless, the iterator construct is inherently stateful: each item are requested using the next() after one has been consumed already. Splitting a generator into multiple processes would lead to make multiple copies of this generator (one for each process: remember that processes have separate memory). You could still use some techniques but sharing memory should be avoided in general, and in most cases would lead no performance gains from the one expected doing true parallelization. So where could we leverage multiprocessing while creating some pipelines and making use of iterators/generators? Well, I see 2 uses cases here, although I‚Äôm open to suggestions. If we have an in-memory stored list and not-so-long, we could use multiprocessing. map to take the list as a whole and split it (or not) in multiple chuncks to be fed to the number of processes in the pool. This could speed up the programm mostly if some heavy CPU-bound computations are being done. The side effect is that multiprocessing. map blocks the calling process until all the processes complete and return the results as a whole. We could also use multiprocessing. imap to fed sequentially chuncks (or element) to worker processes from a to-long-to-be-stored-iterable and also return lazily an iterable.  I‚Äôve also found a smart implementation using mapalong with itertools. islice, which will still go through the iterator (can‚Äôt slice at any place without calling next on preceding elements as iterator are stateful), but has the benefit to be lazy:   pool. imap(function, itertools. islice(iter, N))here That‚Äôs all for this tutorial, I hope it was informative and concise enough, don‚Äôt hesitate to reach me or comment below for any questions. "
    }, {
    "id": 24,
    "url": "http://localhost:4000/github-jupyter-notebooks/",
    "title": "Go to all course practice sessions !",
    "body": "2020/08/03 - Github is a web-hosting platform and software development management service using Git versionning system. This site is developed using Ruby on Rails and contains as of today 50 millions suscribers worldwide. The course content will be available under repository TDs_ESILV "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});


    
function lunr_search(term) {
    $('#lunrsearchresults').show( 1000 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
</script>
<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>




<form class="bd-search hidden-sm-down" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
<input type="text" class="form-control text-small"  id="lunrsearch" name="q" value="" placeholder="Type keyword and enter..."> 
</form>
            </ul>
        </div>
    </div>
    </nav>

    <!-- Search Results -->
    <div id="lunrsearchresults">
        <ul class="mb-0"></ul>
    </div>

    <!-- Content -->
    <main role="main" class="site-content">
        <div class="container">
<div class="row justify-content-center">
    <div class="col-md-8">        
        <div class="row align-items-center mb-5">
            <div class="col-md-9">
                <h2 class="font-weight-bold">Luc <span class="small btn btn-outline-success btn-sm btn-round"><a href="https://github.com/Luc-Bertin">Follow on Github</a></span></h2>
                <p><a href="https://lucbertin.com">https://lucbertin.com</a></p>
                <p class="excerpt">Hi, my name is Luc. To me, code is art and i love coding in Python, hence the website !</p>
            </div>
            <div class="col-md-3 text-right">
                <img alt="Luc" src="/assets/images/avatar1.jpg" class="rounded-circle" height="100" width="100">
            </div>
        </div>
        <h4 class="font-weight-bold spanborder"><span>Posts by Luc</span></h4>
            
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/Notions-Supervised-Machine-Learning/">Supervised Machine Learning</a>
	</h2>
	<p class="excerpt">
	     Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed (if,if,if,else,if). ‚Äî Arthur Samuel, 1959
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#statsenvrac">StatsEnVrac</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 25, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/Notions-Supervised-Machine-Learning/">
	<img class="w-100" src="/assets/images/post_some_statistical_elements/index_img/cover.jpg" alt="Supervised Machine Learning">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/some-functional-programing-exercices/">Some functional programming exercices</a>
	</h2>
	<p class="excerpt">
	   Some exercices following tutorial Introduction to functional programming to make you more comfortable with the concepts.
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#exercices">Exercices</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 14, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/some-functional-programing-exercices/">
	<img class="w-100" src="/assets/images/post_some_functional_programming_exercices/index_img/cover.jpg" alt="Some functional programming exercices">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/pandas-exercices/">Some Pandas exercices</a>
	</h2>
	<p class="excerpt">
	   Some exercices following tutorial Discover Pandas to make you more comfortable with the concepts.
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#exercices">Exercices</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#pandas">Pandas</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 14, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/pandas-exercices/">
	<img class="w-100" src="/assets/images/post_some_pandas_exercices/index_img/cover.png" alt="Some Pandas exercices">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/discover-pandas/">Discover Pandas</a>
	</h2>
	<p class="excerpt">
	   Why Pandas ?
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 10, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/discover-pandas/">
	<img class="w-100" src="/assets/images/post_discover_pandas/index_img/cover.jpg" alt="Discover Pandas">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/webscrapping/">Webscrapping using Selenium</a>
	</h2>
	<p class="excerpt">
	   Selenium is an open-source automated testing suite for web apps. It was at first used to automate tests for web applications as it can emulate user interactions with browsers, althoug...
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#lecture">Lecture</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#selenium">Selenium</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 07, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/webscrapping/">
	<img class="w-100" src="/assets/images/post_webscrapping/index_img/cover.jpg" alt="Webscrapping using Selenium">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/hands-on-numpy/">Hands-on Numpy !</a>
	</h2>
	<p class="excerpt">
	   It is often better to visualize data of apparent heterogeneity (sounds, images, text) as arrays of numbers, so to process these data or apply machine learning on them. A well-known pa...
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#lecture">Lecture</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#numpy">Numpy</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 01, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/hands-on-numpy/">
	<img class="w-100" src="/assets/images/post_hands_on_numpy/cover.jpg" alt="Hands-on Numpy !">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/some-python-exercices/">Some Python exercices</a>
	</h2>
	<p class="excerpt">
	   Some exercices following tutorial Beginning in Python to make you more comfortable with some object-oriented concepts in Python ;)
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#exercices">Exercices</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Sep 01, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/some-python-exercices/">
	<img class="w-100" src="/assets/images/post_some_exercices_in_python/index_img/cover.png" alt="Some Python exercices">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/setting-up-a-simple-flask-app/">Setting up a simple Flask app</a>
	</h2>
	<p class="excerpt">
	   Flask is a micro web framework written in Python, first released in 2010. It is lightweight (hence the ‚Äúmicro‚Äù), has more stars on GitHub that is ‚Äúconcurrent‚Äù Django¬†‚Äî first released ...
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#flask">Flask</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 29, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/setting-up-a-simple-flask-app/">
	<img class="w-100" src="/assets/images/post_setting_up_a_simple_flask_app/flask2.png" alt="Setting up a simple Flask app">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/a-note-on-execution-model/">A note on execution model</a>
	</h2>
	<p class="excerpt">
	   
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#lecture">Lecture</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 28, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/a-note-on-execution-model/">
	<img class="w-100" src="/assets/images/post_execution_model/namespaces.svg" alt="A note on execution model">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/Beginning-in-Python/">Beginning in Python</a>
	</h2>
	<p class="excerpt">
	   1st course will mainly focus on how to approach Python for the first time. For that we will use Jupyter module.
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 22, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/Beginning-in-Python/">
	<img class="w-100" src="/assets/images/post_approaching_python_programming/cover.png" alt="Beginning in Python">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/Install-Python/">Install Python !</a>
	</h2>
	<p class="excerpt">
	   This tutorial helps newcomers to install Python properly and manage different Python versions, especially for Mac users having a system 2.7 Python installed already.
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 14, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/Install-Python/">
	<img class="w-100" src="/assets/images/post_install_python/cover.jpg" alt="Install Python !">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/Coding-A-Perceptron-with-Numpy-copy/">Coding a perceptron with Numpy</a>
	</h2>
	<p class="excerpt">
	   Voici un test pour un nouveau post
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#deep learning">Deep Learning</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 04, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/Coding-A-Perceptron-with-Numpy-copy/">
	<img class="w-100" src="/assets/images/post_coding_a_perceptron/cover.png" alt="Coding a perceptron with Numpy">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/introduction-to-functional-programming/">Introduction to functional programming</a>
	</h2>
	<p class="excerpt">
	   
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#lecture">Lecture</a><span class="sep">, </span>
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#python">Python</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 03, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/introduction-to-functional-programming/">
	<img class="w-100" src="/assets/images/post_functional_programming/cover.png" alt="Introduction to functional programming">
	</a>
	</div>

</div>
            
            <div class="mb-5 d-flex justify-content-between main-loop-card">
<div class="pr-3">
	<h2 class="mb-1 h4 font-weight-bold">
	<a class="text-dark" href="/github-jupyter-notebooks/">Go to all course practice sessions !</a>
	</h2>
	<p class="excerpt">
	   Github is a web-hosting platform and software development management service using Git versionning system. This site is developed using Ruby on Rails and contains as of today 50 milli...
	</p>
	<small class="d-block text-muted">
		In <span class="catlist">
		
		<a class="text-capitalize text-muted smoothscroll" href="/categories.html#tds">TDs</a><span class="sep">, </span>
		
		</span>
	</small>
	<small class="text-muted">
		Aug 03, 2020
	</small>
</div>

	<div class="col-md-3 pr-0 text-right">
	<a href="/github-jupyter-notebooks/">
	<img class="w-100" src="/assets/images/post_github_jupyter_notebooks/cover.jpg" alt="Go to all course practice sessions !">
	</a>
	</div>

</div>
            
    </div>
</div>
</div>
    </main>


    <!-- Scripts: popper, bootstrap, theme, lunr -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

    <script src="/assets/js/theme.js"></script>


    <!-- Footer -->
    <footer class="bg-white border-top p-3 text-muted small">
        <div class="container">
        <div class="row align-items-center justify-content-between">
            <div>
                <span class="navbar-brand mr-2 mb-0"><strong>PythonMood</strong></span>
                <span>Copyright ¬© content: Luc <script>document.write(new Date().getFullYear())</script>.</span>
            </div>
            <!-- <div>
                Made with <a target="_blank" class="text-dark font-weight-bold" href="https://www.wowthemes.net/mundana-jekyll-theme/"> Mundana Jekyll Theme </a> by <a class="text-dark" target="_blank" href="https://www.wowthemes.net">WowThemes</a>.
            </div> -->
        </div>
        </div>
    </footer>

    <!-- All this area goes before </body> closing tag --> 


</body>

</html>
